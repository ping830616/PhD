{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "796268f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-25 09:18:25,151] A new study created in memory with name: no-name-0328ed9b-6911-45f4-aa6b-aa5b8dc40ca2\n",
      "C:\\Users\\Hsiao-ping.ni\\AppData\\Local\\Temp\\ipykernel_56780\\218452991.py:82: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "[I 2024-11-25 09:18:29,317] Trial 0 finished with value: 0.9697014689445496 and parameters: {'hidden_dim1': 48, 'hidden_dim2': 16, 'latent_dim': 14, 'learning_rate': 0.0006243751409959713, 'batch_size': 64}. Best is trial 0 with value: 0.9697014689445496.\n",
      "[I 2024-11-25 09:18:33,169] Trial 1 finished with value: 0.9137906432151794 and parameters: {'hidden_dim1': 96, 'hidden_dim2': 64, 'latent_dim': 10, 'learning_rate': 0.004837007441645962, 'batch_size': 32}. Best is trial 1 with value: 0.9137906432151794.\n",
      "[I 2024-11-25 09:18:36,935] Trial 2 finished with value: 0.9592815041542053 and parameters: {'hidden_dim1': 96, 'hidden_dim2': 32, 'latent_dim': 8, 'learning_rate': 0.006798431915462226, 'batch_size': 64}. Best is trial 1 with value: 0.9137906432151794.\n",
      "[I 2024-11-25 09:18:40,568] Trial 3 finished with value: 1.0884422063827515 and parameters: {'hidden_dim1': 96, 'hidden_dim2': 64, 'latent_dim': 12, 'learning_rate': 0.00012327423783805623, 'batch_size': 48}. Best is trial 1 with value: 0.9137906432151794.\n",
      "[I 2024-11-25 09:18:44,774] Trial 4 finished with value: 0.9226487278938293 and parameters: {'hidden_dim1': 64, 'hidden_dim2': 64, 'latent_dim': 16, 'learning_rate': 0.0008095931771606346, 'batch_size': 48}. Best is trial 1 with value: 0.9137906432151794.\n",
      "[I 2024-11-25 09:18:48,995] Trial 5 finished with value: 0.9839017391204834 and parameters: {'hidden_dim1': 48, 'hidden_dim2': 16, 'latent_dim': 6, 'learning_rate': 0.0010706694020467494, 'batch_size': 64}. Best is trial 1 with value: 0.9137906432151794.\n",
      "[I 2024-11-25 09:18:53,459] Trial 6 finished with value: 0.8031551837921143 and parameters: {'hidden_dim1': 48, 'hidden_dim2': 32, 'latent_dim': 10, 'learning_rate': 0.009748766852017999, 'batch_size': 16}. Best is trial 6 with value: 0.8031551837921143.\n",
      "[I 2024-11-25 09:18:57,591] Trial 7 finished with value: 0.9232521057128906 and parameters: {'hidden_dim1': 64, 'hidden_dim2': 48, 'latent_dim': 14, 'learning_rate': 0.0011046347538170526, 'batch_size': 16}. Best is trial 6 with value: 0.8031551837921143.\n",
      "[I 2024-11-25 09:19:01,430] Trial 8 finished with value: 0.9503493309020996 and parameters: {'hidden_dim1': 96, 'hidden_dim2': 48, 'latent_dim': 8, 'learning_rate': 0.000689252723697788, 'batch_size': 64}. Best is trial 6 with value: 0.8031551837921143.\n",
      "[I 2024-11-25 09:19:05,113] Trial 9 finished with value: 0.9331340789794922 and parameters: {'hidden_dim1': 80, 'hidden_dim2': 16, 'latent_dim': 16, 'learning_rate': 0.0010770857593810697, 'batch_size': 16}. Best is trial 6 with value: 0.8031551837921143.\n",
      "[I 2024-11-25 09:19:09,189] Trial 10 finished with value: 0.9482073783874512 and parameters: {'hidden_dim1': 32, 'hidden_dim2': 32, 'latent_dim': 2, 'learning_rate': 0.003430395015342364, 'batch_size': 32}. Best is trial 6 with value: 0.8031551837921143.\n",
      "[I 2024-11-25 09:19:12,993] Trial 11 finished with value: 0.8612154126167297 and parameters: {'hidden_dim1': 128, 'hidden_dim2': 48, 'latent_dim': 10, 'learning_rate': 0.00939195049840209, 'batch_size': 32}. Best is trial 6 with value: 0.8031551837921143.\n",
      "[I 2024-11-25 09:19:16,929] Trial 12 finished with value: 0.8826847076416016 and parameters: {'hidden_dim1': 128, 'hidden_dim2': 48, 'latent_dim': 6, 'learning_rate': 0.008142563910216992, 'batch_size': 16}. Best is trial 6 with value: 0.8031551837921143.\n",
      "[I 2024-11-25 09:19:20,936] Trial 13 finished with value: 0.9345917701721191 and parameters: {'hidden_dim1': 128, 'hidden_dim2': 32, 'latent_dim': 10, 'learning_rate': 0.002585691593224477, 'batch_size': 32}. Best is trial 6 with value: 0.8031551837921143.\n",
      "[I 2024-11-25 09:19:24,709] Trial 14 finished with value: 0.9238452911376953 and parameters: {'hidden_dim1': 32, 'hidden_dim2': 48, 'latent_dim': 12, 'learning_rate': 0.009982839387029213, 'batch_size': 16}. Best is trial 6 with value: 0.8031551837921143.\n",
      "[I 2024-11-25 09:19:28,485] Trial 15 finished with value: 0.9316022992134094 and parameters: {'hidden_dim1': 112, 'hidden_dim2': 32, 'latent_dim': 4, 'learning_rate': 0.00229935845996246, 'batch_size': 32}. Best is trial 6 with value: 0.8031551837921143.\n",
      "[I 2024-11-25 09:19:32,076] Trial 16 finished with value: 0.9800283312797546 and parameters: {'hidden_dim1': 64, 'hidden_dim2': 48, 'latent_dim': 12, 'learning_rate': 0.0002536253717554741, 'batch_size': 48}. Best is trial 6 with value: 0.8031551837921143.\n",
      "[I 2024-11-25 09:19:35,831] Trial 17 finished with value: 0.9337587356567383 and parameters: {'hidden_dim1': 112, 'hidden_dim2': 32, 'latent_dim': 10, 'learning_rate': 0.004714221972759869, 'batch_size': 16}. Best is trial 6 with value: 0.8031551837921143.\n",
      "[I 2024-11-25 09:19:39,995] Trial 18 finished with value: 0.9099414944648743 and parameters: {'hidden_dim1': 48, 'hidden_dim2': 32, 'latent_dim': 6, 'learning_rate': 0.0018998146875963675, 'batch_size': 32}. Best is trial 6 with value: 0.8031551837921143.\n",
      "[I 2024-11-25 09:19:44,126] Trial 19 finished with value: 0.9401712417602539 and parameters: {'hidden_dim1': 80, 'hidden_dim2': 48, 'latent_dim': 8, 'learning_rate': 0.0052982901503043425, 'batch_size': 16}. Best is trial 6 with value: 0.8031551837921143.\n",
      "[I 2024-11-25 09:19:48,019] Trial 20 finished with value: 0.9586667418479919 and parameters: {'hidden_dim1': 112, 'hidden_dim2': 16, 'latent_dim': 14, 'learning_rate': 0.00042660018403101164, 'batch_size': 32}. Best is trial 6 with value: 0.8031551837921143.\n",
      "[I 2024-11-25 09:19:51,852] Trial 21 finished with value: 0.9285362362861633 and parameters: {'hidden_dim1': 128, 'hidden_dim2': 48, 'latent_dim': 6, 'learning_rate': 0.008819217738149655, 'batch_size': 16}. Best is trial 6 with value: 0.8031551837921143.\n",
      "[I 2024-11-25 09:19:55,967] Trial 22 finished with value: 0.9039075970649719 and parameters: {'hidden_dim1': 128, 'hidden_dim2': 48, 'latent_dim': 4, 'learning_rate': 0.006857387788595681, 'batch_size': 16}. Best is trial 6 with value: 0.8031551837921143.\n",
      "[I 2024-11-25 09:20:00,188] Trial 23 finished with value: 0.8875174522399902 and parameters: {'hidden_dim1': 128, 'hidden_dim2': 64, 'latent_dim': 8, 'learning_rate': 0.009782028122897364, 'batch_size': 16}. Best is trial 6 with value: 0.8031551837921143.\n",
      "[I 2024-11-25 09:20:05,150] Trial 24 finished with value: 0.9046249985694885 and parameters: {'hidden_dim1': 112, 'hidden_dim2': 48, 'latent_dim': 4, 'learning_rate': 0.0031920822054176063, 'batch_size': 32}. Best is trial 6 with value: 0.8031551837921143.\n",
      "[I 2024-11-25 09:20:09,847] Trial 25 finished with value: 0.8057892918586731 and parameters: {'hidden_dim1': 80, 'hidden_dim2': 32, 'latent_dim': 10, 'learning_rate': 0.0062186692094865735, 'batch_size': 16}. Best is trial 6 with value: 0.8031551837921143.\n",
      "[I 2024-11-25 09:20:13,586] Trial 26 finished with value: 0.9812600612640381 and parameters: {'hidden_dim1': 80, 'hidden_dim2': 32, 'latent_dim': 10, 'learning_rate': 0.004015021077996022, 'batch_size': 48}. Best is trial 6 with value: 0.8031551837921143.\n",
      "[I 2024-11-25 09:20:17,482] Trial 27 finished with value: 0.9425711035728455 and parameters: {'hidden_dim1': 64, 'hidden_dim2': 32, 'latent_dim': 12, 'learning_rate': 0.006398932447846385, 'batch_size': 32}. Best is trial 6 with value: 0.8031551837921143.\n",
      "[I 2024-11-25 09:20:21,426] Trial 28 finished with value: 0.9793944358825684 and parameters: {'hidden_dim1': 48, 'hidden_dim2': 32, 'latent_dim': 10, 'learning_rate': 0.0015772049913590784, 'batch_size': 16}. Best is trial 6 with value: 0.8031551837921143.\n",
      "[I 2024-11-25 09:20:25,291] Trial 29 finished with value: 0.9967184662818909 and parameters: {'hidden_dim1': 32, 'hidden_dim2': 16, 'latent_dim': 12, 'learning_rate': 0.005713815631863095, 'batch_size': 16}. Best is trial 6 with value: 0.8031551837921143.\n",
      "[I 2024-11-25 09:20:29,128] Trial 30 finished with value: 0.9654912948608398 and parameters: {'hidden_dim1': 80, 'hidden_dim2': 16, 'latent_dim': 14, 'learning_rate': 0.003270067908183201, 'batch_size': 32}. Best is trial 6 with value: 0.8031551837921143.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-25 09:20:32,907] Trial 31 finished with value: 0.8925666809082031 and parameters: {'hidden_dim1': 112, 'hidden_dim2': 48, 'latent_dim': 8, 'learning_rate': 0.006939479756489666, 'batch_size': 16}. Best is trial 6 with value: 0.8031551837921143.\n",
      "[I 2024-11-25 09:20:36,585] Trial 32 finished with value: 0.8972999453544617 and parameters: {'hidden_dim1': 128, 'hidden_dim2': 48, 'latent_dim': 6, 'learning_rate': 0.00817446267540806, 'batch_size': 16}. Best is trial 6 with value: 0.8031551837921143.\n",
      "[I 2024-11-25 09:20:40,545] Trial 33 finished with value: 0.9035314917564392 and parameters: {'hidden_dim1': 96, 'hidden_dim2': 32, 'latent_dim': 10, 'learning_rate': 0.004456912072286645, 'batch_size': 16}. Best is trial 6 with value: 0.8031551837921143.\n",
      "[I 2024-11-25 09:20:44,364] Trial 34 finished with value: 0.8741876482963562 and parameters: {'hidden_dim1': 96, 'hidden_dim2': 64, 'latent_dim': 10, 'learning_rate': 0.007669539770266366, 'batch_size': 16}. Best is trial 6 with value: 0.8031551837921143.\n",
      "[I 2024-11-25 09:20:47,988] Trial 35 finished with value: 0.8721974492073059 and parameters: {'hidden_dim1': 96, 'hidden_dim2': 64, 'latent_dim': 10, 'learning_rate': 0.006031473519007935, 'batch_size': 32}. Best is trial 6 with value: 0.8031551837921143.\n",
      "[I 2024-11-25 09:20:51,325] Trial 36 finished with value: 1.086156964302063 and parameters: {'hidden_dim1': 64, 'hidden_dim2': 64, 'latent_dim': 12, 'learning_rate': 0.00010919625002480647, 'batch_size': 48}. Best is trial 6 with value: 0.8031551837921143.\n",
      "[I 2024-11-25 09:20:54,921] Trial 37 finished with value: 0.8830499649047852 and parameters: {'hidden_dim1': 80, 'hidden_dim2': 64, 'latent_dim': 10, 'learning_rate': 0.004943609131227811, 'batch_size': 32}. Best is trial 6 with value: 0.8031551837921143.\n",
      "[I 2024-11-25 09:20:58,442] Trial 38 finished with value: 1.0364564657211304 and parameters: {'hidden_dim1': 48, 'hidden_dim2': 64, 'latent_dim': 8, 'learning_rate': 0.00016306441051614794, 'batch_size': 48}. Best is trial 6 with value: 0.8031551837921143.\n",
      "[I 2024-11-25 09:21:02,843] Trial 39 finished with value: 0.9609985947608948 and parameters: {'hidden_dim1': 96, 'hidden_dim2': 32, 'latent_dim': 12, 'learning_rate': 0.0015761698238973565, 'batch_size': 32}. Best is trial 6 with value: 0.8031551837921143.\n",
      "[I 2024-11-25 09:21:06,919] Trial 40 finished with value: 0.9404972195625305 and parameters: {'hidden_dim1': 48, 'hidden_dim2': 32, 'latent_dim': 8, 'learning_rate': 0.006169343443987736, 'batch_size': 48}. Best is trial 6 with value: 0.8031551837921143.\n",
      "[I 2024-11-25 09:21:11,101] Trial 41 finished with value: 0.9165692329406738 and parameters: {'hidden_dim1': 96, 'hidden_dim2': 64, 'latent_dim': 10, 'learning_rate': 0.007579646602349507, 'batch_size': 32}. Best is trial 6 with value: 0.8031551837921143.\n",
      "[I 2024-11-25 09:21:15,095] Trial 42 finished with value: 0.8897304534912109 and parameters: {'hidden_dim1': 96, 'hidden_dim2': 64, 'latent_dim': 10, 'learning_rate': 0.009830100074491314, 'batch_size': 16}. Best is trial 6 with value: 0.8031551837921143.\n",
      "[I 2024-11-25 09:21:19,308] Trial 43 finished with value: 0.8132407069206238 and parameters: {'hidden_dim1': 96, 'hidden_dim2': 64, 'latent_dim': 10, 'learning_rate': 0.005732328804858152, 'batch_size': 16}. Best is trial 6 with value: 0.8031551837921143.\n",
      "[I 2024-11-25 09:21:22,952] Trial 44 finished with value: 0.9006964564323425 and parameters: {'hidden_dim1': 80, 'hidden_dim2': 64, 'latent_dim': 12, 'learning_rate': 0.0036319007822328093, 'batch_size': 64}. Best is trial 6 with value: 0.8031551837921143.\n",
      "[I 2024-11-25 09:21:26,898] Trial 45 finished with value: 0.9176523685455322 and parameters: {'hidden_dim1': 112, 'hidden_dim2': 64, 'latent_dim': 8, 'learning_rate': 0.0026775741584952346, 'batch_size': 32}. Best is trial 6 with value: 0.8031551837921143.\n",
      "[I 2024-11-25 09:21:30,751] Trial 46 finished with value: 0.9343898892402649 and parameters: {'hidden_dim1': 96, 'hidden_dim2': 64, 'latent_dim': 14, 'learning_rate': 0.005576211365268397, 'batch_size': 16}. Best is trial 6 with value: 0.8031551837921143.\n",
      "[I 2024-11-25 09:21:34,704] Trial 47 finished with value: 0.9624503254890442 and parameters: {'hidden_dim1': 64, 'hidden_dim2': 32, 'latent_dim': 10, 'learning_rate': 0.00046168360416135533, 'batch_size': 32}. Best is trial 6 with value: 0.8031551837921143.\n",
      "[I 2024-11-25 09:21:38,871] Trial 48 finished with value: 0.9358587861061096 and parameters: {'hidden_dim1': 32, 'hidden_dim2': 48, 'latent_dim': 12, 'learning_rate': 0.00473318739174077, 'batch_size': 16}. Best is trial 6 with value: 0.8031551837921143.\n",
      "[I 2024-11-25 09:21:43,092] Trial 49 finished with value: 0.9686486721038818 and parameters: {'hidden_dim1': 112, 'hidden_dim2': 16, 'latent_dim': 16, 'learning_rate': 0.008090468176047071, 'batch_size': 16}. Best is trial 6 with value: 0.8031551837921143.\n",
      "[I 2024-11-25 09:21:47,181] Trial 50 finished with value: 0.9423182606697083 and parameters: {'hidden_dim1': 80, 'hidden_dim2': 32, 'latent_dim': 10, 'learning_rate': 0.003819216169575002, 'batch_size': 32}. Best is trial 6 with value: 0.8031551837921143.\n",
      "[I 2024-11-25 09:21:51,205] Trial 51 finished with value: 0.8566355109214783 and parameters: {'hidden_dim1': 96, 'hidden_dim2': 64, 'latent_dim': 10, 'learning_rate': 0.007409365689018987, 'batch_size': 16}. Best is trial 6 with value: 0.8031551837921143.\n",
      "[I 2024-11-25 09:21:55,429] Trial 52 finished with value: 0.9489953517913818 and parameters: {'hidden_dim1': 96, 'hidden_dim2': 64, 'latent_dim': 8, 'learning_rate': 0.006233117678753339, 'batch_size': 16}. Best is trial 6 with value: 0.8031551837921143.\n",
      "[I 2024-11-25 09:21:59,532] Trial 53 finished with value: 0.9188258647918701 and parameters: {'hidden_dim1': 80, 'hidden_dim2': 64, 'latent_dim': 10, 'learning_rate': 0.008737665995001967, 'batch_size': 16}. Best is trial 6 with value: 0.8031551837921143.\n",
      "[I 2024-11-25 09:22:03,635] Trial 54 finished with value: 0.8565567135810852 and parameters: {'hidden_dim1': 112, 'hidden_dim2': 64, 'latent_dim': 12, 'learning_rate': 0.005443360260446851, 'batch_size': 16}. Best is trial 6 with value: 0.8031551837921143.\n",
      "[I 2024-11-25 09:22:07,846] Trial 55 finished with value: 0.8295817375183105 and parameters: {'hidden_dim1': 128, 'hidden_dim2': 64, 'latent_dim': 12, 'learning_rate': 0.004301465265080921, 'batch_size': 16}. Best is trial 6 with value: 0.8031551837921143.\n",
      "[I 2024-11-25 09:22:11,824] Trial 56 finished with value: 0.9113447070121765 and parameters: {'hidden_dim1': 112, 'hidden_dim2': 64, 'latent_dim': 12, 'learning_rate': 0.004307732548812716, 'batch_size': 16}. Best is trial 6 with value: 0.8031551837921143.\n",
      "[I 2024-11-25 09:22:15,549] Trial 57 finished with value: 0.8742279410362244 and parameters: {'hidden_dim1': 112, 'hidden_dim2': 64, 'latent_dim': 14, 'learning_rate': 0.002719514801557659, 'batch_size': 16}. Best is trial 6 with value: 0.8031551837921143.\n",
      "[I 2024-11-25 09:22:19,135] Trial 58 finished with value: 0.9697850346565247 and parameters: {'hidden_dim1': 128, 'hidden_dim2': 64, 'latent_dim': 12, 'learning_rate': 0.0008839726980550601, 'batch_size': 16}. Best is trial 6 with value: 0.8031551837921143.\n",
      "[I 2024-11-25 09:22:22,990] Trial 59 finished with value: 0.9311477541923523 and parameters: {'hidden_dim1': 64, 'hidden_dim2': 64, 'latent_dim': 14, 'learning_rate': 0.005364270442164177, 'batch_size': 16}. Best is trial 6 with value: 0.8031551837921143.\n",
      "[I 2024-11-25 09:22:26,824] Trial 60 finished with value: 0.9106952548027039 and parameters: {'hidden_dim1': 128, 'hidden_dim2': 32, 'latent_dim': 12, 'learning_rate': 0.0021257141280390133, 'batch_size': 16}. Best is trial 6 with value: 0.8031551837921143.\n",
      "[I 2024-11-25 09:22:30,924] Trial 61 finished with value: 0.9595224261283875 and parameters: {'hidden_dim1': 128, 'hidden_dim2': 48, 'latent_dim': 10, 'learning_rate': 0.0072694019733963765, 'batch_size': 16}. Best is trial 6 with value: 0.8031551837921143.\n",
      "[I 2024-11-25 09:22:35,627] Trial 62 finished with value: 0.9412220120429993 and parameters: {'hidden_dim1': 128, 'hidden_dim2': 64, 'latent_dim': 12, 'learning_rate': 0.00997231225231934, 'batch_size': 16}. Best is trial 6 with value: 0.8031551837921143.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-25 09:22:39,617] Trial 63 finished with value: 0.847309410572052 and parameters: {'hidden_dim1': 112, 'hidden_dim2': 48, 'latent_dim': 10, 'learning_rate': 0.0051471395831015595, 'batch_size': 16}. Best is trial 6 with value: 0.8031551837921143.\n",
      "[I 2024-11-25 09:22:43,142] Trial 64 finished with value: 0.9081055521965027 and parameters: {'hidden_dim1': 112, 'hidden_dim2': 48, 'latent_dim': 8, 'learning_rate': 0.004110550919053191, 'batch_size': 16}. Best is trial 6 with value: 0.8031551837921143.\n",
      "[I 2024-11-25 09:22:46,516] Trial 65 finished with value: 0.9396368861198425 and parameters: {'hidden_dim1': 112, 'hidden_dim2': 64, 'latent_dim': 12, 'learning_rate': 0.0030089197052295003, 'batch_size': 16}. Best is trial 6 with value: 0.8031551837921143.\n",
      "[I 2024-11-25 09:22:49,955] Trial 66 finished with value: 0.9713025689125061 and parameters: {'hidden_dim1': 112, 'hidden_dim2': 32, 'latent_dim': 10, 'learning_rate': 0.005122340290406978, 'batch_size': 16}. Best is trial 6 with value: 0.8031551837921143.\n",
      "[I 2024-11-25 09:22:53,224] Trial 67 finished with value: 0.9199619293212891 and parameters: {'hidden_dim1': 96, 'hidden_dim2': 64, 'latent_dim': 14, 'learning_rate': 0.006792225832759448, 'batch_size': 16}. Best is trial 6 with value: 0.8031551837921143.\n",
      "[I 2024-11-25 09:22:57,111] Trial 68 finished with value: 0.8636023998260498 and parameters: {'hidden_dim1': 112, 'hidden_dim2': 48, 'latent_dim': 8, 'learning_rate': 0.0034749436714688387, 'batch_size': 16}. Best is trial 6 with value: 0.8031551837921143.\n",
      "[I 2024-11-25 09:23:00,831] Trial 69 finished with value: 0.9476965069770813 and parameters: {'hidden_dim1': 96, 'hidden_dim2': 64, 'latent_dim': 10, 'learning_rate': 0.008335853416568523, 'batch_size': 16}. Best is trial 6 with value: 0.8031551837921143.\n",
      "[I 2024-11-25 09:23:04,806] Trial 70 finished with value: 0.9603662490844727 and parameters: {'hidden_dim1': 96, 'hidden_dim2': 32, 'latent_dim': 12, 'learning_rate': 0.0012738685057702745, 'batch_size': 16}. Best is trial 6 with value: 0.8031551837921143.\n",
      "[I 2024-11-25 09:23:08,466] Trial 71 finished with value: 0.9041239619255066 and parameters: {'hidden_dim1': 128, 'hidden_dim2': 48, 'latent_dim': 10, 'learning_rate': 0.006859585836294438, 'batch_size': 16}. Best is trial 6 with value: 0.8031551837921143.\n",
      "[I 2024-11-25 09:23:12,617] Trial 72 finished with value: 0.8047650456428528 and parameters: {'hidden_dim1': 128, 'hidden_dim2': 48, 'latent_dim': 10, 'learning_rate': 0.008765456775199297, 'batch_size': 16}. Best is trial 6 with value: 0.8031551837921143.\n",
      "[I 2024-11-25 09:23:16,328] Trial 73 finished with value: 0.952606201171875 and parameters: {'hidden_dim1': 128, 'hidden_dim2': 48, 'latent_dim': 10, 'learning_rate': 0.005785571085342088, 'batch_size': 16}. Best is trial 6 with value: 0.8031551837921143.\n",
      "[I 2024-11-25 09:23:20,139] Trial 74 finished with value: 0.8374333381652832 and parameters: {'hidden_dim1': 112, 'hidden_dim2': 48, 'latent_dim': 10, 'learning_rate': 0.008752419205715938, 'batch_size': 16}. Best is trial 6 with value: 0.8031551837921143.\n",
      "[I 2024-11-25 09:23:23,958] Trial 75 finished with value: 0.8407146334648132 and parameters: {'hidden_dim1': 112, 'hidden_dim2': 48, 'latent_dim': 12, 'learning_rate': 0.00886730877386018, 'batch_size': 16}. Best is trial 6 with value: 0.8031551837921143.\n",
      "[I 2024-11-25 09:23:27,606] Trial 76 finished with value: 0.6872785687446594 and parameters: {'hidden_dim1': 128, 'hidden_dim2': 48, 'latent_dim': 10, 'learning_rate': 0.008866708901565701, 'batch_size': 16}. Best is trial 76 with value: 0.6872785687446594.\n",
      "[I 2024-11-25 09:23:31,109] Trial 77 finished with value: 0.9251627922058105 and parameters: {'hidden_dim1': 128, 'hidden_dim2': 48, 'latent_dim': 8, 'learning_rate': 0.00889264492082066, 'batch_size': 16}. Best is trial 76 with value: 0.6872785687446594.\n",
      "[I 2024-11-25 09:23:34,952] Trial 78 finished with value: 0.8358762264251709 and parameters: {'hidden_dim1': 128, 'hidden_dim2': 48, 'latent_dim': 12, 'learning_rate': 0.008005215274245647, 'batch_size': 16}. Best is trial 76 with value: 0.6872785687446594.\n",
      "[I 2024-11-25 09:23:38,515] Trial 79 finished with value: 0.9047176837921143 and parameters: {'hidden_dim1': 128, 'hidden_dim2': 48, 'latent_dim': 8, 'learning_rate': 0.007880791169175918, 'batch_size': 16}. Best is trial 76 with value: 0.6872785687446594.\n",
      "[I 2024-11-25 09:23:41,956] Trial 80 finished with value: 0.9469906687736511 and parameters: {'hidden_dim1': 128, 'hidden_dim2': 48, 'latent_dim': 2, 'learning_rate': 0.006363351322104865, 'batch_size': 16}. Best is trial 76 with value: 0.6872785687446594.\n",
      "[I 2024-11-25 09:23:45,546] Trial 81 finished with value: 0.9418624043464661 and parameters: {'hidden_dim1': 128, 'hidden_dim2': 48, 'latent_dim': 12, 'learning_rate': 0.008989337281827143, 'batch_size': 16}. Best is trial 76 with value: 0.6872785687446594.\n",
      "[I 2024-11-25 09:23:49,188] Trial 82 finished with value: 0.9177518486976624 and parameters: {'hidden_dim1': 128, 'hidden_dim2': 48, 'latent_dim': 12, 'learning_rate': 0.00896496142157922, 'batch_size': 16}. Best is trial 76 with value: 0.6872785687446594.\n",
      "[I 2024-11-25 09:23:52,688] Trial 83 finished with value: 0.8616226315498352 and parameters: {'hidden_dim1': 128, 'hidden_dim2': 48, 'latent_dim': 10, 'learning_rate': 0.009811530558889047, 'batch_size': 16}. Best is trial 76 with value: 0.6872785687446594.\n",
      "[I 2024-11-25 09:23:56,188] Trial 84 finished with value: 0.9000552296638489 and parameters: {'hidden_dim1': 32, 'hidden_dim2': 48, 'latent_dim': 10, 'learning_rate': 0.0072241191523100285, 'batch_size': 16}. Best is trial 76 with value: 0.6872785687446594.\n",
      "[I 2024-11-25 09:23:59,631] Trial 85 finished with value: 0.8964001536369324 and parameters: {'hidden_dim1': 128, 'hidden_dim2': 32, 'latent_dim': 12, 'learning_rate': 0.008385309854122022, 'batch_size': 16}. Best is trial 76 with value: 0.6872785687446594.\n",
      "[I 2024-11-25 09:24:03,503] Trial 86 finished with value: 0.9280481338500977 and parameters: {'hidden_dim1': 128, 'hidden_dim2': 48, 'latent_dim': 10, 'learning_rate': 0.007659927706532795, 'batch_size': 16}. Best is trial 76 with value: 0.6872785687446594.\n",
      "[I 2024-11-25 09:24:07,010] Trial 87 finished with value: 0.9427406787872314 and parameters: {'hidden_dim1': 112, 'hidden_dim2': 48, 'latent_dim': 12, 'learning_rate': 0.006541291876809526, 'batch_size': 16}. Best is trial 76 with value: 0.6872785687446594.\n",
      "[I 2024-11-25 09:24:10,538] Trial 88 finished with value: 0.8961361050605774 and parameters: {'hidden_dim1': 48, 'hidden_dim2': 32, 'latent_dim': 10, 'learning_rate': 0.005995599472726573, 'batch_size': 16}. Best is trial 76 with value: 0.6872785687446594.\n",
      "[I 2024-11-25 09:24:14,055] Trial 89 finished with value: 0.9994926452636719 and parameters: {'hidden_dim1': 112, 'hidden_dim2': 48, 'latent_dim': 12, 'learning_rate': 0.0002581469657776517, 'batch_size': 16}. Best is trial 76 with value: 0.6872785687446594.\n",
      "[I 2024-11-25 09:24:17,609] Trial 90 finished with value: 0.9506356120109558 and parameters: {'hidden_dim1': 128, 'hidden_dim2': 16, 'latent_dim': 14, 'learning_rate': 0.009117506987261952, 'batch_size': 16}. Best is trial 76 with value: 0.6872785687446594.\n",
      "[I 2024-11-25 09:24:21,434] Trial 91 finished with value: 0.9104046821594238 and parameters: {'hidden_dim1': 112, 'hidden_dim2': 48, 'latent_dim': 10, 'learning_rate': 0.004962213932569833, 'batch_size': 16}. Best is trial 76 with value: 0.6872785687446594.\n",
      "[I 2024-11-25 09:24:24,827] Trial 92 finished with value: 0.9021661877632141 and parameters: {'hidden_dim1': 112, 'hidden_dim2': 48, 'latent_dim': 10, 'learning_rate': 0.006989537999564038, 'batch_size': 16}. Best is trial 76 with value: 0.6872785687446594.\n",
      "[I 2024-11-25 09:24:28,034] Trial 93 finished with value: 0.9446079134941101 and parameters: {'hidden_dim1': 128, 'hidden_dim2': 48, 'latent_dim': 10, 'learning_rate': 0.004600572301380729, 'batch_size': 64}. Best is trial 76 with value: 0.6872785687446594.\n",
      "[I 2024-11-25 09:24:32,227] Trial 94 finished with value: 0.9225127100944519 and parameters: {'hidden_dim1': 112, 'hidden_dim2': 48, 'latent_dim': 10, 'learning_rate': 0.008185943986783644, 'batch_size': 16}. Best is trial 76 with value: 0.6872785687446594.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-25 09:24:36,130] Trial 95 finished with value: 0.9262568354606628 and parameters: {'hidden_dim1': 112, 'hidden_dim2': 32, 'latent_dim': 10, 'learning_rate': 0.005620652701484362, 'batch_size': 16}. Best is trial 76 with value: 0.6872785687446594.\n",
      "[I 2024-11-25 09:24:40,205] Trial 96 finished with value: 0.923095703125 and parameters: {'hidden_dim1': 80, 'hidden_dim2': 48, 'latent_dim': 12, 'learning_rate': 0.006474232494160238, 'batch_size': 16}. Best is trial 76 with value: 0.6872785687446594.\n",
      "[I 2024-11-25 09:24:43,847] Trial 97 finished with value: 0.9242623448371887 and parameters: {'hidden_dim1': 64, 'hidden_dim2': 32, 'latent_dim': 8, 'learning_rate': 0.00766530652218575, 'batch_size': 16}. Best is trial 76 with value: 0.6872785687446594.\n",
      "[I 2024-11-25 09:24:47,527] Trial 98 finished with value: 0.9156362414360046 and parameters: {'hidden_dim1': 128, 'hidden_dim2': 48, 'latent_dim': 10, 'learning_rate': 0.0042037299431782384, 'batch_size': 16}. Best is trial 76 with value: 0.6872785687446594.\n",
      "[I 2024-11-25 09:24:50,898] Trial 99 finished with value: 0.957460880279541 and parameters: {'hidden_dim1': 128, 'hidden_dim2': 48, 'latent_dim': 12, 'learning_rate': 0.0006780537596585076, 'batch_size': 16}. Best is trial 76 with value: 0.6872785687446594.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'hidden_dim1': 128, 'hidden_dim2': 48, 'latent_dim': 10, 'learning_rate': 0.008866708901565701, 'batch_size': 16}\n",
      "Epoch 1/100\n",
      "4/4 [==============================] - 1s 2ms/step - loss: 1.1361\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9846\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8906\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9150\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8904\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9082\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8718\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8803\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9740\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.8603\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9085\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9559\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8543\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8772\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8475\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8518\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8756\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8519\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9134\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.8274\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8849\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8699\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.9085\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8752\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.9051\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8313\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8828\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9148\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9084\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8487\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.8402\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9140\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8322\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8601\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8975\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9189\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8832\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9293\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8726\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8784\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8864\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8748\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8792\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8169\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8464\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8220\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9010\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8529\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8901\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8370\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9294\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8509\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8489\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8651\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8542\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8457\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9131\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.8693\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8436\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.8477\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9062\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.8161\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8534\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.7926\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8223\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.9067\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8946\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8786\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8827\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8013\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8437\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8945\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8229\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.8034\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.8619\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8347\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.7994\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8423\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.9217\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8966\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.8459\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.7973\n",
      "Epoch 83/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8419\n",
      "Epoch 84/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.9243\n",
      "Epoch 85/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8170\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8270\n",
      "Epoch 87/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9146\n",
      "Epoch 88/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.9019\n",
      "Epoch 89/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8864\n",
      "Epoch 90/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.8114\n",
      "Epoch 91/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8771\n",
      "Epoch 92/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8772\n",
      "Epoch 93/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.8301\n",
      "Epoch 94/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8669\n",
      "Epoch 95/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8449\n",
      "Epoch 96/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8680\n",
      "Epoch 97/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.8557\n",
      "Epoch 98/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.7969\n",
      "Epoch 99/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.9558\n",
      "Epoch 100/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8450\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 995us/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Final augmented data shape: (2500, 13)\n",
      "Augmented balanced data saved to /Users/Hsiao-ping.ni/ASU Dropbox/Hsiao-Ping Ni/PhD/Data/4th paper- Chiller/Diffusion_Imbalanced_Augmented_Chiller_Data.xlsx.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.keras.layers import Input, Dense, Layer\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.losses import mse\n",
    "import optuna\n",
    "\n",
    "# Load and preprocess the data\n",
    "data = pd.read_csv('/Users/Hsiao-ping.ni/ASU Dropbox/Hsiao-Ping Ni/PhD/Data/4th paper- Chiller/Diffusion_Anomaly_Detection_Results.csv', encoding='unicode_escape')\n",
    "#data = pd.read_csv('/Users/hsiaopingni/Desktop/Hsiao-Ping PhD/Data/paper- Chiller/Diffusion_Anomaly_Detection_Results.csv', encoding='unicode_escape')\n",
    "data = data[['ï»¿Discharge Temp (F)', 'Input % full load amps (Motor) (%)', 'Condenser liq temp IN (F)',\n",
    "             'Condenser liq temp OUT (F)', 'Chilled liq temp IN (F)', 'Chilled liq temp OUT (F)',\n",
    "             'Condenser saturation (F)', 'Evaporator saturation (F)', 'Evaporator pressure (PSIG)',\n",
    "             'Condenser pressure (PSIG)', 'Oil sump temp (F)', 'Oil pressure (PSIG)', 'Anomaly']]\n",
    "\n",
    "# Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "data_scaled = scaler.fit_transform(data.drop(columns=['Anomaly']))  # Normalize only the features\n",
    "\n",
    "# Separate anomalies and normal data\n",
    "anomalies = data[data['Anomaly'] == 1]  # Assuming '1' is the label for anomalies\n",
    "normal_data = data[data['Anomaly'] == 0]  # Assuming '0' is the label for normal data\n",
    "\n",
    "# Normalize the data separately for anomalies and normal data\n",
    "anomalies_scaled = scaler.transform(anomalies.drop(columns=['Anomaly']))\n",
    "normal_data_scaled = scaler.transform(normal_data.drop(columns=['Anomaly']))\n",
    "\n",
    "# Define the Sampling layer for VAE\n",
    "class Sampling(Layer):\n",
    "    def call(self, inputs):\n",
    "        mean, log_var = inputs\n",
    "        batch = tf.shape(mean)[0]\n",
    "        dim = tf.shape(mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return mean + tf.exp(0.5 * log_var) * epsilon\n",
    "\n",
    "# Define VAE architecture\n",
    "def build_vae(input_dim, hidden_dims, latent_dim):\n",
    "    # Encoder\n",
    "    inputs = Input(shape=(input_dim,))\n",
    "    x = inputs\n",
    "    for dim in hidden_dims:\n",
    "        x = Dense(dim, activation='relu')(x)\n",
    "    mean = Dense(latent_dim)(x)\n",
    "    log_var = Dense(latent_dim)(x)\n",
    "    z = Sampling()([mean, log_var])\n",
    "    encoder = Model(inputs, [mean, log_var, z], name=\"encoder\")\n",
    "    \n",
    "    # Decoder\n",
    "    latent_inputs = Input(shape=(latent_dim,))\n",
    "    x = latent_inputs\n",
    "    for dim in reversed(hidden_dims):\n",
    "        x = Dense(dim, activation='relu')(x)\n",
    "    outputs = Dense(input_dim, activation='sigmoid')(x)\n",
    "    decoder = Model(latent_inputs, outputs, name=\"decoder\")\n",
    "    \n",
    "    # VAE Model\n",
    "    reconstructed = decoder(encoder(inputs)[2])\n",
    "    vae = Model(inputs, reconstructed, name=\"vae\")\n",
    "    \n",
    "    # VAE Loss\n",
    "    reconstruction_loss = mse(inputs, reconstructed) * input_dim\n",
    "    kl_loss = 1 + log_var - tf.square(mean) - tf.exp(log_var)\n",
    "    kl_loss = tf.reduce_sum(kl_loss, axis=-1)\n",
    "    kl_loss *= -0.5\n",
    "    vae_loss = tf.reduce_mean(reconstruction_loss + kl_loss)\n",
    "    vae.add_loss(vae_loss)\n",
    "    \n",
    "    return vae, encoder, decoder\n",
    "\n",
    "# Define the objective function for Optuna\n",
    "def objective(trial):\n",
    "    # Suggest hyperparameters using TPE\n",
    "    hidden_dim1 = trial.suggest_int('hidden_dim1', 32, 128, step=16)\n",
    "    hidden_dim2 = trial.suggest_int('hidden_dim2', 16, 64, step=16)\n",
    "    latent_dim = trial.suggest_int('latent_dim', 2, 16, step=2)\n",
    "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
    "    batch_size = trial.suggest_int('batch_size', 16, 64, step=16)\n",
    "    \n",
    "    hidden_dims = [hidden_dim1, hidden_dim2]\n",
    "    \n",
    "    # Split data into training and validation sets\n",
    "    X_train, X_val = train_test_split(data_scaled, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Train the VAE using training and validation data\n",
    "    vae, encoder, decoder = build_vae(input_dim=data_scaled.shape[1], hidden_dims=hidden_dims, latent_dim=latent_dim)\n",
    "    vae.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate))\n",
    "    history = vae.fit(X_train, X_train, validation_data=(X_val, X_val), epochs=100, batch_size=batch_size, verbose=0)\n",
    "    \n",
    "    # Access 'val_loss' after adding validation data\n",
    "    val_loss = min(history.history['val_loss'])\n",
    "    return val_loss\n",
    "\n",
    "# Run Optuna study using TPE\n",
    "study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler())\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "# Get the best hyperparameters from Optuna\n",
    "best_params = study.best_params\n",
    "print(\"Best hyperparameters:\", best_params)\n",
    "\n",
    "# Train the final VAE using the best hyperparameters\n",
    "hidden_dims = [best_params['hidden_dim1'], best_params['hidden_dim2']]\n",
    "latent_dim = best_params['latent_dim']\n",
    "learning_rate = best_params['learning_rate']\n",
    "batch_size = best_params['batch_size']\n",
    "\n",
    "vae, encoder, decoder = build_vae(input_dim=data_scaled.shape[1], hidden_dims=hidden_dims, latent_dim=latent_dim)\n",
    "vae.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate))\n",
    "history = vae.fit(data_scaled, data_scaled, epochs=100, batch_size=batch_size, verbose=1)\n",
    "\n",
    "# Augment the normal data (generate 2000 normal samples)\n",
    "desired_normal_size = 2000\n",
    "augmented_normal_data_list = []\n",
    "while len(augmented_normal_data_list) < desired_normal_size:\n",
    "    new_samples = vae.predict(normal_data_scaled)\n",
    "    augmented_normal_data_list.extend(new_samples)\n",
    "\n",
    "augmented_normal_data = pd.DataFrame(augmented_normal_data_list[:desired_normal_size], columns=normal_data.columns[:-1])\n",
    "augmented_normal_data['label_column'] = 0  # Label for normal data\n",
    "\n",
    "# Augment the anomalies (generate 500 anomaly samples)\n",
    "desired_anomaly_size = 500\n",
    "augmented_anomaly_data_list = []\n",
    "while len(augmented_anomaly_data_list) < desired_anomaly_size:\n",
    "    new_samples = vae.predict(anomalies_scaled)\n",
    "    augmented_anomaly_data_list.extend(new_samples)\n",
    "\n",
    "augmented_anomaly_data = pd.DataFrame(augmented_anomaly_data_list[:desired_anomaly_size], columns=anomalies.columns[:-1])\n",
    "augmented_anomaly_data['label_column'] = 1  # Label for anomalies\n",
    "\n",
    "# Combine the augmented data and the original data\n",
    "augmented_data = pd.concat([augmented_normal_data, augmented_anomaly_data], axis=0)\n",
    "\n",
    "# Shuffle the augmented data\n",
    "augmented_data = shuffle(augmented_data, random_state=42)\n",
    "\n",
    "# Check final shape of the augmented dataset\n",
    "print(f\"Final augmented data shape: {augmented_data.shape}\")\n",
    "\n",
    "# Save the augmented data to an Excel file\n",
    "output_path = '/Users/Hsiao-ping.ni/ASU Dropbox/Hsiao-Ping Ni/PhD/Data/4th paper- Chiller/Diffusion_Imbalanced_Augmented_Chiller_Data.xlsx'\n",
    "#output_path = '/Users/hsiaopingni/Desktop/Diffusion_Imbalanced_Augmented_Chiller_Data.xlsx'\n",
    "augmented_data.to_excel(output_path, index=False)\n",
    "print(f\"Augmented balanced data saved to {output_path}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ad82391",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ks_2samp\n",
    "\n",
    "# Calculate mean and standard deviation for each parameter\n",
    "original_stats = data.describe().loc[['mean', 'std']]\n",
    "augmented_stats = augmented_data.describe().loc[['mean', 'std']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e89ed269",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ï»¿Discharge Temp (F)</th>\n",
       "      <th>Input % full load amps (Motor) (%)</th>\n",
       "      <th>Condenser liq temp IN (F)</th>\n",
       "      <th>Condenser liq temp OUT (F)</th>\n",
       "      <th>Chilled liq temp IN (F)</th>\n",
       "      <th>Chilled liq temp OUT (F)</th>\n",
       "      <th>Condenser saturation (F)</th>\n",
       "      <th>Evaporator saturation (F)</th>\n",
       "      <th>Evaporator pressure (PSIG)</th>\n",
       "      <th>Condenser pressure (PSIG)</th>\n",
       "      <th>Oil sump temp (F)</th>\n",
       "      <th>Oil pressure (PSIG)</th>\n",
       "      <th>Anomaly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>102.970000</td>\n",
       "      <td>50.900000</td>\n",
       "      <td>77.975000</td>\n",
       "      <td>83.655000</td>\n",
       "      <td>47.320000</td>\n",
       "      <td>40.513333</td>\n",
       "      <td>83.876667</td>\n",
       "      <td>39.725000</td>\n",
       "      <td>34.775000</td>\n",
       "      <td>93.911667</td>\n",
       "      <td>131.076667</td>\n",
       "      <td>35.027667</td>\n",
       "      <td>0.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.529731</td>\n",
       "      <td>7.772594</td>\n",
       "      <td>7.268335</td>\n",
       "      <td>7.399116</td>\n",
       "      <td>1.284167</td>\n",
       "      <td>0.076947</td>\n",
       "      <td>7.777899</td>\n",
       "      <td>0.287376</td>\n",
       "      <td>0.272232</td>\n",
       "      <td>14.149553</td>\n",
       "      <td>1.876561</td>\n",
       "      <td>0.421637</td>\n",
       "      <td>0.219784</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ï»¿Discharge Temp (F)  Input % full load amps (Motor) (%)  \\\n",
       "mean             102.970000                           50.900000   \n",
       "std                6.529731                            7.772594   \n",
       "\n",
       "      Condenser liq temp IN (F)  Condenser liq temp OUT (F)  \\\n",
       "mean                  77.975000                   83.655000   \n",
       "std                    7.268335                    7.399116   \n",
       "\n",
       "      Chilled liq temp IN (F)  Chilled liq temp OUT (F)  \\\n",
       "mean                47.320000                 40.513333   \n",
       "std                  1.284167                  0.076947   \n",
       "\n",
       "      Condenser saturation (F)  Evaporator saturation (F)  \\\n",
       "mean                 83.876667                  39.725000   \n",
       "std                   7.777899                   0.287376   \n",
       "\n",
       "      Evaporator pressure (PSIG)  Condenser pressure (PSIG)  \\\n",
       "mean                   34.775000                  93.911667   \n",
       "std                     0.272232                  14.149553   \n",
       "\n",
       "      Oil sump temp (F)  Oil pressure (PSIG)   Anomaly  \n",
       "mean         131.076667            35.027667  0.050000  \n",
       "std            1.876561             0.421637  0.219784  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91df2f04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ï»¿Discharge Temp (F)</th>\n",
       "      <th>Input % full load amps (Motor) (%)</th>\n",
       "      <th>Condenser liq temp IN (F)</th>\n",
       "      <th>Condenser liq temp OUT (F)</th>\n",
       "      <th>Chilled liq temp IN (F)</th>\n",
       "      <th>Chilled liq temp OUT (F)</th>\n",
       "      <th>Condenser saturation (F)</th>\n",
       "      <th>Evaporator saturation (F)</th>\n",
       "      <th>Evaporator pressure (PSIG)</th>\n",
       "      <th>Condenser pressure (PSIG)</th>\n",
       "      <th>Oil sump temp (F)</th>\n",
       "      <th>Oil pressure (PSIG)</th>\n",
       "      <th>label_column</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.287288</td>\n",
       "      <td>0.386616</td>\n",
       "      <td>0.315057</td>\n",
       "      <td>0.348286</td>\n",
       "      <td>0.683933</td>\n",
       "      <td>0.375610</td>\n",
       "      <td>0.376395</td>\n",
       "      <td>0.608584</td>\n",
       "      <td>0.618676</td>\n",
       "      <td>0.355833</td>\n",
       "      <td>0.549466</td>\n",
       "      <td>0.497163</td>\n",
       "      <td>0.20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.105049</td>\n",
       "      <td>0.028895</td>\n",
       "      <td>0.098183</td>\n",
       "      <td>0.096757</td>\n",
       "      <td>0.015667</td>\n",
       "      <td>0.014256</td>\n",
       "      <td>0.090175</td>\n",
       "      <td>0.024745</td>\n",
       "      <td>0.027693</td>\n",
       "      <td>0.093061</td>\n",
       "      <td>0.028772</td>\n",
       "      <td>0.010989</td>\n",
       "      <td>0.40008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ï»¿Discharge Temp (F)  Input % full load amps (Motor) (%)  \\\n",
       "mean               0.287288                            0.386616   \n",
       "std                0.105049                            0.028895   \n",
       "\n",
       "      Condenser liq temp IN (F)  Condenser liq temp OUT (F)  \\\n",
       "mean                   0.315057                    0.348286   \n",
       "std                    0.098183                    0.096757   \n",
       "\n",
       "      Chilled liq temp IN (F)  Chilled liq temp OUT (F)  \\\n",
       "mean                 0.683933                  0.375610   \n",
       "std                  0.015667                  0.014256   \n",
       "\n",
       "      Condenser saturation (F)  Evaporator saturation (F)  \\\n",
       "mean                  0.376395                   0.608584   \n",
       "std                   0.090175                   0.024745   \n",
       "\n",
       "      Evaporator pressure (PSIG)  Condenser pressure (PSIG)  \\\n",
       "mean                    0.618676                   0.355833   \n",
       "std                     0.027693                   0.093061   \n",
       "\n",
       "      Oil sump temp (F)  Oil pressure (PSIG)  label_column  \n",
       "mean           0.549466             0.497163       0.20000  \n",
       "std            0.028772             0.010989       0.40008  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmented_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f927df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
