{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2449187",
   "metadata": {},
   "source": [
    "# Regression with Deep Neural Network (DNN)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf46af2",
   "metadata": {},
   "source": [
    "In a regression problem, the aim is to predict the output of a continuous value, like a energy consumption, a temperature value or a probability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b62a5c",
   "metadata": {},
   "source": [
    "This file demonstrates how to build models to predict the energy efficiency of the MAU system. To do this, you will provide the models with a description of many MAUs from that a certain period. This description includes attributes like temperature, humidity, airflow, and enthalpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "757b6769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use seaborn for pairplot.\n",
    "!pip install -q seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bcc84e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Make NumPy printouts easier to read.\n",
    "np.set_printoptions(precision=3, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04780b27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.12.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58eaa09e",
   "metadata": {},
   "source": [
    "## Load all MAU entrance data (1700 counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd298cf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ï»¿Date</th>\n",
       "      <th>Temperature (Â°F)</th>\n",
       "      <th>Humidity (%)</th>\n",
       "      <th>Density (g/m3)</th>\n",
       "      <th>Enthalpy, h (kJ/kg)</th>\n",
       "      <th>x (g/kg)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22-Feb-24</td>\n",
       "      <td>73.990</td>\n",
       "      <td>31.99</td>\n",
       "      <td>6.702413</td>\n",
       "      <td>38.115265</td>\n",
       "      <td>5.559379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22-Feb-24</td>\n",
       "      <td>87.400</td>\n",
       "      <td>20.51</td>\n",
       "      <td>6.544377</td>\n",
       "      <td>45.499387</td>\n",
       "      <td>5.685505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22-Feb-24</td>\n",
       "      <td>88.410</td>\n",
       "      <td>20.05</td>\n",
       "      <td>6.557303</td>\n",
       "      <td>46.266794</td>\n",
       "      <td>5.741044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22-Feb-24</td>\n",
       "      <td>87.370</td>\n",
       "      <td>20.35</td>\n",
       "      <td>6.375138</td>\n",
       "      <td>45.395059</td>\n",
       "      <td>5.621946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22-Feb-24</td>\n",
       "      <td>87.330</td>\n",
       "      <td>20.63</td>\n",
       "      <td>6.542479</td>\n",
       "      <td>45.638374</td>\n",
       "      <td>5.729283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1695</th>\n",
       "      <td>4-Apr-24</td>\n",
       "      <td>90.770</td>\n",
       "      <td>7.00</td>\n",
       "      <td>2.423557</td>\n",
       "      <td>38.439054</td>\n",
       "      <td>2.133134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1696</th>\n",
       "      <td>4-Apr-24</td>\n",
       "      <td>90.734</td>\n",
       "      <td>7.57</td>\n",
       "      <td>2.704262</td>\n",
       "      <td>38.739736</td>\n",
       "      <td>2.209288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1697</th>\n",
       "      <td>4-Apr-24</td>\n",
       "      <td>88.988</td>\n",
       "      <td>7.97</td>\n",
       "      <td>2.686313</td>\n",
       "      <td>37.939121</td>\n",
       "      <td>2.276854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1698</th>\n",
       "      <td>4-Apr-24</td>\n",
       "      <td>90.194</td>\n",
       "      <td>7.64</td>\n",
       "      <td>2.681059</td>\n",
       "      <td>38.888463</td>\n",
       "      <td>2.256234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1699</th>\n",
       "      <td>4-Apr-24</td>\n",
       "      <td>86.720</td>\n",
       "      <td>7.95</td>\n",
       "      <td>2.370964</td>\n",
       "      <td>36.105389</td>\n",
       "      <td>2.130334</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1700 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ï»¿Date  Temperature (Â°F)  Humidity (%)  Density (g/m3)  \\\n",
       "0     22-Feb-24             73.990         31.99        6.702413   \n",
       "1     22-Feb-24             87.400         20.51        6.544377   \n",
       "2     22-Feb-24             88.410         20.05        6.557303   \n",
       "3     22-Feb-24             87.370         20.35        6.375138   \n",
       "4     22-Feb-24             87.330         20.63        6.542479   \n",
       "...         ...                ...           ...             ...   \n",
       "1695   4-Apr-24             90.770          7.00        2.423557   \n",
       "1696   4-Apr-24             90.734          7.57        2.704262   \n",
       "1697   4-Apr-24             88.988          7.97        2.686313   \n",
       "1698   4-Apr-24             90.194          7.64        2.681059   \n",
       "1699   4-Apr-24             86.720          7.95        2.370964   \n",
       "\n",
       "      Enthalpy, h (kJ/kg)  x (g/kg)  \n",
       "0               38.115265  5.559379  \n",
       "1               45.499387  5.685505  \n",
       "2               46.266794  5.741044  \n",
       "3               45.395059  5.621946  \n",
       "4               45.638374  5.729283  \n",
       "...                   ...       ...  \n",
       "1695            38.439054  2.133134  \n",
       "1696            38.739736  2.209288  \n",
       "1697            37.939121  2.276854  \n",
       "1698            38.888463  2.256234  \n",
       "1699            36.105389  2.130334  \n",
       "\n",
       "[1700 rows x 6 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load entrance data\n",
    "data_entrance = pd.read_csv('/Users/hsiaopingni/Desktop/Hsiao-Ping PhD/Data/MAU_paper/random_noise_data_entrance_1700.csv', encoding='unicode_escape')\n",
    "#data_entrance=pd.read_csv(r'C:\\Users\\Hsiao-ping.ni\\ASU Dropbox\\Hsiao-Ping Ni\\PhD\\Data\\3rd paper- MAU\\random_noise_data_entrance_1700.csv', encoding='unicode_escape')\n",
    "#data_entrance=pd.read_csv(r'C:\\Users\\nick8\\ASU Dropbox\\Hsiao-Ping Ni\\PhD\\Data\\3rd paper- MAU\\random_noise_data_entrance_1700.csv', encoding='unicode_escape')\n",
    "data_entrance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80c1e7b",
   "metadata": {},
   "source": [
    "## Load all MAU exit data (1700 counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6f18855",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ï»¿Date</th>\n",
       "      <th>Temperature (Â°F)</th>\n",
       "      <th>Humidity (%)</th>\n",
       "      <th>Density (g/m^3)</th>\n",
       "      <th>Enthalpy, h (kJ/kg)</th>\n",
       "      <th>x (g/kg)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22-Feb-24</td>\n",
       "      <td>75.038</td>\n",
       "      <td>38.79</td>\n",
       "      <td>8.374574</td>\n",
       "      <td>42.415875</td>\n",
       "      <td>7.166912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22-Feb-24</td>\n",
       "      <td>74.984</td>\n",
       "      <td>38.16</td>\n",
       "      <td>8.239896</td>\n",
       "      <td>42.119254</td>\n",
       "      <td>6.983385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22-Feb-24</td>\n",
       "      <td>75.092</td>\n",
       "      <td>39.94</td>\n",
       "      <td>8.658678</td>\n",
       "      <td>43.006037</td>\n",
       "      <td>7.411021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22-Feb-24</td>\n",
       "      <td>75.020</td>\n",
       "      <td>39.08</td>\n",
       "      <td>8.453469</td>\n",
       "      <td>42.499437</td>\n",
       "      <td>2.181991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22-Feb-24</td>\n",
       "      <td>75.038</td>\n",
       "      <td>38.89</td>\n",
       "      <td>8.459624</td>\n",
       "      <td>42.490894</td>\n",
       "      <td>7.221786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1695</th>\n",
       "      <td>4-Apr-24</td>\n",
       "      <td>75.074</td>\n",
       "      <td>38.43</td>\n",
       "      <td>8.296299</td>\n",
       "      <td>42.284681</td>\n",
       "      <td>7.071466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1696</th>\n",
       "      <td>4-Apr-24</td>\n",
       "      <td>75.146</td>\n",
       "      <td>39.14</td>\n",
       "      <td>8.555746</td>\n",
       "      <td>42.633912</td>\n",
       "      <td>7.346817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1697</th>\n",
       "      <td>4-Apr-24</td>\n",
       "      <td>75.074</td>\n",
       "      <td>42.52</td>\n",
       "      <td>8.509596</td>\n",
       "      <td>42.566891</td>\n",
       "      <td>7.177446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1698</th>\n",
       "      <td>4-Apr-24</td>\n",
       "      <td>75.146</td>\n",
       "      <td>38.07</td>\n",
       "      <td>8.359937</td>\n",
       "      <td>42.185792</td>\n",
       "      <td>6.955636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1699</th>\n",
       "      <td>4-Apr-24</td>\n",
       "      <td>75.182</td>\n",
       "      <td>39.89</td>\n",
       "      <td>8.661061</td>\n",
       "      <td>43.083376</td>\n",
       "      <td>7.525113</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1700 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ï»¿Date  Temperature (Â°F)  Humidity (%)  Density (g/m^3)  \\\n",
       "0     22-Feb-24             75.038         38.79         8.374574   \n",
       "1     22-Feb-24             74.984         38.16         8.239896   \n",
       "2     22-Feb-24             75.092         39.94         8.658678   \n",
       "3     22-Feb-24             75.020         39.08         8.453469   \n",
       "4     22-Feb-24             75.038         38.89         8.459624   \n",
       "...         ...                ...           ...              ...   \n",
       "1695   4-Apr-24             75.074         38.43         8.296299   \n",
       "1696   4-Apr-24             75.146         39.14         8.555746   \n",
       "1697   4-Apr-24             75.074         42.52         8.509596   \n",
       "1698   4-Apr-24             75.146         38.07         8.359937   \n",
       "1699   4-Apr-24             75.182         39.89         8.661061   \n",
       "\n",
       "      Enthalpy, h (kJ/kg)  x (g/kg)  \n",
       "0               42.415875  7.166912  \n",
       "1               42.119254  6.983385  \n",
       "2               43.006037  7.411021  \n",
       "3               42.499437  2.181991  \n",
       "4               42.490894  7.221786  \n",
       "...                   ...       ...  \n",
       "1695            42.284681  7.071466  \n",
       "1696            42.633912  7.346817  \n",
       "1697            42.566891  7.177446  \n",
       "1698            42.185792  6.955636  \n",
       "1699            43.083376  7.525113  \n",
       "\n",
       "[1700 rows x 6 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load exit data\n",
    "data_exit = pd.read_csv('/Users/hsiaopingni/Desktop/Hsiao-Ping PhD/Data/MAU_paper/random_noise_data_exit_1700.csv', encoding='unicode_escape')\n",
    "#data_exit=pd.read_csv(r'C:\\Users\\Hsiao-ping.ni\\ASU Dropbox\\Hsiao-Ping Ni\\PhD\\Data\\3rd paper- MAU\\random_noise_data_exit_1700.csv', encoding='unicode_escape')\n",
    "#data_exit=pd.read_csv(r'C:\\Users\\nick8\\ASU Dropbox\\Hsiao-Ping Ni\\PhD\\Data\\3rd paper- MAU\\random_noise_data_exit_1700.csv', encoding='unicode_escape')\n",
    "data_exit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4941ff",
   "metadata": {},
   "source": [
    "## Split the data into training and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926f127a",
   "metadata": {},
   "source": [
    "Now, split the dataset into a training set and a test set. You will use the test set in the final evaluation of your model.\n",
    "\n",
    "The line of code \"train_dataset = dataset.sample(frac=0.8, random_state=0)\" creates a training dataset by randomly selecting 80% of the rows from the dataset, ensuring that the selection is reproducible by setting a random state. The frac=0.8 parameter specifies that 80% of the data should be sampled, and random_state=0 ensures that the random selection of rows is consistent every time the code is run, facilitating reproducible results in experiments or analyses.\n",
    "\n",
    "The line \"test_dataset = dataset.drop(train_dataset.index)\" removes all rows from dataset that are already included in train_dataset, effectively creating a test dataset. This is achieved by dropping rows indexed in train_dataset.index from the original dataset. The result is a dataset containing 20% of the original data, not selected for training, used for testing model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0899dde3",
   "metadata": {},
   "source": [
    "### Train datasets for MAU entrance (1360 counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909af274",
   "metadata": {},
   "source": [
    "Drop 'Count' and 'Which MAU' columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3ae9f3e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature (Â°F)</th>\n",
       "      <th>Humidity (%)</th>\n",
       "      <th>Density (g/m3)</th>\n",
       "      <th>Enthalpy, h (kJ/kg)</th>\n",
       "      <th>x (g/kg)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>90.194</td>\n",
       "      <td>7.64</td>\n",
       "      <td>2.690796</td>\n",
       "      <td>38.729669</td>\n",
       "      <td>2.381493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>80.780</td>\n",
       "      <td>22.35</td>\n",
       "      <td>5.820378</td>\n",
       "      <td>40.131530</td>\n",
       "      <td>4.981644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>90.770</td>\n",
       "      <td>7.00</td>\n",
       "      <td>2.519978</td>\n",
       "      <td>38.301343</td>\n",
       "      <td>2.105956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1229</th>\n",
       "      <td>75.540</td>\n",
       "      <td>29.08</td>\n",
       "      <td>6.490289</td>\n",
       "      <td>38.374865</td>\n",
       "      <td>5.469321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654</th>\n",
       "      <td>85.660</td>\n",
       "      <td>14.32</td>\n",
       "      <td>4.332828</td>\n",
       "      <td>39.808657</td>\n",
       "      <td>3.644525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>87.400</td>\n",
       "      <td>20.51</td>\n",
       "      <td>6.495102</td>\n",
       "      <td>45.562149</td>\n",
       "      <td>5.722994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>87.400</td>\n",
       "      <td>20.51</td>\n",
       "      <td>6.577599</td>\n",
       "      <td>45.580326</td>\n",
       "      <td>5.726651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832</th>\n",
       "      <td>86.720</td>\n",
       "      <td>7.95</td>\n",
       "      <td>2.372378</td>\n",
       "      <td>36.182355</td>\n",
       "      <td>2.059846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>951</th>\n",
       "      <td>86.720</td>\n",
       "      <td>7.95</td>\n",
       "      <td>2.493572</td>\n",
       "      <td>36.132664</td>\n",
       "      <td>2.117976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1144</th>\n",
       "      <td>75.540</td>\n",
       "      <td>29.08</td>\n",
       "      <td>6.409704</td>\n",
       "      <td>38.223150</td>\n",
       "      <td>5.414350</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1360 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Temperature (Â°F)  Humidity (%)  Density (g/m3)  Enthalpy, h (kJ/kg)  \\\n",
       "678              90.194          7.64        2.690796            38.729669   \n",
       "6                80.780         22.35        5.820378            40.131530   \n",
       "182              90.770          7.00        2.519978            38.301343   \n",
       "1229             75.540         29.08        6.490289            38.374865   \n",
       "654              85.660         14.32        4.332828            39.808657   \n",
       "...                 ...           ...             ...                  ...   \n",
       "732              87.400         20.51        6.495102            45.562149   \n",
       "715              87.400         20.51        6.577599            45.580326   \n",
       "832              86.720          7.95        2.372378            36.182355   \n",
       "951              86.720          7.95        2.493572            36.132664   \n",
       "1144             75.540         29.08        6.409704            38.223150   \n",
       "\n",
       "      x (g/kg)  \n",
       "678   2.381493  \n",
       "6     4.981644  \n",
       "182   2.105956  \n",
       "1229  5.469321  \n",
       "654   3.644525  \n",
       "...        ...  \n",
       "732   5.722994  \n",
       "715   5.726651  \n",
       "832   2.059846  \n",
       "951   2.117976  \n",
       "1144  5.414350  \n",
       "\n",
       "[1360 rows x 5 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_entrance = data_entrance.drop(['ï»¿Date'], axis=1)\n",
    "train_dataset_entrance = data_entrance.sample(frac=0.8, random_state=0)\n",
    "test_dataset_entrance = data_entrance.drop(train_dataset_entrance.index)\n",
    "train_dataset_entrance\n",
    "\n",
    "# Spliting data into Feature \n",
    "#X=data[['Humidity (%)','Airflow (g/m^3)','Enthalpy, h (kJ/kg)','x (g/kg)']]\n",
    "#y=data['Temperature (°F)']\n",
    "\n",
    "# Import train_test_split function\n",
    "#from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split dataset into training set and test (validation) set\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)  # 80% training and 20% test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f4ed3e",
   "metadata": {},
   "source": [
    "### Test datasets for MAU entrance (340 counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "94c5ded8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature (Â°F)</th>\n",
       "      <th>Humidity (%)</th>\n",
       "      <th>Density (g/m3)</th>\n",
       "      <th>Enthalpy, h (kJ/kg)</th>\n",
       "      <th>x (g/kg)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>78.57</td>\n",
       "      <td>26.62</td>\n",
       "      <td>6.464909</td>\n",
       "      <td>40.252792</td>\n",
       "      <td>3.837001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>80.78</td>\n",
       "      <td>22.35</td>\n",
       "      <td>5.744959</td>\n",
       "      <td>40.173020</td>\n",
       "      <td>4.886453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>87.76</td>\n",
       "      <td>12.46</td>\n",
       "      <td>4.021235</td>\n",
       "      <td>40.352206</td>\n",
       "      <td>3.496527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>85.66</td>\n",
       "      <td>14.32</td>\n",
       "      <td>4.443511</td>\n",
       "      <td>39.904371</td>\n",
       "      <td>3.683571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>78.57</td>\n",
       "      <td>26.62</td>\n",
       "      <td>6.403753</td>\n",
       "      <td>40.250647</td>\n",
       "      <td>3.839436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1660</th>\n",
       "      <td>78.57</td>\n",
       "      <td>26.62</td>\n",
       "      <td>6.410665</td>\n",
       "      <td>40.247850</td>\n",
       "      <td>3.911928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1671</th>\n",
       "      <td>75.54</td>\n",
       "      <td>29.08</td>\n",
       "      <td>6.483653</td>\n",
       "      <td>38.307150</td>\n",
       "      <td>5.490089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1674</th>\n",
       "      <td>85.66</td>\n",
       "      <td>14.32</td>\n",
       "      <td>4.370929</td>\n",
       "      <td>39.763514</td>\n",
       "      <td>3.757167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1684</th>\n",
       "      <td>87.40</td>\n",
       "      <td>20.51</td>\n",
       "      <td>6.468397</td>\n",
       "      <td>45.507832</td>\n",
       "      <td>5.584946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1694</th>\n",
       "      <td>78.57</td>\n",
       "      <td>26.62</td>\n",
       "      <td>6.456255</td>\n",
       "      <td>40.173394</td>\n",
       "      <td>3.851134</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>340 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Temperature (Â°F)  Humidity (%)  Density (g/m3)  Enthalpy, h (kJ/kg)  \\\n",
       "11                78.57         26.62        6.464909            40.252792   \n",
       "23                80.78         22.35        5.744959            40.173020   \n",
       "24                87.76         12.46        4.021235            40.352206   \n",
       "25                85.66         14.32        4.443511            39.904371   \n",
       "28                78.57         26.62        6.403753            40.250647   \n",
       "...                 ...           ...             ...                  ...   \n",
       "1660              78.57         26.62        6.410665            40.247850   \n",
       "1671              75.54         29.08        6.483653            38.307150   \n",
       "1674              85.66         14.32        4.370929            39.763514   \n",
       "1684              87.40         20.51        6.468397            45.507832   \n",
       "1694              78.57         26.62        6.456255            40.173394   \n",
       "\n",
       "      x (g/kg)  \n",
       "11    3.837001  \n",
       "23    4.886453  \n",
       "24    3.496527  \n",
       "25    3.683571  \n",
       "28    3.839436  \n",
       "...        ...  \n",
       "1660  3.911928  \n",
       "1671  5.490089  \n",
       "1674  3.757167  \n",
       "1684  5.584946  \n",
       "1694  3.851134  \n",
       "\n",
       "[340 rows x 5 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset_entrance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da96491a",
   "metadata": {},
   "source": [
    "### Load original entrance data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c4b11db2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "      <th>Which MAU</th>\n",
       "      <th>Temperature (°F)</th>\n",
       "      <th>Humidity (%)</th>\n",
       "      <th>Density (g/m^3)</th>\n",
       "      <th>Enthalpy, h (kJ/kg)</th>\n",
       "      <th>x (g/kg)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>73.990</td>\n",
       "      <td>31.99</td>\n",
       "      <td>6.73</td>\n",
       "      <td>38.08</td>\n",
       "      <td>5.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>87.400</td>\n",
       "      <td>20.51</td>\n",
       "      <td>6.51</td>\n",
       "      <td>45.55</td>\n",
       "      <td>5.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>88.410</td>\n",
       "      <td>20.05</td>\n",
       "      <td>6.59</td>\n",
       "      <td>46.29</td>\n",
       "      <td>5.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>87.370</td>\n",
       "      <td>20.35</td>\n",
       "      <td>6.45</td>\n",
       "      <td>45.39</td>\n",
       "      <td>5.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>87.330</td>\n",
       "      <td>20.63</td>\n",
       "      <td>6.51</td>\n",
       "      <td>45.59</td>\n",
       "      <td>5.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>75.540</td>\n",
       "      <td>29.08</td>\n",
       "      <td>6.44</td>\n",
       "      <td>38.33</td>\n",
       "      <td>5.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>80.780</td>\n",
       "      <td>22.35</td>\n",
       "      <td>5.81</td>\n",
       "      <td>40.09</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>87.760</td>\n",
       "      <td>12.46</td>\n",
       "      <td>3.97</td>\n",
       "      <td>40.32</td>\n",
       "      <td>3.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>85.660</td>\n",
       "      <td>14.32</td>\n",
       "      <td>4.39</td>\n",
       "      <td>39.87</td>\n",
       "      <td>3.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>89.650</td>\n",
       "      <td>13.09</td>\n",
       "      <td>4.42</td>\n",
       "      <td>42.21</td>\n",
       "      <td>3.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>88.720</td>\n",
       "      <td>13.32</td>\n",
       "      <td>4.37</td>\n",
       "      <td>41.51</td>\n",
       "      <td>3.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>78.570</td>\n",
       "      <td>26.62</td>\n",
       "      <td>6.44</td>\n",
       "      <td>40.20</td>\n",
       "      <td>3.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>90.770</td>\n",
       "      <td>7.00</td>\n",
       "      <td>2.42</td>\n",
       "      <td>38.36</td>\n",
       "      <td>2.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>90.734</td>\n",
       "      <td>7.57</td>\n",
       "      <td>2.63</td>\n",
       "      <td>38.76</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>88.988</td>\n",
       "      <td>7.97</td>\n",
       "      <td>2.71</td>\n",
       "      <td>38.04</td>\n",
       "      <td>2.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>90.194</td>\n",
       "      <td>7.64</td>\n",
       "      <td>2.76</td>\n",
       "      <td>38.77</td>\n",
       "      <td>2.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>86.720</td>\n",
       "      <td>7.95</td>\n",
       "      <td>2.44</td>\n",
       "      <td>36.15</td>\n",
       "      <td>2.12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Count  Which MAU  Temperature (°F)  Humidity (%)  Density (g/m^3)  \\\n",
       "0       1          1            73.990         31.99             6.73   \n",
       "1       2          2            87.400         20.51             6.51   \n",
       "2       3          3            88.410         20.05             6.59   \n",
       "3       4          4            87.370         20.35             6.45   \n",
       "4       5          5            87.330         20.63             6.51   \n",
       "5       6          9            75.540         29.08             6.44   \n",
       "6       7          1            80.780         22.35             5.81   \n",
       "7       8          1            87.760         12.46             3.97   \n",
       "8       9          1            85.660         14.32             4.39   \n",
       "9      10          3            89.650         13.09             4.42   \n",
       "10     11          4            88.720         13.32             4.37   \n",
       "11     12          1            78.570         26.62             6.44   \n",
       "12     13          2            90.770          7.00             2.42   \n",
       "13     14          3            90.734          7.57             2.63   \n",
       "14     15          4            88.988          7.97             2.71   \n",
       "15     16          5            90.194          7.64             2.76   \n",
       "16     17          6            86.720          7.95             2.44   \n",
       "\n",
       "    Enthalpy, h (kJ/kg)  x (g/kg)  \n",
       "0                 38.08      5.68  \n",
       "1                 45.55      5.66  \n",
       "2                 46.29      5.74  \n",
       "3                 45.39      5.60  \n",
       "4                 45.59      5.66  \n",
       "5                 38.33      5.46  \n",
       "6                 40.09      4.98  \n",
       "7                 40.32      3.46  \n",
       "8                 39.87      3.72  \n",
       "9                 42.21      3.86  \n",
       "10                41.51      3.81  \n",
       "11                40.20      3.88  \n",
       "12                38.36      2.10  \n",
       "13                38.76      2.31  \n",
       "14                38.04      2.30  \n",
       "15                38.77      2.32  \n",
       "16                36.15      2.12  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load entrance data\n",
    "ori_data_entrance = pd.read_csv('/Users/hsiaopingni/Desktop/Hsiao-Ping PhD/Data/MAU_paper/AI_model_MAU_Entrance.csv', encoding='unicode_escape')\n",
    "#ori_data_entrance=pd.read_csv(r'C:\\Users\\Hsiao-ping.ni\\ASU Dropbox\\Hsiao-Ping Ni\\PhD\\Data\\3rd paper- MAU\\AI_model_MAU_Entrance.csv', encoding='unicode_escape')\n",
    "#ori_data_entrance=pd.read_csv(r'C:\\Users\\nick8\\ASU Dropbox\\Hsiao-Ping Ni\\PhD\\Data\\3rd paper- MAU\\AI_model_MAU_Entrance.csv', encoding='unicode_escape')\n",
    "ori_data_entrance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7573f91",
   "metadata": {},
   "source": [
    "### Original test datasets for MAU entrance (3 counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "296f1b43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "      <th>Which MAU</th>\n",
       "      <th>Temperature (°F)</th>\n",
       "      <th>Humidity (%)</th>\n",
       "      <th>Density (g/m^3)</th>\n",
       "      <th>Enthalpy, h (kJ/kg)</th>\n",
       "      <th>x (g/kg)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>75.540</td>\n",
       "      <td>29.08</td>\n",
       "      <td>6.44</td>\n",
       "      <td>38.33</td>\n",
       "      <td>5.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>90.770</td>\n",
       "      <td>7.00</td>\n",
       "      <td>2.42</td>\n",
       "      <td>38.36</td>\n",
       "      <td>2.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>90.194</td>\n",
       "      <td>7.64</td>\n",
       "      <td>2.76</td>\n",
       "      <td>38.77</td>\n",
       "      <td>2.32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Count  Which MAU  Temperature (°F)  Humidity (%)  Density (g/m^3)  \\\n",
       "5       6          9            75.540         29.08             6.44   \n",
       "12     13          2            90.770          7.00             2.42   \n",
       "15     16          5            90.194          7.64             2.76   \n",
       "\n",
       "    Enthalpy, h (kJ/kg)  x (g/kg)  \n",
       "5                 38.33      5.46  \n",
       "12                38.36      2.10  \n",
       "15                38.77      2.32  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ori_test_entrance = ori_data_entrance.iloc[[5, 12, 15]]\n",
    "ori_test_entrance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe38de2f",
   "metadata": {},
   "source": [
    "### Train datasets for MAU exit (1360 counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fcaa78ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature (Â°F)</th>\n",
       "      <th>Humidity (%)</th>\n",
       "      <th>Density (g/m^3)</th>\n",
       "      <th>Enthalpy, h (kJ/kg)</th>\n",
       "      <th>x (g/kg)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>75.146</td>\n",
       "      <td>38.07</td>\n",
       "      <td>8.223149</td>\n",
       "      <td>42.222884</td>\n",
       "      <td>7.024901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>74.876</td>\n",
       "      <td>38.19</td>\n",
       "      <td>8.317148</td>\n",
       "      <td>41.918531</td>\n",
       "      <td>6.993284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>75.074</td>\n",
       "      <td>38.43</td>\n",
       "      <td>8.350496</td>\n",
       "      <td>42.282774</td>\n",
       "      <td>7.214184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1229</th>\n",
       "      <td>75.110</td>\n",
       "      <td>38.80</td>\n",
       "      <td>8.482469</td>\n",
       "      <td>42.535429</td>\n",
       "      <td>7.231600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654</th>\n",
       "      <td>74.894</td>\n",
       "      <td>38.55</td>\n",
       "      <td>8.984841</td>\n",
       "      <td>42.145285</td>\n",
       "      <td>7.535246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>74.984</td>\n",
       "      <td>38.16</td>\n",
       "      <td>8.312813</td>\n",
       "      <td>41.957162</td>\n",
       "      <td>7.084627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>74.984</td>\n",
       "      <td>38.16</td>\n",
       "      <td>8.240574</td>\n",
       "      <td>42.078205</td>\n",
       "      <td>7.030646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832</th>\n",
       "      <td>75.182</td>\n",
       "      <td>39.89</td>\n",
       "      <td>8.718000</td>\n",
       "      <td>43.084918</td>\n",
       "      <td>7.364656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>951</th>\n",
       "      <td>75.182</td>\n",
       "      <td>39.89</td>\n",
       "      <td>8.687491</td>\n",
       "      <td>43.150646</td>\n",
       "      <td>7.390063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1144</th>\n",
       "      <td>75.110</td>\n",
       "      <td>38.80</td>\n",
       "      <td>8.506222</td>\n",
       "      <td>42.522690</td>\n",
       "      <td>7.254198</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1360 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Temperature (Â°F)  Humidity (%)  Density (g/m^3)  Enthalpy, h (kJ/kg)  \\\n",
       "678              75.146         38.07         8.223149            42.222884   \n",
       "6                74.876         38.19         8.317148            41.918531   \n",
       "182              75.074         38.43         8.350496            42.282774   \n",
       "1229             75.110         38.80         8.482469            42.535429   \n",
       "654              74.894         38.55         8.984841            42.145285   \n",
       "...                 ...           ...              ...                  ...   \n",
       "732              74.984         38.16         8.312813            41.957162   \n",
       "715              74.984         38.16         8.240574            42.078205   \n",
       "832              75.182         39.89         8.718000            43.084918   \n",
       "951              75.182         39.89         8.687491            43.150646   \n",
       "1144             75.110         38.80         8.506222            42.522690   \n",
       "\n",
       "      x (g/kg)  \n",
       "678   7.024901  \n",
       "6     6.993284  \n",
       "182   7.214184  \n",
       "1229  7.231600  \n",
       "654   7.535246  \n",
       "...        ...  \n",
       "732   7.084627  \n",
       "715   7.030646  \n",
       "832   7.364656  \n",
       "951   7.390063  \n",
       "1144  7.254198  \n",
       "\n",
       "[1360 rows x 5 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_exit = data_exit.drop(['ï»¿Date'], axis=1)\n",
    "train_dataset_exit = data_exit.sample(frac=0.8, random_state=0)\n",
    "test_dataset_exit = data_exit.drop(train_dataset_exit.index)\n",
    "train_dataset_exit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67a3cca",
   "metadata": {},
   "source": [
    "### Test datasets for MAU exit (340 counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bb8dbaca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature (Â°F)</th>\n",
       "      <th>Humidity (%)</th>\n",
       "      <th>Density (g/m^3)</th>\n",
       "      <th>Enthalpy, h (kJ/kg)</th>\n",
       "      <th>x (g/kg)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>74.516</td>\n",
       "      <td>38.64</td>\n",
       "      <td>8.329598</td>\n",
       "      <td>41.750416</td>\n",
       "      <td>7.113062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>74.876</td>\n",
       "      <td>38.19</td>\n",
       "      <td>8.285078</td>\n",
       "      <td>41.957149</td>\n",
       "      <td>7.090686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>74.804</td>\n",
       "      <td>38.61</td>\n",
       "      <td>8.351687</td>\n",
       "      <td>42.049004</td>\n",
       "      <td>7.109332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>74.894</td>\n",
       "      <td>38.55</td>\n",
       "      <td>8.826337</td>\n",
       "      <td>42.122536</td>\n",
       "      <td>7.625883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>74.516</td>\n",
       "      <td>38.64</td>\n",
       "      <td>8.351497</td>\n",
       "      <td>41.824864</td>\n",
       "      <td>7.106831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1660</th>\n",
       "      <td>74.516</td>\n",
       "      <td>38.64</td>\n",
       "      <td>8.253768</td>\n",
       "      <td>41.686250</td>\n",
       "      <td>7.168617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1671</th>\n",
       "      <td>75.110</td>\n",
       "      <td>38.80</td>\n",
       "      <td>8.372885</td>\n",
       "      <td>42.504321</td>\n",
       "      <td>7.140405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1674</th>\n",
       "      <td>74.894</td>\n",
       "      <td>38.55</td>\n",
       "      <td>8.877564</td>\n",
       "      <td>42.148165</td>\n",
       "      <td>7.514101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1684</th>\n",
       "      <td>74.984</td>\n",
       "      <td>38.16</td>\n",
       "      <td>8.239657</td>\n",
       "      <td>42.088350</td>\n",
       "      <td>6.950375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1694</th>\n",
       "      <td>74.516</td>\n",
       "      <td>38.64</td>\n",
       "      <td>8.291765</td>\n",
       "      <td>41.691279</td>\n",
       "      <td>7.140439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>340 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Temperature (Â°F)  Humidity (%)  Density (g/m^3)  Enthalpy, h (kJ/kg)  \\\n",
       "11               74.516         38.64         8.329598            41.750416   \n",
       "23               74.876         38.19         8.285078            41.957149   \n",
       "24               74.804         38.61         8.351687            42.049004   \n",
       "25               74.894         38.55         8.826337            42.122536   \n",
       "28               74.516         38.64         8.351497            41.824864   \n",
       "...                 ...           ...              ...                  ...   \n",
       "1660             74.516         38.64         8.253768            41.686250   \n",
       "1671             75.110         38.80         8.372885            42.504321   \n",
       "1674             74.894         38.55         8.877564            42.148165   \n",
       "1684             74.984         38.16         8.239657            42.088350   \n",
       "1694             74.516         38.64         8.291765            41.691279   \n",
       "\n",
       "      x (g/kg)  \n",
       "11    7.113062  \n",
       "23    7.090686  \n",
       "24    7.109332  \n",
       "25    7.625883  \n",
       "28    7.106831  \n",
       "...        ...  \n",
       "1660  7.168617  \n",
       "1671  7.140405  \n",
       "1674  7.514101  \n",
       "1684  6.950375  \n",
       "1694  7.140439  \n",
       "\n",
       "[340 rows x 5 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset_exit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8993a2",
   "metadata": {},
   "source": [
    "### Load original exit data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3d60fe45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "      <th>Which MAU</th>\n",
       "      <th>Temperature (°F)</th>\n",
       "      <th>Humidity (%)</th>\n",
       "      <th>Density (g/m^3)</th>\n",
       "      <th>Enthalpy, h (kJ/kg)</th>\n",
       "      <th>x (g/kg)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>75.038</td>\n",
       "      <td>38.79</td>\n",
       "      <td>8.40</td>\n",
       "      <td>42.38</td>\n",
       "      <td>7.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>74.984</td>\n",
       "      <td>38.16</td>\n",
       "      <td>8.28</td>\n",
       "      <td>42.05</td>\n",
       "      <td>7.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>75.092</td>\n",
       "      <td>39.94</td>\n",
       "      <td>8.68</td>\n",
       "      <td>42.99</td>\n",
       "      <td>7.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>75.020</td>\n",
       "      <td>39.08</td>\n",
       "      <td>8.48</td>\n",
       "      <td>42.52</td>\n",
       "      <td>2.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>75.038</td>\n",
       "      <td>38.89</td>\n",
       "      <td>8.45</td>\n",
       "      <td>42.45</td>\n",
       "      <td>7.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>75.110</td>\n",
       "      <td>38.80</td>\n",
       "      <td>8.45</td>\n",
       "      <td>42.50</td>\n",
       "      <td>7.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>74.876</td>\n",
       "      <td>38.19</td>\n",
       "      <td>8.26</td>\n",
       "      <td>41.93</td>\n",
       "      <td>7.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>74.804</td>\n",
       "      <td>38.61</td>\n",
       "      <td>8.32</td>\n",
       "      <td>42.04</td>\n",
       "      <td>7.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>74.894</td>\n",
       "      <td>38.55</td>\n",
       "      <td>8.83</td>\n",
       "      <td>42.11</td>\n",
       "      <td>7.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>75.074</td>\n",
       "      <td>39.34</td>\n",
       "      <td>8.56</td>\n",
       "      <td>42.73</td>\n",
       "      <td>7.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>75.110</td>\n",
       "      <td>38.67</td>\n",
       "      <td>8.43</td>\n",
       "      <td>42.48</td>\n",
       "      <td>7.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>74.516</td>\n",
       "      <td>38.64</td>\n",
       "      <td>8.27</td>\n",
       "      <td>41.76</td>\n",
       "      <td>7.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>75.074</td>\n",
       "      <td>38.43</td>\n",
       "      <td>8.36</td>\n",
       "      <td>42.28</td>\n",
       "      <td>7.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>75.146</td>\n",
       "      <td>39.14</td>\n",
       "      <td>8.52</td>\n",
       "      <td>42.67</td>\n",
       "      <td>7.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>75.074</td>\n",
       "      <td>42.52</td>\n",
       "      <td>8.47</td>\n",
       "      <td>42.52</td>\n",
       "      <td>7.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>75.146</td>\n",
       "      <td>38.07</td>\n",
       "      <td>8.30</td>\n",
       "      <td>42.19</td>\n",
       "      <td>7.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>75.182</td>\n",
       "      <td>39.89</td>\n",
       "      <td>8.70</td>\n",
       "      <td>43.09</td>\n",
       "      <td>7.41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Count  Which MAU  Temperature (°F)  Humidity (%)   Density (g/m^3)  \\\n",
       "0       1          1            75.038         38.79              8.40   \n",
       "1       2          2            74.984         38.16              8.28   \n",
       "2       3          3            75.092         39.94              8.68   \n",
       "3       4          4            75.020         39.08              8.48   \n",
       "4       5          5            75.038         38.89              8.45   \n",
       "5       6          9            75.110         38.80              8.45   \n",
       "6       7          1            74.876         38.19              8.26   \n",
       "7       8          1            74.804         38.61              8.32   \n",
       "8       9          1            74.894         38.55              8.83   \n",
       "9      10          3            75.074         39.34              8.56   \n",
       "10     11          4            75.110         38.67              8.43   \n",
       "11     12          1            74.516         38.64              8.27   \n",
       "12     13          2            75.074         38.43              8.36   \n",
       "13     14          3            75.146         39.14              8.52   \n",
       "14     15          4            75.074         42.52              8.47   \n",
       "15     16          5            75.146         38.07              8.30   \n",
       "16     17          6            75.182         39.89              8.70   \n",
       "\n",
       "     Enthalpy, h (kJ/kg)   x (g/kg)  \n",
       "0                  42.38       7.17  \n",
       "1                  42.05       7.04  \n",
       "2                  42.99       7.40  \n",
       "3                  42.52       2.22  \n",
       "4                  42.45       7.19  \n",
       "5                  42.50       7.19  \n",
       "6                  41.93       7.03  \n",
       "7                  42.04       7.08  \n",
       "8                  42.11       7.59  \n",
       "9                  42.73       7.28  \n",
       "10                 42.48       7.17  \n",
       "11                 41.76       7.12  \n",
       "12                 42.28       7.11  \n",
       "13                 42.67       7.26  \n",
       "14                 42.52       7.21  \n",
       "15                 42.19       7.06  \n",
       "16                 43.09       7.41  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load exit data\n",
    "ori_data_exit = pd.read_csv('/Users/hsiaopingni/Desktop/Hsiao-Ping PhD/Data/MAU_paper/AI_model_MAU_Exit.csv', encoding='unicode_escape')\n",
    "#ori_data_exit=pd.read_csv(r'C:\\Users\\Hsiao-ping.ni\\ASU Dropbox\\Hsiao-Ping Ni\\PhD\\Data\\3rd paper- MAU\\AI_model_MAU_Exit.csv', encoding='unicode_escape')\n",
    "#ori_data_exit=pd.read_csv(r'C:\\Users\\nick8\\ASU Dropbox\\Hsiao-Ping Ni\\PhD\\Data\\3rd paper- MAU\\AI_model_MAU_Exit.csv', encoding='unicode_escape')\n",
    "ori_data_exit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f23a761",
   "metadata": {},
   "source": [
    "### Original test datasets for MAU exit (3 counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b11ee79d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "      <th>Which MAU</th>\n",
       "      <th>Temperature (°F)</th>\n",
       "      <th>Humidity (%)</th>\n",
       "      <th>Density (g/m^3)</th>\n",
       "      <th>Enthalpy, h (kJ/kg)</th>\n",
       "      <th>x (g/kg)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>75.110</td>\n",
       "      <td>38.80</td>\n",
       "      <td>8.45</td>\n",
       "      <td>42.50</td>\n",
       "      <td>7.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>75.074</td>\n",
       "      <td>38.43</td>\n",
       "      <td>8.36</td>\n",
       "      <td>42.28</td>\n",
       "      <td>7.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>75.146</td>\n",
       "      <td>38.07</td>\n",
       "      <td>8.30</td>\n",
       "      <td>42.19</td>\n",
       "      <td>7.06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Count  Which MAU  Temperature (°F)  Humidity (%)   Density (g/m^3)  \\\n",
       "5       6          9            75.110         38.80              8.45   \n",
       "12     13          2            75.074         38.43              8.36   \n",
       "15     16          5            75.146         38.07              8.30   \n",
       "\n",
       "     Enthalpy, h (kJ/kg)   x (g/kg)  \n",
       "5                  42.50       7.19  \n",
       "12                 42.28       7.11  \n",
       "15                 42.19       7.06  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ori_test_exit = ori_data_exit.iloc[[5, 12, 15]]\n",
    "ori_test_exit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb1ad4a",
   "metadata": {},
   "source": [
    "## Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478de120",
   "metadata": {},
   "source": [
    "Let's check the overall statistics. Note how each feature covers a very different range.\n",
    "\n",
    ".describe(): This method generates descriptive statistics that summarize the central tendency, dispersion, and shape of the dataset's distribution, excluding NaN values. By default, it provides information such as count (number of non-missing values), mean, standard deviation (std), minimum, 25th percentile (25%), median (50th percentile), 75th percentile (75%), and maximum for numeric columns.\n",
    "\n",
    ".transpose() or .T: This method transposes the DataFrame, swapping its rows and columns. After calling .describe(), the resulting DataFrame has the descriptive statistics as rows and the features (or columns of the original dataset) as columns. Transposing flips this layout, so the features become rows and the descriptive statistics become columns. This often makes the output more readable and easier to analyze, especially if the dataset has many features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248e88be",
   "metadata": {},
   "source": [
    "### Train datasets for MAU entrance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9344f266",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Temperature (Â°F)</th>\n",
       "      <td>1360.0</td>\n",
       "      <td>85.839838</td>\n",
       "      <td>5.093658</td>\n",
       "      <td>73.990000</td>\n",
       "      <td>85.660000</td>\n",
       "      <td>87.400000</td>\n",
       "      <td>88.988000</td>\n",
       "      <td>90.770000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Humidity (%)</th>\n",
       "      <td>1360.0</td>\n",
       "      <td>16.604610</td>\n",
       "      <td>7.770026</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.970000</td>\n",
       "      <td>14.320000</td>\n",
       "      <td>20.630000</td>\n",
       "      <td>31.990000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Density (g/m3)</th>\n",
       "      <td>1360.0</td>\n",
       "      <td>4.796579</td>\n",
       "      <td>1.669356</td>\n",
       "      <td>2.281108</td>\n",
       "      <td>2.749258</td>\n",
       "      <td>4.453171</td>\n",
       "      <td>6.476791</td>\n",
       "      <td>6.876141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Enthalpy, h (kJ/kg)</th>\n",
       "      <td>1360.0</td>\n",
       "      <td>40.808037</td>\n",
       "      <td>3.036174</td>\n",
       "      <td>36.037672</td>\n",
       "      <td>38.364110</td>\n",
       "      <td>40.083703</td>\n",
       "      <td>42.250144</td>\n",
       "      <td>46.405056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x (g/kg)</th>\n",
       "      <td>1360.0</td>\n",
       "      <td>4.035193</td>\n",
       "      <td>1.392419</td>\n",
       "      <td>1.935583</td>\n",
       "      <td>2.345592</td>\n",
       "      <td>3.848603</td>\n",
       "      <td>5.589423</td>\n",
       "      <td>5.837205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      count       mean       std        min        25%  \\\n",
       "Temperature (Â°F)    1360.0  85.839838  5.093658  73.990000  85.660000   \n",
       "Humidity (%)         1360.0  16.604610  7.770026   7.000000   7.970000   \n",
       "Density (g/m3)       1360.0   4.796579  1.669356   2.281108   2.749258   \n",
       "Enthalpy, h (kJ/kg)  1360.0  40.808037  3.036174  36.037672  38.364110   \n",
       "x (g/kg)             1360.0   4.035193  1.392419   1.935583   2.345592   \n",
       "\n",
       "                           50%        75%        max  \n",
       "Temperature (Â°F)    87.400000  88.988000  90.770000  \n",
       "Humidity (%)         14.320000  20.630000  31.990000  \n",
       "Density (g/m3)        4.453171   6.476791   6.876141  \n",
       "Enthalpy, h (kJ/kg)  40.083703  42.250144  46.405056  \n",
       "x (g/kg)              3.848603   5.589423   5.837205  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset_entrance.describe().transpose()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6188981e",
   "metadata": {},
   "source": [
    "### Train datasets for MAU exit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e38f405b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Temperature (Â°F)</th>\n",
       "      <td>1360.0</td>\n",
       "      <td>75.010312</td>\n",
       "      <td>0.157998</td>\n",
       "      <td>74.516000</td>\n",
       "      <td>74.984000</td>\n",
       "      <td>75.074000</td>\n",
       "      <td>75.110000</td>\n",
       "      <td>75.182000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Humidity (%)</th>\n",
       "      <td>1360.0</td>\n",
       "      <td>39.043154</td>\n",
       "      <td>1.021265</td>\n",
       "      <td>38.070000</td>\n",
       "      <td>38.550000</td>\n",
       "      <td>38.790000</td>\n",
       "      <td>39.140000</td>\n",
       "      <td>42.520000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Density (g/m^3)</th>\n",
       "      <td>1360.0</td>\n",
       "      <td>8.455716</td>\n",
       "      <td>0.164876</td>\n",
       "      <td>8.099327</td>\n",
       "      <td>8.328012</td>\n",
       "      <td>8.432570</td>\n",
       "      <td>8.539476</td>\n",
       "      <td>8.984841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Enthalpy, h (kJ/kg)</th>\n",
       "      <td>1360.0</td>\n",
       "      <td>42.394030</td>\n",
       "      <td>0.351024</td>\n",
       "      <td>41.656657</td>\n",
       "      <td>42.098359</td>\n",
       "      <td>42.433094</td>\n",
       "      <td>42.577958</td>\n",
       "      <td>43.196384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x (g/kg)</th>\n",
       "      <td>1360.0</td>\n",
       "      <td>6.906349</td>\n",
       "      <td>1.197294</td>\n",
       "      <td>2.071204</td>\n",
       "      <td>7.079184</td>\n",
       "      <td>7.170856</td>\n",
       "      <td>7.268821</td>\n",
       "      <td>7.698429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      count       mean       std        min        25%  \\\n",
       "Temperature (Â°F)    1360.0  75.010312  0.157998  74.516000  74.984000   \n",
       "Humidity (%)         1360.0  39.043154  1.021265  38.070000  38.550000   \n",
       "Density (g/m^3)      1360.0   8.455716  0.164876   8.099327   8.328012   \n",
       "Enthalpy, h (kJ/kg)  1360.0  42.394030  0.351024  41.656657  42.098359   \n",
       "x (g/kg)             1360.0   6.906349  1.197294   2.071204   7.079184   \n",
       "\n",
       "                           50%        75%        max  \n",
       "Temperature (Â°F)    75.074000  75.110000  75.182000  \n",
       "Humidity (%)         38.790000  39.140000  42.520000  \n",
       "Density (g/m^3)       8.432570   8.539476   8.984841  \n",
       "Enthalpy, h (kJ/kg)  42.433094  42.577958  43.196384  \n",
       "x (g/kg)              7.170856   7.268821   7.698429  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset_exit.describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39af1dc6",
   "metadata": {},
   "source": [
    "## Split features from labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8512c35e",
   "metadata": {},
   "source": [
    "Separate the target value—the \"label\"—from the features. This label is the value that you will train the model to predict.\n",
    "\n",
    "train_features = train_dataset.copy(): This line creates a copy of the train_dataset DataFrame and assigns it to train_features. The .copy() method ensures that the original dataset remains unchanged when modifications are made to train_features. This dataset contains the features used to train the machine learning model.\n",
    "\n",
    "test_features = test_dataset.copy(): Similarly, this line duplicates the test_dataset DataFrame, storing the copy in test_features. This is done to preserve the original test_dataset while allowing modifications on test_features. This dataset is used to evaluate the model's performance after training.\n",
    "\n",
    "train_labels = train_features.pop('Temperature (°F)'): The .pop() method removes the column named 'Temperature (°F)' from train_features and returns it. This removed column is then stored in train_labels. In our machine learning context, 'Temperature (°F)' is considered the target variable (or label) that the model will be trained to predict. By doing this, train_features now only contains the input features (or independent variables) for the training data, while train_labels holds the corresponding target values.\n",
    "\n",
    "test_labels = test_features.pop('Temperature (°F)'): This line does the same operation as the previous one but for the testing dataset. It removes the 'Temperature (°F)' column from test_features and stores it in test_labels. Now, test_features only includes the input features for the testing data, and test_labels contains the corresponding target values that will be used to evaluate the model's predictive accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a918516",
   "metadata": {},
   "source": [
    "### Train and test features, and train and test labels for MAU entrance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ed65d195",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_entrance = train_dataset_entrance.copy()\n",
    "test_features_entrance = test_dataset_entrance.copy()\n",
    "train_labels_entrance = train_features_entrance.pop('Temperature (Â°F)')\n",
    "test_labels_entrance = test_features_entrance.pop('Temperature (Â°F)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ba566e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original\n",
    "ori_test_features_entrance = ori_test_entrance.copy()\n",
    "ori_test_labels_entrance = ori_test_features_entrance.pop('Temperature (°F)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e2479641",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Humidity (%)</th>\n",
       "      <th>Density (g/m3)</th>\n",
       "      <th>Enthalpy, h (kJ/kg)</th>\n",
       "      <th>x (g/kg)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>7.64</td>\n",
       "      <td>2.690796</td>\n",
       "      <td>38.729669</td>\n",
       "      <td>2.381493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>22.35</td>\n",
       "      <td>5.820378</td>\n",
       "      <td>40.131530</td>\n",
       "      <td>4.981644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>7.00</td>\n",
       "      <td>2.519978</td>\n",
       "      <td>38.301343</td>\n",
       "      <td>2.105956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1229</th>\n",
       "      <td>29.08</td>\n",
       "      <td>6.490289</td>\n",
       "      <td>38.374865</td>\n",
       "      <td>5.469321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654</th>\n",
       "      <td>14.32</td>\n",
       "      <td>4.332828</td>\n",
       "      <td>39.808657</td>\n",
       "      <td>3.644525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>20.51</td>\n",
       "      <td>6.495102</td>\n",
       "      <td>45.562149</td>\n",
       "      <td>5.722994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>20.51</td>\n",
       "      <td>6.577599</td>\n",
       "      <td>45.580326</td>\n",
       "      <td>5.726651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832</th>\n",
       "      <td>7.95</td>\n",
       "      <td>2.372378</td>\n",
       "      <td>36.182355</td>\n",
       "      <td>2.059846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>951</th>\n",
       "      <td>7.95</td>\n",
       "      <td>2.493572</td>\n",
       "      <td>36.132664</td>\n",
       "      <td>2.117976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1144</th>\n",
       "      <td>29.08</td>\n",
       "      <td>6.409704</td>\n",
       "      <td>38.223150</td>\n",
       "      <td>5.414350</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1360 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Humidity (%)  Density (g/m3)  Enthalpy, h (kJ/kg)  x (g/kg)\n",
       "678           7.64        2.690796            38.729669  2.381493\n",
       "6            22.35        5.820378            40.131530  4.981644\n",
       "182           7.00        2.519978            38.301343  2.105956\n",
       "1229         29.08        6.490289            38.374865  5.469321\n",
       "654          14.32        4.332828            39.808657  3.644525\n",
       "...            ...             ...                  ...       ...\n",
       "732          20.51        6.495102            45.562149  5.722994\n",
       "715          20.51        6.577599            45.580326  5.726651\n",
       "832           7.95        2.372378            36.182355  2.059846\n",
       "951           7.95        2.493572            36.132664  2.117976\n",
       "1144         29.08        6.409704            38.223150  5.414350\n",
       "\n",
       "[1360 rows x 4 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features_entrance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c1a40da4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Humidity (%)</th>\n",
       "      <th>Density (g/m3)</th>\n",
       "      <th>Enthalpy, h (kJ/kg)</th>\n",
       "      <th>x (g/kg)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>26.62</td>\n",
       "      <td>6.464909</td>\n",
       "      <td>40.252792</td>\n",
       "      <td>3.837001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>22.35</td>\n",
       "      <td>5.744959</td>\n",
       "      <td>40.173020</td>\n",
       "      <td>4.886453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>12.46</td>\n",
       "      <td>4.021235</td>\n",
       "      <td>40.352206</td>\n",
       "      <td>3.496527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>14.32</td>\n",
       "      <td>4.443511</td>\n",
       "      <td>39.904371</td>\n",
       "      <td>3.683571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>26.62</td>\n",
       "      <td>6.403753</td>\n",
       "      <td>40.250647</td>\n",
       "      <td>3.839436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1660</th>\n",
       "      <td>26.62</td>\n",
       "      <td>6.410665</td>\n",
       "      <td>40.247850</td>\n",
       "      <td>3.911928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1671</th>\n",
       "      <td>29.08</td>\n",
       "      <td>6.483653</td>\n",
       "      <td>38.307150</td>\n",
       "      <td>5.490089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1674</th>\n",
       "      <td>14.32</td>\n",
       "      <td>4.370929</td>\n",
       "      <td>39.763514</td>\n",
       "      <td>3.757167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1684</th>\n",
       "      <td>20.51</td>\n",
       "      <td>6.468397</td>\n",
       "      <td>45.507832</td>\n",
       "      <td>5.584946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1694</th>\n",
       "      <td>26.62</td>\n",
       "      <td>6.456255</td>\n",
       "      <td>40.173394</td>\n",
       "      <td>3.851134</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>340 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Humidity (%)  Density (g/m3)  Enthalpy, h (kJ/kg)  x (g/kg)\n",
       "11           26.62        6.464909            40.252792  3.837001\n",
       "23           22.35        5.744959            40.173020  4.886453\n",
       "24           12.46        4.021235            40.352206  3.496527\n",
       "25           14.32        4.443511            39.904371  3.683571\n",
       "28           26.62        6.403753            40.250647  3.839436\n",
       "...            ...             ...                  ...       ...\n",
       "1660         26.62        6.410665            40.247850  3.911928\n",
       "1671         29.08        6.483653            38.307150  5.490089\n",
       "1674         14.32        4.370929            39.763514  3.757167\n",
       "1684         20.51        6.468397            45.507832  5.584946\n",
       "1694         26.62        6.456255            40.173394  3.851134\n",
       "\n",
       "[340 rows x 4 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_features_entrance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "23c9a277",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Humidity (%)</th>\n",
       "      <th>Density (g/m^3)</th>\n",
       "      <th>Enthalpy, h (kJ/kg)</th>\n",
       "      <th>x (g/kg)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>29.08</td>\n",
       "      <td>6.44</td>\n",
       "      <td>38.33</td>\n",
       "      <td>5.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7.00</td>\n",
       "      <td>2.42</td>\n",
       "      <td>38.36</td>\n",
       "      <td>2.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7.64</td>\n",
       "      <td>2.76</td>\n",
       "      <td>38.77</td>\n",
       "      <td>2.32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Humidity (%)  Density (g/m^3)  Enthalpy, h (kJ/kg)  x (g/kg)\n",
       "5          29.08             6.44                38.33      5.46\n",
       "12          7.00             2.42                38.36      2.10\n",
       "15          7.64             2.76                38.77      2.32"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ori_test_features_entrance = ori_test_features_entrance.drop(['Count','Which MAU'], axis=1)\n",
    "ori_test_features_entrance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "04f9d966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "678     90.194\n",
       "6       80.780\n",
       "182     90.770\n",
       "1229    75.540\n",
       "654     85.660\n",
       "         ...  \n",
       "732     87.400\n",
       "715     87.400\n",
       "832     86.720\n",
       "951     86.720\n",
       "1144    75.540\n",
       "Name: Temperature (Â°F), Length: 1360, dtype: float64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels_entrance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fd346d9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11      78.57\n",
       "23      80.78\n",
       "24      87.76\n",
       "25      85.66\n",
       "28      78.57\n",
       "        ...  \n",
       "1660    78.57\n",
       "1671    75.54\n",
       "1674    85.66\n",
       "1684    87.40\n",
       "1694    78.57\n",
       "Name: Temperature (Â°F), Length: 340, dtype: float64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels_entrance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd02152",
   "metadata": {},
   "source": [
    "### Train and test features, and train and test labels for MAU exit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a99eca75",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_exit = train_dataset_exit.copy()\n",
    "test_features_exit = test_dataset_exit.copy()\n",
    "train_labels_exit = train_features_exit.pop('Temperature (Â°F)')\n",
    "test_labels_exit = test_features_exit.pop('Temperature (Â°F)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3d90accc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original\n",
    "ori_test_features_exit = ori_test_exit.copy()\n",
    "ori_test_labels_exit = ori_test_features_exit.pop('Temperature (°F)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0ba7c11c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Humidity (%)</th>\n",
       "      <th>Density (g/m^3)</th>\n",
       "      <th>Enthalpy, h (kJ/kg)</th>\n",
       "      <th>x (g/kg)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>38.07</td>\n",
       "      <td>8.223149</td>\n",
       "      <td>42.222884</td>\n",
       "      <td>7.024901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>38.19</td>\n",
       "      <td>8.317148</td>\n",
       "      <td>41.918531</td>\n",
       "      <td>6.993284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>38.43</td>\n",
       "      <td>8.350496</td>\n",
       "      <td>42.282774</td>\n",
       "      <td>7.214184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1229</th>\n",
       "      <td>38.80</td>\n",
       "      <td>8.482469</td>\n",
       "      <td>42.535429</td>\n",
       "      <td>7.231600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654</th>\n",
       "      <td>38.55</td>\n",
       "      <td>8.984841</td>\n",
       "      <td>42.145285</td>\n",
       "      <td>7.535246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>38.16</td>\n",
       "      <td>8.312813</td>\n",
       "      <td>41.957162</td>\n",
       "      <td>7.084627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>38.16</td>\n",
       "      <td>8.240574</td>\n",
       "      <td>42.078205</td>\n",
       "      <td>7.030646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832</th>\n",
       "      <td>39.89</td>\n",
       "      <td>8.718000</td>\n",
       "      <td>43.084918</td>\n",
       "      <td>7.364656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>951</th>\n",
       "      <td>39.89</td>\n",
       "      <td>8.687491</td>\n",
       "      <td>43.150646</td>\n",
       "      <td>7.390063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1144</th>\n",
       "      <td>38.80</td>\n",
       "      <td>8.506222</td>\n",
       "      <td>42.522690</td>\n",
       "      <td>7.254198</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1360 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Humidity (%)  Density (g/m^3)  Enthalpy, h (kJ/kg)  x (g/kg)\n",
       "678          38.07         8.223149            42.222884  7.024901\n",
       "6            38.19         8.317148            41.918531  6.993284\n",
       "182          38.43         8.350496            42.282774  7.214184\n",
       "1229         38.80         8.482469            42.535429  7.231600\n",
       "654          38.55         8.984841            42.145285  7.535246\n",
       "...            ...              ...                  ...       ...\n",
       "732          38.16         8.312813            41.957162  7.084627\n",
       "715          38.16         8.240574            42.078205  7.030646\n",
       "832          39.89         8.718000            43.084918  7.364656\n",
       "951          39.89         8.687491            43.150646  7.390063\n",
       "1144         38.80         8.506222            42.522690  7.254198\n",
       "\n",
       "[1360 rows x 4 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features_exit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "57ab8ada",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Humidity (%)</th>\n",
       "      <th>Density (g/m^3)</th>\n",
       "      <th>Enthalpy, h (kJ/kg)</th>\n",
       "      <th>x (g/kg)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>38.64</td>\n",
       "      <td>8.329598</td>\n",
       "      <td>41.750416</td>\n",
       "      <td>7.113062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>38.19</td>\n",
       "      <td>8.285078</td>\n",
       "      <td>41.957149</td>\n",
       "      <td>7.090686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>38.61</td>\n",
       "      <td>8.351687</td>\n",
       "      <td>42.049004</td>\n",
       "      <td>7.109332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>38.55</td>\n",
       "      <td>8.826337</td>\n",
       "      <td>42.122536</td>\n",
       "      <td>7.625883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>38.64</td>\n",
       "      <td>8.351497</td>\n",
       "      <td>41.824864</td>\n",
       "      <td>7.106831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1660</th>\n",
       "      <td>38.64</td>\n",
       "      <td>8.253768</td>\n",
       "      <td>41.686250</td>\n",
       "      <td>7.168617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1671</th>\n",
       "      <td>38.80</td>\n",
       "      <td>8.372885</td>\n",
       "      <td>42.504321</td>\n",
       "      <td>7.140405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1674</th>\n",
       "      <td>38.55</td>\n",
       "      <td>8.877564</td>\n",
       "      <td>42.148165</td>\n",
       "      <td>7.514101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1684</th>\n",
       "      <td>38.16</td>\n",
       "      <td>8.239657</td>\n",
       "      <td>42.088350</td>\n",
       "      <td>6.950375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1694</th>\n",
       "      <td>38.64</td>\n",
       "      <td>8.291765</td>\n",
       "      <td>41.691279</td>\n",
       "      <td>7.140439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>340 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Humidity (%)  Density (g/m^3)  Enthalpy, h (kJ/kg)  x (g/kg)\n",
       "11           38.64         8.329598            41.750416  7.113062\n",
       "23           38.19         8.285078            41.957149  7.090686\n",
       "24           38.61         8.351687            42.049004  7.109332\n",
       "25           38.55         8.826337            42.122536  7.625883\n",
       "28           38.64         8.351497            41.824864  7.106831\n",
       "...            ...              ...                  ...       ...\n",
       "1660         38.64         8.253768            41.686250  7.168617\n",
       "1671         38.80         8.372885            42.504321  7.140405\n",
       "1674         38.55         8.877564            42.148165  7.514101\n",
       "1684         38.16         8.239657            42.088350  6.950375\n",
       "1694         38.64         8.291765            41.691279  7.140439\n",
       "\n",
       "[340 rows x 4 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_features_exit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f590ea0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Humidity (%)</th>\n",
       "      <th>Density (g/m^3)</th>\n",
       "      <th>Enthalpy, h (kJ/kg)</th>\n",
       "      <th>x (g/kg)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>38.80</td>\n",
       "      <td>8.45</td>\n",
       "      <td>42.50</td>\n",
       "      <td>7.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>38.43</td>\n",
       "      <td>8.36</td>\n",
       "      <td>42.28</td>\n",
       "      <td>7.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>38.07</td>\n",
       "      <td>8.30</td>\n",
       "      <td>42.19</td>\n",
       "      <td>7.06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Humidity (%)   Density (g/m^3)   Enthalpy, h (kJ/kg)   x (g/kg)\n",
       "5          38.80              8.45                 42.50       7.19\n",
       "12         38.43              8.36                 42.28       7.11\n",
       "15         38.07              8.30                 42.19       7.06"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ori_test_features_exit = ori_test_features_exit.drop(['Count','Which MAU'], axis=1)\n",
    "ori_test_features_exit  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0ad33b2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "678     75.146\n",
       "6       74.876\n",
       "182     75.074\n",
       "1229    75.110\n",
       "654     74.894\n",
       "         ...  \n",
       "732     74.984\n",
       "715     74.984\n",
       "832     75.182\n",
       "951     75.182\n",
       "1144    75.110\n",
       "Name: Temperature (Â°F), Length: 1360, dtype: float64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels_exit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7da236b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11      74.516\n",
       "23      74.876\n",
       "24      74.804\n",
       "25      74.894\n",
       "28      74.516\n",
       "         ...  \n",
       "1660    74.516\n",
       "1671    75.110\n",
       "1674    74.894\n",
       "1684    74.984\n",
       "1694    74.516\n",
       "Name: Temperature (Â°F), Length: 340, dtype: float64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels_exit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fd9d6d02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5     75.110\n",
       "12    75.074\n",
       "15    75.146\n",
       "Name: Temperature (°F), dtype: float64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ori_test_labels_exit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e07e6e9",
   "metadata": {},
   "source": [
    "## Regression with a deep neural network (DNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db869e0a",
   "metadata": {},
   "source": [
    "Here, you will implement a multiple-input DNN model.\n",
    "\n",
    "The name \"hidden\" here just means not directly connected to the inputs or outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a282793",
   "metadata": {},
   "source": [
    "This model will contain a few layers.\n",
    "\n",
    "* The dense input layer.\n",
    "* Two hidden, non-linear, `Dense` layers with the ReLU (`relu`) activation function nonlinearity.\n",
    "* A linear `Dense` single-output layer.\n",
    "\n",
    "The `compile` method is included in the `build_and_compile_model` function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f8e0518d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_and_compile_model():\n",
    "  model = keras.Sequential([\n",
    "      layers.Dense(4,  kernel_initializer='normal', input_dim = train_features_entrance.shape[1], activation='relu'),\n",
    "      layers.Dense(64,  kernel_initializer='normal', activation='relu'),\n",
    "      layers.Dense(64,  kernel_initializer='normal', activation='relu'),\n",
    "      layers.Dense(1)])\n",
    "\n",
    "  model.compile(loss='mean_absolute_error',\n",
    "                optimizer=tf.keras.optimizers.Adam(0.001))\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a2a043ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment with different configurations\n",
    "#configs = [\n",
    " #   {\"layers\": 2, \"neurons_per_layer\": [32, 16]},\n",
    " #   {\"layers\": 3, \"neurons_per_layer\": [64, 32, 16]},\n",
    " #   {\"layers\": 4, \"neurons_per_layer\": [128, 64, 32, 16]},\n",
    " #   {\"layers\": 2, \"neurons_per_layer\": [64, 64]},\n",
    " #   {\"layers\": 3, \"neurons_per_layer\": [128, 64, 32]}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1449909e",
   "metadata": {},
   "source": [
    "### Regression using a DNN and multiple inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0d03c2cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 4)                 20        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                320       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,565\n",
      "Trainable params: 4,565\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x320e30c50>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_model = build_and_compile_model()\n",
    "dnn_model.summary()\n",
    "dnn_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a155532",
   "metadata": {},
   "source": [
    "This table summarizes the architecture of the neural network model. The table is divided into several columns detailing the layers in the model, their types, output shapes, and the number of parameters (weights and biases) each layer has. Here's a breakdown of the table:\n",
    "\n",
    "Layer: Indicates the name and type of each layer in the model. The model consists of a normalization layer followed by three dense (fully connected) layers.\n",
    "\n",
    "Output Shape: The shape of the output for each layer. The notation (None, x) indicates that the batch size is variable (denoted by None), and x is the dimensionality of the output from that layer.\n",
    "\n",
    "The normalization layer takes an input with 9 features ((None, 9)).\n",
    "The first dense layer outputs 64 units ((None, 64)).\n",
    "The second dense layer, identical to the first, also outputs 64 units.\n",
    "The final dense layer outputs a single unit ((None, 1)), corresponding to the model's prediction.\n",
    "\n",
    "Param #: Lists the number of parameters in each layer, which are learned during the training process.\n",
    "\n",
    "The normalization layer has 19 parameters, which are not trainable. These parameters might include statistics like mean and variance for each input feature used for data normalization.\n",
    "The first dense layer has 640 parameters, calculated as (9 input features * 64 output units) + 64 bias terms.\n",
    "The second dense layer has 4160 parameters, derived from (64 input units * 64 output units) + 64 bias terms.\n",
    "The final dense layer has 65 parameters, from (64 input units * 1 output unit) + 1 bias term.\n",
    "\n",
    "Total params: The total number of parameters in the model, summing to 4,884. This includes both trainable and non-trainable parameters.\n",
    "\n",
    "Trainable params: The number of parameters that will be updated during training, totaling 4,865. This excludes the normalization layer's statistics.\n",
    "\n",
    "Non-trainable params: Parameters that do not get updated during the training process, in this case, 19, likely related to the normalization layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3793b510",
   "metadata": {},
   "source": [
    "\n",
    "Train the model with Keras `Model.fit`.\n",
    "\n",
    "The validation_split=0.2 argument in the fit method of the Keras API indicates that 20% of the training data should be set aside for validation. The model will train on 80% of the data and evaluate its performance on the remaining 20% to monitor for issues like overfitting. This validation set is not used to update the model's weights; it's only for evaluation purposes to give an estimate of the model's performance on unseen data.\n",
    "\n",
    "The verbose parameter controls how much information the training process outputs to the console. Setting verbose=0 means that you won’t see any logging output during training, which can be useful if you don't need to track the training process in detail and want to avoid cluttering your console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "66eccda2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-24 19:58:55.809772: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.56 s, sys: 1.03 s, total: 3.59 s\n",
      "Wall time: 2.28 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history_entrance = dnn_model.fit(\n",
    "    train_features_entrance,\n",
    "    train_labels_entrance,\n",
    "    validation_split=0.2,\n",
    "    verbose=0, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "73ea7bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.44 s, sys: 990 ms, total: 3.43 s\n",
      "Wall time: 2.19 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history_exit = dnn_model.fit(\n",
    "    train_features_exit,\n",
    "    train_labels_exit,\n",
    "    validation_split=0.2,\n",
    "    verbose=0, epochs=100) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d46c66",
   "metadata": {},
   "source": [
    "### Visualize the model's training progress in DNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d182f5f",
   "metadata": {},
   "source": [
    "Visualize the model's training progress using the stats stored in the `history` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "39113f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(history_entrance):\n",
    "  plt.plot(history_entrance.history['loss'], label='Training loss')\n",
    "  plt.plot(history_entrance.history['val_loss'], label='Validation loss')\n",
    "  plt.ylim([0, 100])\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('Error [Temperature (°F)]')\n",
    "  plt.title('Training progress in DNN model for MAU entrance')\n",
    "  plt.legend()\n",
    "  plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b62084fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss(history_entrance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4657bd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(history_exit):\n",
    "  plt.plot(history_exit.history['loss'], label='Training loss')\n",
    "  plt.plot(history_exit.history['val_loss'], label='Validation loss')\n",
    "  plt.ylim([0, 2])\n",
    "  plt.xlim([0, 100])\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('Error [Temperature (°F)]')\n",
    "  plt.title('Training progress in DNN model for MAU exit')\n",
    "  plt.legend()\n",
    "  plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "89c506f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plot_loss(history_exit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298aa32c",
   "metadata": {},
   "source": [
    "### Collect the results on the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b205b1",
   "metadata": {},
   "source": [
    "#### MAU entrance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f4dbd181",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(340, 4)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_features_entrance = np.asarray(test_features_entrance).astype(np.float32)\n",
    "test_features_entrance.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "fa2521ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dnn_model': 4.927254676818848}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results_entrance = {}\n",
    "test_results_entrance['dnn_model'] = dnn_model.evaluate(test_features_entrance, test_labels_entrance, verbose=0)\n",
    "test_results_entrance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "86a9c752",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 4)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#original\n",
    "ori_test_features_entrance = np.asarray(ori_test_features_entrance).astype(np.float32)\n",
    "ori_test_features_entrance.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "70ddc098",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dnn_model': 6.273030757904053}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ori_test_results_entrance = {}\n",
    "ori_test_results_entrance['dnn_model'] = dnn_model.evaluate(ori_test_features_entrance, ori_test_labels_entrance, verbose=0)\n",
    "ori_test_results_entrance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e20fa7",
   "metadata": {},
   "source": [
    "#### MAU exit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c1d5a3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features_exit = np.asarray(test_features_exit).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1d5d13e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dnn_model': 0.23160427808761597}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results_exit = {}\n",
    "test_results_exit['dnn_model'] = dnn_model.evaluate(test_features_exit, test_labels_exit, verbose=0)\n",
    "test_results_exit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "776c748c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 4)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#original\n",
    "ori_test_features_exit = np.asarray(ori_test_features_exit).astype(np.float32)\n",
    "ori_test_features_exit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "df88e434",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dnn_model': 0.10655975341796875}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ori_test_results_exit = {}\n",
    "ori_test_results_exit['dnn_model'] = dnn_model.evaluate(ori_test_features_exit, ori_test_labels_exit, verbose=0)\n",
    "ori_test_results_exit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09606ee2",
   "metadata": {},
   "source": [
    "## Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "35c1fff3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean absolute error [Temperature]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dnn_model</th>\n",
       "      <td>4.927255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Mean absolute error [Temperature]\n",
       "dnn_model                           4.927255"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(test_results_entrance, index=['Mean absolute error [Temperature]']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e86c2eb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean absolute error [Temperature]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dnn_model</th>\n",
       "      <td>6.273031</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Mean absolute error [Temperature]\n",
       "dnn_model                           6.273031"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# original\n",
    "pd.DataFrame(ori_test_results_entrance, index=['Mean absolute error [Temperature]']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4ad1c10f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean absolute error [Temperature]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dnn_model</th>\n",
       "      <td>0.231604</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Mean absolute error [Temperature]\n",
       "dnn_model                           0.231604"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(test_results_exit, index=['Mean absolute error [Temperature]']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "91a68fc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean absolute error [Temperature]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dnn_model</th>\n",
       "      <td>0.10656</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Mean absolute error [Temperature]\n",
       "dnn_model                            0.10656"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#original\n",
    "pd.DataFrame(ori_test_results_exit, index=['Mean absolute error [Temperature]']).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5853fab4",
   "metadata": {},
   "source": [
    "### Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "39d7f904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 335us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([76.144, 77.7  , 81.915, 80.277, 76.267, 82.197, 78.81 , 85.697,\n",
       "       82.108, 84.015, 77.306, 78.866, 84.704, 84.609, 73.015, 78.816,\n",
       "       84.515, 85.79 , 77.369, 80.356, 84.047, 82.461, 81.612, 84.658,\n",
       "       83.894, 82.48 , 85.458, 84.519, 83.824, 82.918, 75.946, 71.963,\n",
       "       84.506, 82.821, 76.07 , 82.537, 82.1  , 81.993, 76.288, 82.302,\n",
       "       82.077, 78.871, 84.527, 77.434, 83.106, 85.521, 83.029, 82.353,\n",
       "       81.279, 78.783, 84.462, 73.007, 80.213, 82.344, 72.134, 76.234,\n",
       "       82.464, 77.666, 84.562, 85.332, 84.691, 85.593, 84.345, 73.289,\n",
       "       81.317, 82.165, 84.653, 85.554, 82.242, 80.238, 84.766, 80.421,\n",
       "       72.125, 84.254, 77.443, 82.394, 72.044, 84.758, 76.153, 82.366,\n",
       "       78.603, 84.466, 83.947, 82.359, 81.099, 82.129, 82.155, 84.782,\n",
       "       73.511, 80.321, 85.612, 77.469, 80.586, 82.602, 82.859, 84.777,\n",
       "       82.247, 72.992, 82.196, 78.778, 72.033, 84.455, 82.272, 82.907,\n",
       "       78.586, 71.919, 84.631, 81.826, 76.322, 82.153, 82.152, 79.119,\n",
       "       84.44 , 77.387, 82.589, 78.979, 84.456, 84.701, 73.101, 76.191,\n",
       "       82.163, 78.791, 73.203, 75.955, 78.49 , 84.811, 80.434, 83.036,\n",
       "       78.868, 82.355, 71.94 , 82.822, 82.48 , 84.457, 78.886, 72.114,\n",
       "       84.66 , 80.133, 82.167, 71.76 , 72.967, 82.423, 78.696, 84.577,\n",
       "       84.685, 80.253, 84.453, 85.711, 81.872, 80.49 , 82.413, 71.743,\n",
       "       85.483, 73.075, 84.059, 82.523, 82.288, 81.232, 72.221, 84.001,\n",
       "       82.095, 84.484, 84.574, 72.963, 82.041, 80.415, 82.741, 82.401,\n",
       "       71.982, 73.09 , 85.564, 83.154, 82.536, 78.947, 72.033, 83.798,\n",
       "       82.898, 82.159, 84.579, 73.218, 83.938, 82.067, 84.72 , 85.541,\n",
       "       84.909, 73.181, 83.011, 81.817, 80.241, 83.93 , 78.649, 84.433,\n",
       "       82.253, 82.866, 82.349, 81.247, 72.012, 85.532, 84.714, 82.399,\n",
       "       82.183, 84.493, 84.547, 81.921, 83.998, 84.628, 84.522, 71.999,\n",
       "       85.546, 82.661, 82.227, 72.202, 84.682, 77.35 , 78.935, 77.538,\n",
       "       76.222, 82.394, 82.453, 80.976, 72.108, 77.344, 76.374, 81.085,\n",
       "       77.472, 78.574, 84.672, 85.581, 77.39 , 82.132, 82.443, 81.198,\n",
       "       82.306, 78.921, 85.489, 84.624, 82.435, 81.074, 78.768, 77.601,\n",
       "       76.167, 82.063, 78.565, 84.573, 80.014, 76.103, 81.277, 78.695,\n",
       "       72.067, 84.46 , 80.541, 84.014, 82.255, 81.238, 71.73 , 83.857,\n",
       "       83.019, 76.394, 81.203, 84.423, 84.071, 81.178, 84.443, 72.99 ,\n",
       "       82.431, 84.614, 84.464, 81.899, 84.572, 73.23 , 82.38 , 85.487,\n",
       "       84.59 , 82.242, 83.748, 73.061, 82.074, 75.956, 82.418, 84.805,\n",
       "       77.504, 82.258, 84.788, 77.462, 76.377, 82.433, 77.493, 82.154,\n",
       "       84.067, 82.304, 84.529, 77.37 , 81.873, 71.91 , 83.083, 82.371,\n",
       "       72.275, 84.607, 82.025, 83.021, 81.318, 84.609, 77.633, 83.841,\n",
       "       81.302, 71.999, 81.199, 78.713, 85.571, 82.488, 77.609, 80.262,\n",
       "       78.818, 84.74 , 73.247, 77.45 , 81.887, 84.161, 84.584, 83.303,\n",
       "       81.193, 78.649, 84.369, 80.328, 73.122, 84.359, 82.166, 84.05 ,\n",
       "       82.778, 82.276, 76.072, 82.413, 84.584, 72.83 , 81.879, 76.249,\n",
       "       73.01 , 80.208, 84.59 , 76.039], dtype=float32)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions_entrance = dnn_model.predict(test_features_entrance).flatten()\n",
    "test_predictions_entrance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7f90c0c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 7ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([73.135, 82.318, 82.233], dtype=float32)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# original\n",
    "ori_test_predictions_entrance = dnn_model.predict(ori_test_features_entrance).flatten()\n",
    "ori_test_predictions_entrance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "8f24baf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 312us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([74.188, 74.619, 74.607, 73.759, 74.258, 75.127, 75.36 , 75.351,\n",
       "       74.66 , 75.301, 74.638, 75.373, 74.754, 75.212, 75.308, 75.453,\n",
       "       74.768, 75.422, 74.993, 73.873, 75.182, 75.483, 74.772, 75.226,\n",
       "       75.094, 75.167, 75.333, 74.742, 75.223, 75.057, 74.661, 75.08 ,\n",
       "       75.071, 75.167, 74.126, 75.247, 74.925, 74.7  , 74.159, 75.15 ,\n",
       "       75.142, 75.641, 75.211, 74.653, 75.259, 75.437, 75.066, 74.881,\n",
       "       75.132, 75.647, 74.987, 75.056, 73.7  , 74.858, 75.09 , 74.235,\n",
       "       75.141, 74.452, 74.873, 75.221, 74.663, 75.464, 74.684, 75.133,\n",
       "       75.109, 75.054, 74.648, 75.322, 74.548, 73.775, 74.662, 73.992,\n",
       "       74.98 , 74.79 , 74.754, 74.872, 74.92 , 74.817, 74.36 , 75.363,\n",
       "       75.517, 75.032, 75.151, 75.189, 74.796, 74.569, 74.8  , 74.865,\n",
       "       75.056, 73.565, 75.428, 74.456, 73.579, 75.442, 75.03 , 74.995,\n",
       "       74.622, 75.043, 75.085, 75.256, 75.072, 75.211, 74.701, 75.301,\n",
       "       75.464, 75.102, 75.132, 74.646, 74.394, 74.787, 74.967, 75.433,\n",
       "       74.896, 74.626, 75.233, 75.409, 75.059, 74.916, 74.941, 74.171,\n",
       "       74.79 , 75.282, 74.923, 74.279, 75.182, 74.913, 73.67 , 75.127,\n",
       "       75.594, 75.367, 75.237, 75.108, 75.127, 75.095, 75.454, 75.215,\n",
       "       75.195, 73.435, 75.402, 75.169, 74.99 , 74.896, 75.369, 74.919,\n",
       "       74.907, 73.816, 74.782, 75.501, 74.852, 73.548, 74.982, 75.216,\n",
       "       75.385, 75.173, 75.311, 74.757, 75.02 , 75.223, 74.806, 75.117,\n",
       "       75.096, 74.849, 75.11 , 75.086, 74.71 , 73.716, 75.173, 75.338,\n",
       "       74.77 , 75.059, 75.488, 74.864, 74.967, 75.516, 75.061, 75.141,\n",
       "       75.176, 74.818, 74.783, 75.103, 75.434, 74.9  , 74.989, 75.487,\n",
       "       75.007, 75.235, 75.343, 74.623, 73.925, 75.194, 75.617, 74.644,\n",
       "       74.734, 74.967, 75.317, 74.813, 74.994, 75.409, 74.883, 74.591,\n",
       "       74.871, 74.971, 74.934, 74.44 , 75.069, 74.503, 75.108, 74.82 ,\n",
       "       75.662, 75.276, 75.004, 74.905, 75.165, 74.377, 75.41 , 74.407,\n",
       "       74.18 , 74.951, 75.454, 74.669, 74.94 , 74.667, 74.351, 74.939,\n",
       "       74.429, 75.414, 74.715, 75.389, 74.612, 74.651, 74.789, 74.895,\n",
       "       74.848, 75.437, 75.437, 75.11 , 75.139, 74.882, 75.359, 74.573,\n",
       "       74.555, 74.807, 75.5  , 74.844, 73.875, 74.265, 75.091, 75.36 ,\n",
       "       75.192, 74.895, 73.792, 75.293, 74.85 , 74.867, 75.04 , 75.291,\n",
       "       75.106, 74.398, 75.137, 75.204, 75.229, 75.044, 74.904, 75.177,\n",
       "       74.973, 74.864, 74.951, 74.79 , 74.921, 75.1  , 74.603, 75.318,\n",
       "       74.947, 74.801, 75.125, 75.494, 74.644, 74.373, 75.205, 75.099,\n",
       "       74.808, 74.951, 74.83 , 74.535, 74.194, 75.045, 74.597, 74.619,\n",
       "       75.238, 74.985, 74.868, 74.628, 74.72 , 75.063, 75.149, 75.049,\n",
       "       75.03 , 75.199, 74.694, 75.257, 75.087, 74.948, 74.334, 75.001,\n",
       "       74.756, 74.857, 74.737, 75.354, 75.353, 75.245, 74.828, 73.617,\n",
       "       75.507, 75.186, 75.071, 74.727, 74.464, 74.55 , 74.897, 74.98 ,\n",
       "       75.03 , 75.289, 74.937, 73.488, 75.116, 74.943, 74.811, 75.183,\n",
       "       74.864, 75.054, 74.406, 75.024, 75.083, 75.044, 74.621, 74.245,\n",
       "       75.263, 73.691, 74.915, 74.174], dtype=float32)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions_exit = dnn_model.predict(test_features_exit).flatten()\n",
    "test_predictions_exit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6ef9be09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 7ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([75.099, 74.957, 74.955], dtype=float32)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# original\n",
    "ori_test_predictions_exit = dnn_model.predict(ori_test_features_exit).flatten()\n",
    "ori_test_predictions_exit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "27f0962c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11     -2.425682\n",
       "23     -3.079515\n",
       "24     -5.844732\n",
       "25     -5.383389\n",
       "28     -2.303353\n",
       "          ...   \n",
       "1660   -2.320549\n",
       "1671   -2.530005\n",
       "1674   -5.451672\n",
       "1684   -2.809874\n",
       "1694   -2.530953\n",
       "Name: Temperature (Â°F), Length: 340, dtype: float64"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_entrance = test_predictions_entrance - test_labels_entrance\n",
    "error_entrance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "aea14cb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    -2.405402\n",
       "12   -8.452381\n",
       "15   -7.961303\n",
       "Name: Temperature (°F), dtype: float64"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# original\n",
    "ori_error_entrance = ori_test_predictions_entrance - ori_test_labels_entrance\n",
    "ori_error_entrance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c6df03d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(error_entrance, bins=25)\n",
    "plt.xlabel('Prediction Error [Temperature]')\n",
    "_ = plt.ylabel('Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "de1919f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# original\n",
    "plt.hist(ori_error_entrance, bins=25)\n",
    "plt.xlabel('Prediction Error [Temperature]')\n",
    "_ = plt.ylabel('Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "61995131",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11     -0.328180\n",
       "23     -0.256936\n",
       "24     -0.196670\n",
       "25     -1.135409\n",
       "28     -0.257669\n",
       "          ...   \n",
       "1660   -0.271043\n",
       "1671    0.153329\n",
       "1674   -1.202884\n",
       "1684   -0.069205\n",
       "1694   -0.341806\n",
       "Name: Temperature (Â°F), Length: 340, dtype: float64"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_exit = test_predictions_exit - test_labels_exit\n",
    "error_exit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "95f0ecb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    -0.010871\n",
       "12   -0.117350\n",
       "15   -0.191448\n",
       "Name: Temperature (°F), dtype: float64"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# original\n",
    "ori_error_exit = ori_test_predictions_exit - ori_test_labels_exit\n",
    "ori_error_exit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "6066fedc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(error_exit, bins=25)\n",
    "plt.xlabel('Prediction Error [Temperature]')\n",
    "_ = plt.ylabel('Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e8cd42a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# original\n",
    "plt.hist(ori_error_exit, bins=25)\n",
    "plt.xlabel('Prediction Error [Temperature]')\n",
    "_ = plt.ylabel('Count')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fa24a0",
   "metadata": {},
   "source": [
    "#### Average error (AE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8c90bb",
   "metadata": {},
   "source": [
    "AE: Provide a measure of bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d98de95a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average error: -4.927254446590648\n"
     ]
    }
   ],
   "source": [
    "average_error_entrance = np.mean(error_entrance)\n",
    "print(\"Average error:\", average_error_entrance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "f65107c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average error: -6.273028788248699\n"
     ]
    }
   ],
   "source": [
    "# original\n",
    "ori_average_error_entrance = np.mean(ori_error_entrance)\n",
    "print(\"Average error:\", ori_average_error_entrance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "f3634dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average error: -0.09636714872472413\n"
     ]
    }
   ],
   "source": [
    "average_error_exit = np.mean(error_exit)\n",
    "print(\"Average error:\", average_error_exit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "003f2745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average error: -0.10655659993489526\n"
     ]
    }
   ],
   "source": [
    "# original\n",
    "ori_average_error_exit = np.mean(ori_error_exit)\n",
    "print(\"Average error:\", ori_average_error_exit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58aee21",
   "metadata": {},
   "source": [
    "#### Mean squared error (MSE) and mean absolute error (MAE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef604f2d",
   "metadata": {},
   "source": [
    "MSE: Penalize significant errors more heavily \\\n",
    "MAE: Provide a measure of the average magnitude of errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "33b9d2af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 29.927871971627546\n",
      "Mean Absolute Error: 4.927254446590648\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mse = mean_squared_error(test_labels_entrance, test_predictions_entrance)\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "mae = mean_absolute_error(test_labels_entrance, test_predictions_entrance)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Mean Absolute Error:\", mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "d3570a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 46.87035061168937\n",
      "Mean Absolute Error: 6.273028788248699\n"
     ]
    }
   ],
   "source": [
    "# original\n",
    "ori_mse = mean_squared_error(ori_test_labels_entrance, ori_test_predictions_entrance)\n",
    "ori_mae = mean_absolute_error(ori_test_labels_entrance, ori_test_predictions_entrance)\n",
    "print(\"Mean Squared Error:\", ori_mse)\n",
    "print(\"Mean Absolute Error:\", ori_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "aa516341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.11973011652916586\n",
      "Mean Absolute Error: 0.23160438914579548\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mse = mean_squared_error(test_labels_exit, test_predictions_exit)\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "mae = mean_absolute_error(test_labels_exit, test_predictions_exit)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Mean Absolute Error:\", mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "4bc4e4bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.016847237179058238\n",
      "Mean Absolute Error: 0.10655659993489526\n"
     ]
    }
   ],
   "source": [
    "# original\n",
    "ori_mse = mean_squared_error(ori_test_labels_exit, ori_test_predictions_exit)\n",
    "ori_mae = mean_absolute_error(ori_test_labels_exit, ori_test_predictions_exit)\n",
    "print(\"Mean Squared Error:\", ori_mse)\n",
    "print(\"Mean Absolute Error:\", ori_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "4beb1cd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE: 5.66%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def mean_absolute_percentage_error(y_actual, y_pred):\n",
    "    y_actual, y_pred = np.array(y_actual), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_actual - y_pred) / y_actual)) * 100\n",
    "\n",
    "mape = mean_absolute_percentage_error(test_labels_entrance, test_predictions_entrance)\n",
    "print(f'MAPE: {mape:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "e7317a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE: 7.11%\n"
     ]
    }
   ],
   "source": [
    "# original\n",
    "mape = mean_absolute_percentage_error(ori_test_labels_entrance, ori_test_predictions_entrance)\n",
    "print(f'MAPE: {mape:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "ed1eb16d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE: 0.31%\n"
     ]
    }
   ],
   "source": [
    "mape = mean_absolute_percentage_error(test_labels_exit, test_predictions_exit)\n",
    "print(f'MAPE: {mape:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "27375966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE: 0.14%\n"
     ]
    }
   ],
   "source": [
    "mape = mean_absolute_percentage_error(ori_test_labels_exit, ori_test_predictions_exit)\n",
    "print(f'MAPE: {mape:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a997e0f",
   "metadata": {},
   "source": [
    "# Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "483aab5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-24 19:59:01,290] A new study created in memory with name: no-name-e54d593b-361c-4d04-96fc-705b3c0ef4d3\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6404/2147256317.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:59:08,181] Trial 0 finished with value: 0.5570507794618607 and parameters: {'num_layers': 5, 'num_neurons_layer_0': 92, 'num_neurons_layer_1': 48, 'num_neurons_layer_2': 68, 'num_neurons_layer_3': 100, 'num_neurons_layer_4': 24, 'learning_rate': 0.0008415547054936021, 'activation': 'relu'}. Best is trial 0 with value: 0.5570507794618607.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6404/2147256317.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:59:15,494] Trial 1 finished with value: 0.7986577600240707 and parameters: {'num_layers': 5, 'num_neurons_layer_0': 108, 'num_neurons_layer_1': 128, 'num_neurons_layer_2': 128, 'num_neurons_layer_3': 24, 'num_neurons_layer_4': 80, 'learning_rate': 0.004053866838040277, 'activation': 'tanh'}. Best is trial 0 with value: 0.5570507794618607.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6404/2147256317.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:59:21,174] Trial 2 finished with value: 0.5595938861370087 and parameters: {'num_layers': 3, 'num_neurons_layer_0': 124, 'num_neurons_layer_1': 32, 'num_neurons_layer_2': 76, 'learning_rate': 0.0004240198436130544, 'activation': 'relu'}. Best is trial 0 with value: 0.5570507794618607.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6404/2147256317.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:59:26,565] Trial 3 finished with value: 56.18984031677246 and parameters: {'num_layers': 2, 'num_neurons_layer_0': 96, 'num_neurons_layer_1': 36, 'learning_rate': 0.00013815416013714585, 'activation': 'tanh'}. Best is trial 0 with value: 0.5570507794618607.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6404/2147256317.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:59:32,765] Trial 4 finished with value: 1.5932369232177734 and parameters: {'num_layers': 4, 'num_neurons_layer_0': 60, 'num_neurons_layer_1': 72, 'num_neurons_layer_2': 40, 'num_neurons_layer_3': 84, 'learning_rate': 0.007291157356916283, 'activation': 'relu'}. Best is trial 0 with value: 0.5570507794618607.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6404/2147256317.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:59:39,388] Trial 5 finished with value: 0.7583253681659698 and parameters: {'num_layers': 4, 'num_neurons_layer_0': 44, 'num_neurons_layer_1': 120, 'num_neurons_layer_2': 40, 'num_neurons_layer_3': 72, 'learning_rate': 0.0010527771266267394, 'activation': 'relu'}. Best is trial 0 with value: 0.5570507794618607.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6404/2147256317.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:59:43,812] Trial 6 finished with value: 0.6016537845134735 and parameters: {'num_layers': 1, 'num_neurons_layer_0': 56, 'learning_rate': 0.006388909244599878, 'activation': 'relu'}. Best is trial 0 with value: 0.5570507794618607.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6404/2147256317.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:59:51,085] Trial 7 finished with value: 0.5303560048341751 and parameters: {'num_layers': 4, 'num_neurons_layer_0': 124, 'num_neurons_layer_1': 84, 'num_neurons_layer_2': 108, 'num_neurons_layer_3': 104, 'learning_rate': 0.0012747146584220451, 'activation': 'relu'}. Best is trial 7 with value: 0.5303560048341751.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6404/2147256317.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:59:58,638] Trial 8 finished with value: 67.7089786529541 and parameters: {'num_layers': 5, 'num_neurons_layer_0': 16, 'num_neurons_layer_1': 104, 'num_neurons_layer_2': 116, 'num_neurons_layer_3': 116, 'num_neurons_layer_4': 16, 'learning_rate': 0.0001253304655021965, 'activation': 'tanh'}. Best is trial 7 with value: 0.5303560048341751.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6404/2147256317.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:00:06,714] Trial 9 finished with value: 29.388821601867676 and parameters: {'num_layers': 5, 'num_neurons_layer_0': 124, 'num_neurons_layer_1': 52, 'num_neurons_layer_2': 68, 'num_neurons_layer_3': 108, 'num_neurons_layer_4': 56, 'learning_rate': 0.00021563817211057526, 'activation': 'tanh'}. Best is trial 7 with value: 0.5303560048341751.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6404/2147256317.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:00:12,982] Trial 10 finished with value: 0.8223410546779633 and parameters: {'num_layers': 3, 'num_neurons_layer_0': 84, 'num_neurons_layer_1': 88, 'num_neurons_layer_2': 100, 'learning_rate': 0.0020023824893704674, 'activation': 'relu'}. Best is trial 7 with value: 0.5303560048341751.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6404/2147256317.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:00:19,955] Trial 11 finished with value: 0.5006768703460693 and parameters: {'num_layers': 4, 'num_neurons_layer_0': 104, 'num_neurons_layer_1': 64, 'num_neurons_layer_2': 80, 'num_neurons_layer_3': 88, 'learning_rate': 0.0006987797390902408, 'activation': 'relu'}. Best is trial 11 with value: 0.5006768703460693.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6404/2147256317.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:00:26,965] Trial 12 finished with value: 0.49343812465667725 and parameters: {'num_layers': 4, 'num_neurons_layer_0': 112, 'num_neurons_layer_1': 72, 'num_neurons_layer_2': 96, 'num_neurons_layer_3': 68, 'learning_rate': 0.0006412100647949428, 'activation': 'relu'}. Best is trial 12 with value: 0.49343812465667725.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6404/2147256317.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:00:33,654] Trial 13 finished with value: 0.4918321967124939 and parameters: {'num_layers': 4, 'num_neurons_layer_0': 104, 'num_neurons_layer_1': 64, 'num_neurons_layer_2': 84, 'num_neurons_layer_3': 56, 'learning_rate': 0.0004250619975704975, 'activation': 'relu'}. Best is trial 13 with value: 0.4918321967124939.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6404/2147256317.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:00:38,702] Trial 14 finished with value: 0.5865670740604401 and parameters: {'num_layers': 2, 'num_neurons_layer_0': 76, 'num_neurons_layer_1': 16, 'learning_rate': 0.0003403503719337083, 'activation': 'relu'}. Best is trial 13 with value: 0.4918321967124939.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6404/2147256317.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:00:44,899] Trial 15 finished with value: 0.5388591587543488 and parameters: {'num_layers': 3, 'num_neurons_layer_0': 108, 'num_neurons_layer_1': 84, 'num_neurons_layer_2': 92, 'learning_rate': 0.00041307252497605406, 'activation': 'relu'}. Best is trial 13 with value: 0.4918321967124939.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6404/2147256317.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:00:51,611] Trial 16 finished with value: 0.603728324174881 and parameters: {'num_layers': 4, 'num_neurons_layer_0': 112, 'num_neurons_layer_1': 60, 'num_neurons_layer_2': 56, 'num_neurons_layer_3': 48, 'learning_rate': 0.002200736782580763, 'activation': 'relu'}. Best is trial 13 with value: 0.4918321967124939.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6404/2147256317.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:00:57,016] Trial 17 finished with value: 0.6585977971553802 and parameters: {'num_layers': 2, 'num_neurons_layer_0': 84, 'num_neurons_layer_1': 100, 'learning_rate': 0.0002660182816074564, 'activation': 'relu'}. Best is trial 13 with value: 0.4918321967124939.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6404/2147256317.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:01:03,586] Trial 18 finished with value: 1.7397026233375072 and parameters: {'num_layers': 4, 'num_neurons_layer_0': 68, 'num_neurons_layer_1': 76, 'num_neurons_layer_2': 16, 'num_neurons_layer_3': 56, 'learning_rate': 0.0005901854206406938, 'activation': 'tanh'}. Best is trial 13 with value: 0.4918321967124939.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6404/2147256317.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:01:09,454] Trial 19 finished with value: 0.6233415007591248 and parameters: {'num_layers': 3, 'num_neurons_layer_0': 32, 'num_neurons_layer_1': 100, 'num_neurons_layer_2': 92, 'learning_rate': 0.00020400878143156184, 'activation': 'relu'}. Best is trial 13 with value: 0.4918321967124939.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6404/2147256317.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:01:14,106] Trial 20 finished with value: 0.5443441569805145 and parameters: {'num_layers': 1, 'num_neurons_layer_0': 96, 'learning_rate': 0.0016390299270812971, 'activation': 'relu'}. Best is trial 13 with value: 0.4918321967124939.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6404/2147256317.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:01:20,759] Trial 21 finished with value: 0.4135911464691162 and parameters: {'num_layers': 4, 'num_neurons_layer_0': 112, 'num_neurons_layer_1': 68, 'num_neurons_layer_2': 88, 'num_neurons_layer_3': 68, 'learning_rate': 0.0006598229228239862, 'activation': 'relu'}. Best is trial 21 with value: 0.4135911464691162.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6404/2147256317.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:01:27,398] Trial 22 finished with value: 0.6608028560876846 and parameters: {'num_layers': 4, 'num_neurons_layer_0': 116, 'num_neurons_layer_1': 68, 'num_neurons_layer_2': 84, 'num_neurons_layer_3': 56, 'learning_rate': 0.0005785297173630383, 'activation': 'relu'}. Best is trial 21 with value: 0.4135911464691162.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6404/2147256317.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:01:33,442] Trial 23 finished with value: 0.5593795329332352 and parameters: {'num_layers': 3, 'num_neurons_layer_0': 128, 'num_neurons_layer_1': 52, 'num_neurons_layer_2': 104, 'learning_rate': 0.0005022606669553768, 'activation': 'relu'}. Best is trial 21 with value: 0.4135911464691162.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6404/2147256317.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:01:40,684] Trial 24 finished with value: 1.847203254699707 and parameters: {'num_layers': 5, 'num_neurons_layer_0': 100, 'num_neurons_layer_1': 40, 'num_neurons_layer_2': 92, 'num_neurons_layer_3': 36, 'num_neurons_layer_4': 124, 'learning_rate': 0.0030078272745723703, 'activation': 'relu'}. Best is trial 21 with value: 0.4135911464691162.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6404/2147256317.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:01:47,533] Trial 25 finished with value: 0.47387704253196716 and parameters: {'num_layers': 4, 'num_neurons_layer_0': 116, 'num_neurons_layer_1': 60, 'num_neurons_layer_2': 116, 'num_neurons_layer_3': 72, 'learning_rate': 0.001083787249010025, 'activation': 'relu'}. Best is trial 21 with value: 0.4135911464691162.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6404/2147256317.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:01:54,428] Trial 26 finished with value: 0.36335501074790955 and parameters: {'num_layers': 4, 'num_neurons_layer_0': 88, 'num_neurons_layer_1': 60, 'num_neurons_layer_2': 128, 'num_neurons_layer_3': 80, 'learning_rate': 0.0013396397485392203, 'activation': 'tanh'}. Best is trial 26 with value: 0.36335501074790955.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6404/2147256317.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:02:02,093] Trial 27 finished with value: 0.43111634254455566 and parameters: {'num_layers': 5, 'num_neurons_layer_0': 84, 'num_neurons_layer_1': 24, 'num_neurons_layer_2': 128, 'num_neurons_layer_3': 76, 'num_neurons_layer_4': 120, 'learning_rate': 0.0011560173673471844, 'activation': 'tanh'}. Best is trial 26 with value: 0.36335501074790955.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6404/2147256317.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:02:10,135] Trial 28 finished with value: 0.6501554250717163 and parameters: {'num_layers': 5, 'num_neurons_layer_0': 84, 'num_neurons_layer_1': 44, 'num_neurons_layer_2': 124, 'num_neurons_layer_3': 88, 'num_neurons_layer_4': 124, 'learning_rate': 0.001462947988841545, 'activation': 'tanh'}. Best is trial 26 with value: 0.36335501074790955.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6404/2147256317.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:02:17,564] Trial 29 finished with value: 1.7428291253745556 and parameters: {'num_layers': 5, 'num_neurons_layer_0': 88, 'num_neurons_layer_1': 20, 'num_neurons_layer_2': 112, 'num_neurons_layer_3': 80, 'num_neurons_layer_4': 84, 'learning_rate': 0.000824067440384574, 'activation': 'tanh'}. Best is trial 26 with value: 0.36335501074790955.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6404/2147256317.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:02:25,168] Trial 30 finished with value: 1.4525761678814888 and parameters: {'num_layers': 5, 'num_neurons_layer_0': 68, 'num_neurons_layer_1': 32, 'num_neurons_layer_2': 128, 'num_neurons_layer_3': 64, 'num_neurons_layer_4': 100, 'learning_rate': 0.003175783091533733, 'activation': 'tanh'}. Best is trial 26 with value: 0.36335501074790955.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6404/2147256317.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:02:32,183] Trial 31 finished with value: 0.3679780922830105 and parameters: {'num_layers': 4, 'num_neurons_layer_0': 92, 'num_neurons_layer_1': 56, 'num_neurons_layer_2': 124, 'num_neurons_layer_3': 72, 'learning_rate': 0.0010819829504078596, 'activation': 'tanh'}. Best is trial 26 with value: 0.36335501074790955.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6404/2147256317.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:02:39,775] Trial 32 finished with value: 1.7399519197642803 and parameters: {'num_layers': 5, 'num_neurons_layer_0': 76, 'num_neurons_layer_1': 52, 'num_neurons_layer_2': 120, 'num_neurons_layer_3': 76, 'num_neurons_layer_4': 48, 'learning_rate': 0.0008441439149671927, 'activation': 'tanh'}. Best is trial 26 with value: 0.36335501074790955.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6404/2147256317.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:02:45,933] Trial 33 finished with value: 0.28102970495820045 and parameters: {'num_layers': 3, 'num_neurons_layer_0': 92, 'num_neurons_layer_1': 24, 'num_neurons_layer_2': 128, 'learning_rate': 0.001972231333306555, 'activation': 'tanh'}. Best is trial 33 with value: 0.28102970495820045.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6404/2147256317.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:02:52,110] Trial 34 finished with value: 0.10807193070650101 and parameters: {'num_layers': 3, 'num_neurons_layer_0': 92, 'num_neurons_layer_1': 48, 'num_neurons_layer_2': 108, 'learning_rate': 0.002118820939893383, 'activation': 'tanh'}. Best is trial 34 with value: 0.10807193070650101.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6404/2147256317.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:02:58,162] Trial 35 finished with value: 0.2786802798509598 and parameters: {'num_layers': 3, 'num_neurons_layer_0': 92, 'num_neurons_layer_1': 28, 'num_neurons_layer_2': 120, 'learning_rate': 0.004500154958386179, 'activation': 'tanh'}. Best is trial 34 with value: 0.10807193070650101.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6404/2147256317.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:03:03,567] Trial 36 finished with value: 0.22688952460885048 and parameters: {'num_layers': 2, 'num_neurons_layer_0': 96, 'num_neurons_layer_1': 28, 'learning_rate': 0.004511702989066995, 'activation': 'tanh'}. Best is trial 34 with value: 0.10807193070650101.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6404/2147256317.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:03:08,701] Trial 37 finished with value: 0.7631734199821949 and parameters: {'num_layers': 2, 'num_neurons_layer_0': 96, 'num_neurons_layer_1': 28, 'learning_rate': 0.0099027805639237, 'activation': 'tanh'}. Best is trial 34 with value: 0.10807193070650101.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6404/2147256317.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:03:13,610] Trial 38 finished with value: 0.30578405037522316 and parameters: {'num_layers': 2, 'num_neurons_layer_0': 72, 'num_neurons_layer_1': 36, 'learning_rate': 0.005000553739830468, 'activation': 'tanh'}. Best is trial 34 with value: 0.10807193070650101.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6404/2147256317.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:03:19,208] Trial 39 finished with value: 0.41914601996541023 and parameters: {'num_layers': 3, 'num_neurons_layer_0': 100, 'num_neurons_layer_1': 16, 'num_neurons_layer_2': 104, 'learning_rate': 0.003986546038604475, 'activation': 'tanh'}. Best is trial 34 with value: 0.10807193070650101.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6404/2147256317.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:03:23,552] Trial 40 finished with value: 0.26186301186680794 and parameters: {'num_layers': 2, 'num_neurons_layer_0': 60, 'num_neurons_layer_1': 28, 'learning_rate': 0.002496555856658211, 'activation': 'tanh'}. Best is trial 34 with value: 0.10807193070650101.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6404/2147256317.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:03:27,926] Trial 41 finished with value: 0.2928758077323437 and parameters: {'num_layers': 2, 'num_neurons_layer_0': 60, 'num_neurons_layer_1': 28, 'learning_rate': 0.00257302183382831, 'activation': 'tanh'}. Best is trial 34 with value: 0.10807193070650101.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6404/2147256317.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:03:32,325] Trial 42 finished with value: 0.3209781385958195 and parameters: {'num_layers': 2, 'num_neurons_layer_0': 48, 'num_neurons_layer_1': 44, 'learning_rate': 0.00462438845581848, 'activation': 'tanh'}. Best is trial 34 with value: 0.10807193070650101.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6404/2147256317.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:03:36,168] Trial 43 finished with value: 0.4608282968401909 and parameters: {'num_layers': 1, 'num_neurons_layer_0': 52, 'learning_rate': 0.0035372988998057654, 'activation': 'tanh'}. Best is trial 34 with value: 0.10807193070650101.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6404/2147256317.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:03:41,176] Trial 44 finished with value: 0.3362283334136009 and parameters: {'num_layers': 3, 'num_neurons_layer_0': 40, 'num_neurons_layer_1': 24, 'num_neurons_layer_2': 68, 'learning_rate': 0.006416498338378429, 'activation': 'tanh'}. Best is trial 34 with value: 0.10807193070650101.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6404/2147256317.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:03:46,913] Trial 45 finished with value: 0.2933061420917511 and parameters: {'num_layers': 3, 'num_neurons_layer_0': 80, 'num_neurons_layer_1': 36, 'num_neurons_layer_2': 56, 'learning_rate': 0.0018173212250261347, 'activation': 'tanh'}. Best is trial 34 with value: 0.10807193070650101.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6404/2147256317.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:03:52,132] Trial 46 finished with value: 0.31433623284101486 and parameters: {'num_layers': 3, 'num_neurons_layer_0': 64, 'num_neurons_layer_1': 32, 'num_neurons_layer_2': 112, 'learning_rate': 0.0022698249694673906, 'activation': 'tanh'}. Best is trial 34 with value: 0.10807193070650101.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6404/2147256317.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:03:57,028] Trial 47 finished with value: 0.25424153730273247 and parameters: {'num_layers': 2, 'num_neurons_layer_0': 96, 'num_neurons_layer_1': 24, 'learning_rate': 0.00478506217212709, 'activation': 'tanh'}. Best is trial 34 with value: 0.10807193070650101.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6404/2147256317.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:04:02,166] Trial 48 finished with value: 0.3634043186903 and parameters: {'num_layers': 2, 'num_neurons_layer_0': 100, 'num_neurons_layer_1': 44, 'learning_rate': 0.008453551490127914, 'activation': 'tanh'}. Best is trial 34 with value: 0.10807193070650101.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6404/2147256317.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:04:06,543] Trial 49 finished with value: 0.3303770422935486 and parameters: {'num_layers': 1, 'num_neurons_layer_0': 76, 'learning_rate': 0.005376826057083149, 'activation': 'tanh'}. Best is trial 34 with value: 0.10807193070650101.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6404/2147256317.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:04:11,430] Trial 50 finished with value: 0.25434665381908417 and parameters: {'num_layers': 2, 'num_neurons_layer_0': 104, 'num_neurons_layer_1': 20, 'learning_rate': 0.0027089111151773256, 'activation': 'tanh'}. Best is trial 34 with value: 0.10807193070650101.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6404/2147256317.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:04:16,261] Trial 51 finished with value: 0.39344391599297523 and parameters: {'num_layers': 2, 'num_neurons_layer_0': 104, 'num_neurons_layer_1': 16, 'learning_rate': 0.0026996454688680174, 'activation': 'tanh'}. Best is trial 34 with value: 0.10807193070650101.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6404/2147256317.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:04:21,121] Trial 52 finished with value: 0.22235627844929695 and parameters: {'num_layers': 2, 'num_neurons_layer_0': 108, 'num_neurons_layer_1': 28, 'learning_rate': 0.0039461820621760355, 'activation': 'tanh'}. Best is trial 34 with value: 0.10807193070650101.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6404/2147256317.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:04:25,866] Trial 53 finished with value: 0.36164453998208046 and parameters: {'num_layers': 2, 'num_neurons_layer_0': 120, 'num_neurons_layer_1': 20, 'learning_rate': 0.00372237644727448, 'activation': 'tanh'}. Best is trial 34 with value: 0.10807193070650101.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6404/2147256317.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:04:30,045] Trial 54 finished with value: 0.2378852516412735 and parameters: {'num_layers': 1, 'num_neurons_layer_0': 108, 'learning_rate': 0.006196532334761027, 'activation': 'tanh'}. Best is trial 34 with value: 0.10807193070650101.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6404/2147256317.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:04:34,414] Trial 55 finished with value: 0.2941996417939663 and parameters: {'num_layers': 1, 'num_neurons_layer_0': 108, 'learning_rate': 0.006437492349077657, 'activation': 'tanh'}. Best is trial 34 with value: 0.10807193070650101.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6404/2147256317.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:04:38,518] Trial 56 finished with value: 0.26273059472441673 and parameters: {'num_layers': 1, 'num_neurons_layer_0': 104, 'learning_rate': 0.00582120178818279, 'activation': 'tanh'}. Best is trial 34 with value: 0.10807193070650101.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6404/2147256317.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:04:42,631] Trial 57 finished with value: 0.33386528119444847 and parameters: {'num_layers': 1, 'num_neurons_layer_0': 116, 'learning_rate': 0.007866228426333034, 'activation': 'tanh'}. Best is trial 34 with value: 0.10807193070650101.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6404/2147256317.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:04:47,435] Trial 58 finished with value: 0.25265391170978546 and parameters: {'num_layers': 2, 'num_neurons_layer_0': 108, 'num_neurons_layer_1': 40, 'learning_rate': 0.0033584248526662727, 'activation': 'tanh'}. Best is trial 34 with value: 0.10807193070650101.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6404/2147256317.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:04:51,535] Trial 59 finished with value: 0.17834578454494476 and parameters: {'num_layers': 1, 'num_neurons_layer_0': 108, 'learning_rate': 0.00430616364971692, 'activation': 'tanh'}. Best is trial 34 with value: 0.10807193070650101.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6404/2147256317.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:04:55,709] Trial 60 finished with value: 0.17026184871792793 and parameters: {'num_layers': 1, 'num_neurons_layer_0': 120, 'learning_rate': 0.0032685756224481687, 'activation': 'tanh'}. Best is trial 34 with value: 0.10807193070650101.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6404/2147256317.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:04:59,937] Trial 61 finished with value: 0.21659672632813454 and parameters: {'num_layers': 1, 'num_neurons_layer_0': 128, 'learning_rate': 0.003358496278715971, 'activation': 'tanh'}. Best is trial 34 with value: 0.10807193070650101.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6404/2147256317.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:05:04,132] Trial 62 finished with value: 0.20216145366430283 and parameters: {'num_layers': 1, 'num_neurons_layer_0': 128, 'learning_rate': 0.004120305815838761, 'activation': 'tanh'}. Best is trial 34 with value: 0.10807193070650101.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6404/2147256317.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:05:08,302] Trial 63 finished with value: 0.18482161685824394 and parameters: {'num_layers': 1, 'num_neurons_layer_0': 128, 'learning_rate': 0.0039158248765818575, 'activation': 'tanh'}. Best is trial 34 with value: 0.10807193070650101.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6404/2147256317.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:05:12,417] Trial 64 finished with value: 0.20905804634094238 and parameters: {'num_layers': 1, 'num_neurons_layer_0': 128, 'learning_rate': 0.003997350540289125, 'activation': 'tanh'}. Best is trial 34 with value: 0.10807193070650101.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6404/2147256317.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:05:16,613] Trial 65 finished with value: 0.20349648594856262 and parameters: {'num_layers': 1, 'num_neurons_layer_0': 128, 'learning_rate': 0.003265390084465634, 'activation': 'tanh'}. Best is trial 34 with value: 0.10807193070650101.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6404/2147256317.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:05:20,833] Trial 66 finished with value: 0.19153429940342903 and parameters: {'num_layers': 1, 'num_neurons_layer_0': 124, 'learning_rate': 0.00308319310940742, 'activation': 'tanh'}. Best is trial 34 with value: 0.10807193070650101.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6404/2147256317.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:05:25,005] Trial 67 finished with value: 0.216923076659441 and parameters: {'num_layers': 1, 'num_neurons_layer_0': 120, 'learning_rate': 0.0029722958089726174, 'activation': 'tanh'}. Best is trial 34 with value: 0.10807193070650101.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6404/2147256317.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:05:29,277] Trial 68 finished with value: 0.2804652974009514 and parameters: {'num_layers': 1, 'num_neurons_layer_0': 124, 'learning_rate': 0.0015463092991771436, 'activation': 'tanh'}. Best is trial 34 with value: 0.10807193070650101.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6404/2147256317.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:05:33,588] Trial 69 finished with value: 0.224187184125185 and parameters: {'num_layers': 1, 'num_neurons_layer_0': 120, 'learning_rate': 0.0022657430291504817, 'activation': 'tanh'}. Best is trial 34 with value: 0.10807193070650101.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6404/2147256317.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:05:37,687] Trial 70 finished with value: 0.19561121240258217 and parameters: {'num_layers': 1, 'num_neurons_layer_0': 128, 'learning_rate': 0.00172480040204837, 'activation': 'tanh'}. Best is trial 34 with value: 0.10807193070650101.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6404/2147256317.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:05:41,833] Trial 71 finished with value: 0.25704649463295937 and parameters: {'num_layers': 1, 'num_neurons_layer_0': 128, 'learning_rate': 0.002045585950001468, 'activation': 'tanh'}. Best is trial 34 with value: 0.10807193070650101.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6404/2147256317.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:05:46,006] Trial 72 finished with value: 0.21781941130757332 and parameters: {'num_layers': 1, 'num_neurons_layer_0': 124, 'learning_rate': 0.0029523257737779744, 'activation': 'tanh'}. Best is trial 34 with value: 0.10807193070650101.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6404/2147256317.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:05:50,120] Trial 73 finished with value: 0.2948531024158001 and parameters: {'num_layers': 1, 'num_neurons_layer_0': 116, 'learning_rate': 0.002357236350199299, 'activation': 'tanh'}. Best is trial 34 with value: 0.10807193070650101.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6404/2147256317.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:05:54,226] Trial 74 finished with value: 0.2552865855395794 and parameters: {'num_layers': 1, 'num_neurons_layer_0': 124, 'learning_rate': 0.004266833387537039, 'activation': 'tanh'}. Best is trial 34 with value: 0.10807193070650101.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6404/2147256317.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:05:58,359] Trial 75 finished with value: 0.2627711072564125 and parameters: {'num_layers': 1, 'num_neurons_layer_0': 120, 'learning_rate': 0.0017057871697656291, 'activation': 'tanh'}. Best is trial 34 with value: 0.10807193070650101.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6404/2147256317.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:06:02,564] Trial 76 finished with value: 0.2201676182448864 and parameters: {'num_layers': 1, 'num_neurons_layer_0': 112, 'learning_rate': 0.005221646747819374, 'activation': 'tanh'}. Best is trial 34 with value: 0.10807193070650101.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6404/2147256317.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:06:06,811] Trial 77 finished with value: 0.3400610387325287 and parameters: {'num_layers': 1, 'num_neurons_layer_0': 124, 'learning_rate': 0.0012537153447078828, 'activation': 'tanh'}. Best is trial 34 with value: 0.10807193070650101.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6404/2147256317.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:06:11,126] Trial 78 finished with value: 0.1942392736673355 and parameters: {'num_layers': 1, 'num_neurons_layer_0': 128, 'learning_rate': 0.0018892999994318854, 'activation': 'tanh'}. Best is trial 34 with value: 0.10807193070650101.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6404/2147256317.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:06:15,327] Trial 79 finished with value: 0.28592512011528015 and parameters: {'num_layers': 1, 'num_neurons_layer_0': 120, 'learning_rate': 0.0017590896393893682, 'activation': 'tanh'}. Best is trial 34 with value: 0.10807193070650101.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6404/2147256317.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:06:19,529] Trial 80 finished with value: 24.385011672973633 and parameters: {'num_layers': 1, 'num_neurons_layer_0': 124, 'learning_rate': 0.00010692375697745594, 'activation': 'tanh'}. Best is trial 34 with value: 0.10807193070650101.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6404/2147256317.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:06:23,939] Trial 81 finished with value: 0.20334535837173462 and parameters: {'num_layers': 1, 'num_neurons_layer_0': 128, 'learning_rate': 0.0028840644390754565, 'activation': 'tanh'}. Best is trial 34 with value: 0.10807193070650101.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6404/2147256317.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:06:28,184] Trial 82 finished with value: 0.27227288484573364 and parameters: {'num_layers': 1, 'num_neurons_layer_0': 128, 'learning_rate': 0.0019274582815824127, 'activation': 'tanh'}. Best is trial 34 with value: 0.10807193070650101.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6404/2147256317.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:06:32,422] Trial 83 finished with value: 0.27139466255903244 and parameters: {'num_layers': 1, 'num_neurons_layer_0': 116, 'learning_rate': 0.0013746932675177492, 'activation': 'tanh'}. Best is trial 34 with value: 0.10807193070650101.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6404/2147256317.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:06:37,115] Trial 84 finished with value: 0.15686361491680145 and parameters: {'num_layers': 1, 'num_neurons_layer_0': 112, 'learning_rate': 0.002877180178010185, 'activation': 'tanh'}. Best is trial 34 with value: 0.10807193070650101.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6404/2147256317.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:06:41,736] Trial 85 finished with value: 0.2195236049592495 and parameters: {'num_layers': 1, 'num_neurons_layer_0': 112, 'learning_rate': 0.0025248815413193683, 'activation': 'tanh'}. Best is trial 34 with value: 0.10807193070650101.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6404/2147256317.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:06:46,131] Trial 86 finished with value: 0.21523157507181168 and parameters: {'num_layers': 1, 'num_neurons_layer_0': 116, 'learning_rate': 0.0020632212856101697, 'activation': 'tanh'}. Best is trial 34 with value: 0.10807193070650101.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6404/2147256317.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:06:50,534] Trial 87 finished with value: 0.22825361415743828 and parameters: {'num_layers': 1, 'num_neurons_layer_0': 120, 'learning_rate': 0.003570423896353553, 'activation': 'tanh'}. Best is trial 34 with value: 0.10807193070650101.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6404/2147256317.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:06:55,069] Trial 88 finished with value: 0.43736881017684937 and parameters: {'num_layers': 1, 'num_neurons_layer_0': 124, 'learning_rate': 0.003746390139657215, 'activation': 'relu'}. Best is trial 34 with value: 0.10807193070650101.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6404/2147256317.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:06:59,510] Trial 89 finished with value: 0.2809253856539726 and parameters: {'num_layers': 1, 'num_neurons_layer_0': 112, 'learning_rate': 0.0015576679052467337, 'activation': 'tanh'}. Best is trial 34 with value: 0.10807193070650101.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6404/2147256317.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:07:03,530] Trial 90 finished with value: 11.257524967193604 and parameters: {'num_layers': 1, 'num_neurons_layer_0': 20, 'learning_rate': 0.0009200885958745481, 'activation': 'tanh'}. Best is trial 34 with value: 0.10807193070650101.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6404/2147256317.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:07:07,865] Trial 91 finished with value: 0.185495525598526 and parameters: {'num_layers': 1, 'num_neurons_layer_0': 128, 'learning_rate': 0.002771727306732569, 'activation': 'tanh'}. Best is trial 34 with value: 0.10807193070650101.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6404/2147256317.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:07:12,301] Trial 92 finished with value: 0.22126038372516632 and parameters: {'num_layers': 1, 'num_neurons_layer_0': 124, 'learning_rate': 0.002757533572451405, 'activation': 'tanh'}. Best is trial 34 with value: 0.10807193070650101.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6404/2147256317.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:07:16,724] Trial 93 finished with value: 0.19675587862730026 and parameters: {'num_layers': 1, 'num_neurons_layer_0': 128, 'learning_rate': 0.002369770731006539, 'activation': 'tanh'}. Best is trial 34 with value: 0.10807193070650101.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6404/2147256317.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:07:21,138] Trial 94 finished with value: 0.20615656673908234 and parameters: {'num_layers': 1, 'num_neurons_layer_0': 116, 'learning_rate': 0.002199295870692712, 'activation': 'tanh'}. Best is trial 34 with value: 0.10807193070650101.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6404/2147256317.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:07:25,608] Trial 95 finished with value: 0.24825945124030113 and parameters: {'num_layers': 1, 'num_neurons_layer_0': 120, 'learning_rate': 0.0024200993517472726, 'activation': 'tanh'}. Best is trial 34 with value: 0.10807193070650101.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6404/2147256317.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:07:30,041] Trial 96 finished with value: 0.23746227100491524 and parameters: {'num_layers': 1, 'num_neurons_layer_0': 128, 'learning_rate': 0.0018735771710510368, 'activation': 'tanh'}. Best is trial 34 with value: 0.10807193070650101.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6404/2147256317.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:07:34,470] Trial 97 finished with value: 0.20370811596512794 and parameters: {'num_layers': 1, 'num_neurons_layer_0': 124, 'learning_rate': 0.003074361487993844, 'activation': 'tanh'}. Best is trial 34 with value: 0.10807193070650101.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6404/2147256317.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:07:39,155] Trial 98 finished with value: 0.18154776841402054 and parameters: {'num_layers': 1, 'num_neurons_layer_0': 120, 'learning_rate': 0.002597171556717054, 'activation': 'tanh'}. Best is trial 34 with value: 0.10807193070650101.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6404/2147256317.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:07:43,500] Trial 99 finished with value: 0.5845992863178253 and parameters: {'num_layers': 1, 'num_neurons_layer_0': 112, 'learning_rate': 0.003207692027670053, 'activation': 'relu'}. Best is trial 34 with value: 0.10807193070650101.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0oAAAIhCAYAAABwnkrAAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB+r0lEQVR4nO3deXhU5dnH8d9kTyDskIUgIIuAKKIoAiqgAhJBbMQFXKDWSosoSBVFaw1eChZbQItKrRu2UnFB2tciEpXNAoqIGyBoZZeIIhCWkPV5/xhnmElmkpnJbGfy/VxXrmTOOXPmnpmHMHfu+3mOzRhjBAAAAABwiot0AAAAAAAQbUiUAAAAAKAKEiUAAAAAqIJECQAAAACqIFECAAAAgCpIlAAAAACgChIlAAAAAKiCRAkAAAAAqiBRAgAAAIAqSJQARK1169bp6quvVlZWlpKSkpSZmamRI0dq7dq1dTrvU089pRdffLHa9h07dshms3ncF6hQnNPV5s2blZ+frx07dlTbN3bsWLVr1y4kj1sbm83m9tW4cWMNGDBA//nPfyISj1UNGDBA3bt3j3QYUS0/P7/aePP0NWDAAI/3X7FihWw2m1asWOH3Y9flvgCiH4kSgKj0l7/8Rf369dOePXs0c+ZMvfvuu/rTn/6kvXv36oILLtDcuXMDPre3RCkrK0tr167V5ZdfXofIQ39OV5s3b9a0adM8JkoPPPCA3nzzzZA8ri8cSe1///tfPfnkkyosLNTw4cNJlhBUt9xyi9auXev8WrRokSTp9ttvd9v+1FNPebz/2WefrbVr1+rss88OZ9gALCAh0gEAQFX//e9/NWnSJOXm5urNN99UQsLJX1XXXXedfvGLX2jixInq2bOn+vXrF7THTU5O1vnnnx+084XqnL7q0KFDRB7XISMjw/nc+/btqz59+qhjx46aM2eO18SxrKxMNpvN7T0PlYqKCpWXlys5OTnkj4W68/Z+5eTkKCcnx3nb8UeDU045pcZ/e46x1qhRo4j9GwUQ3agoAYg6M2bMkM1m09NPP13tA3NCQoKeeuop2Ww2Pfroo87tjvabjRs3Ki8vT40aNVLjxo11ww036IcffnAe165dO23atEkrV650tuQ42tM8tck5zvv555/r6quvVuPGjdWsWTNNnjxZ5eXl2rp1qy677DKlp6erXbt2mjlzplu8ns5ZU3uQ40Pexx9/rOuuu07t2rVTamqq2rVrp1GjRmnnzp3O87z44ou6+uqrJUkDBw50nsPxWJ5a706cOKGpU6eqffv2SkpKUuvWrXXbbbfp0KFDbse1a9dOw4YN09KlS3X22WcrNTVVXbp00fPPP1/b2+dVhw4d1LJlS+dzcLQt/f3vf9fvfvc7tW7dWsnJyfrmm28kSc8//7x69OihlJQUNWvWTL/4xS+0ZcuWauf929/+ps6dOys5OVndunXTggULqj13x/swc+ZMPfzww2rfvr2Sk5O1fPly5+t9xRVXqFmzZkpJSVHPnj316quvuj3O8ePHddddd6l9+/bOmHr16qV//vOfzmO+/fZbXXfddcrOzlZycrIyMjJ0ySWX6NNPPw34datNZWWlZs6cqS5duig5OVmtWrXSTTfdpD179rgdt3HjRg0bNkytWrVScnKysrOzdfnll7sd99prr6l3795q3Lix0tLSdOqpp+rmm2+uNQabzaYJEybor3/9q9t78corr1Q7trCwUOPGjVNOTo6SkpLUvn17TZs2TeXl5c5janu//FXTWPPUPufLvz8AsY+KEoCoUlFRoeXLl6tXr15ufyV21aZNG51zzjl6//33VVFRofj4eOe+X/ziF7rmmmv0m9/8Rps2bdIDDzygzZs368MPP1RiYqLefPNNjRw5Uo0bN3a24vhSUbjmmmt0ww03aNy4cSooKNDMmTNVVlamd999V+PHj9ddd92lBQsW6J577lHHjh2Vl5fn9VxV51gVFxfrxhtvVEVFhZo1aybJ/kHxtNNO03XXXadmzZpp3759evrpp3Xuuedq8+bNatGihS6//HJNnz5d9913n5588kln65C3SpIxRldeeaXee+89TZ06VRdeeKE+//xzPfjgg872JNfX4rPPPtPvfvc73XvvvcrIyNCzzz6rX/3qV+rYsaMuuuiiWl+zqg4ePKgDBw6oU6dObtunTp2qPn36aN68eYqLi1OrVq00Y8YM3XfffRo1apRmzJihAwcOKD8/X3369NH69eud53jmmWc0btw4XXXVVZo9e7YOHz6sadOmqaSkxGMMTzzxhDp37qw//elPatSokTp16qTly5frsssuU+/evTVv3jw1btxYr7zyiq699lodP35cY8eOlSRNnjxZf//73/Xwww+rZ8+eOnbsmL788ksdOHDAef7c3FxVVFRo5syZOuWUU/Tjjz9qzZo1bonoiy++qF/+8pd64YUXnOeui9/+9rd65plnNGHCBA0bNkw7duzQAw88oBUrVuiTTz5RixYtdOzYMQ0aNEjt27fXk08+qYyMDBUWFmr58uU6cuSIJPu4vPbaa3XttdcqPz9fKSkp2rlzp95//32f4vj3v/+t5cuX66GHHlKDBg301FNPadSoUUpISNDIkSMl2ZOk8847T3FxcfrDH/6gDh06aO3atXr44Ye1Y8cOvfDCC27n9PR+1YWnsVZYWFjtOF/+/QGoBwwARJHCwkIjyVx33XU1HnfttdcaSeb77783xhjz4IMPGknmzjvvdDvu5ZdfNpLMP/7xD+e2008/3fTv37/aObdv324kmRdeeMG5zXHeP//5z27HnnXWWUaSWbRokXNbWVmZadmypcnLy6vxnK7Ky8vNiBEjTMOGDc2GDRu8Pt/y8nJz9OhR06BBA/P44487t7/22mtGklm+fHm1+4wZM8a0bdvWeXvp0qVGkpk5c6bbcQsXLjSSzDPPPOPc1rZtW5OSkmJ27tzp3FZcXGyaNWtmxo0b5zVOB0lm/PjxpqyszJSWlpotW7aYoUOHGknmySefNMYYs3z5ciPJXHTRRW73PXjwoElNTTW5ublu23ft2mWSk5PN6NGjjTHGVFRUmMzMTNO7d2+343bu3GkSExPdnrvjfejQoYMpLS11O75Lly6mZ8+epqyszG37sGHDTFZWlqmoqDDGGNO9e3dz5ZVXen3OP/74o5Fk5syZU+NrM3/+fBMfH2/mz59f43HGGNO/f39z+umne92/ZcsW52vt6sMPPzSSzH333WeMMebjjz82kszixYu9nutPf/qTkWQOHTpUa1xVSTKpqammsLDQua28vNx06dLFdOzY0blt3LhxpmHDhm7jyvWxN23aZIyp+f2qjeO+jz32mHObt7Hmus/TvyHX5+Lp358v9wVgXbTeAbAkY4wke8uPq+uvv97t9jXXXKOEhISAW3Ychg0b5na7a9eustlsGjp0qHNbQkKCOnbs6Fd7zoQJE/Sf//xHr732mttk8qNHjzqrUwkJCUpISFDDhg117Ngxj+1nvnBUBqpWMa6++mo1aNBA7733ntv2s846S6eccorzdkpKijp37uzz83vqqaeUmJiopKQkde3aVWvWrNFDDz2k8ePHux131VVXud1eu3atiouLq8XZpk0bXXzxxc44t27dqsLCQl1zzTVux51yyile565dccUVSkxMdN7+5ptv9NVXXznHTXl5ufMrNzdX+/bt09atWyVJ5513nt5++23de++9WrFihYqLi93O3axZM3Xo0EGPPfaYZs2apY0bN6qysrJaDDfddJPKy8t10003eXvpfOYY11Vfq/POO09du3Z1vlYdO3ZU06ZNdc8992jevHnavHlztXOde+65kuz/Zl599VXt3bvXr1guueQSZWRkOG/Hx8fr2muv1TfffONs73vrrbc0cOBAZWdnu73Wjn9HK1eudDtn1ferrqqONW9C8e8PgPWQKAGIKi1atFBaWpq2b99e43E7duxQWlqas1XNITMz0+12QkKCmjdv7tYeFYiqj5OUlKS0tDSlpKRU237ixAmfzvnwww9r3rx5+utf/6rLLrvMbd/o0aM1d+5c3XLLLXrnnXf00Ucfaf369WrZsmW1D+i+OnDggBISEtSyZUu37TabTZmZmdVeo+bNm1c7R3Jyss+Pf80112j9+vX6+OOPtXXrVh04cEAPPPBAteOysrKqxelpuyRlZ2c79zu+u344d/C0zdM5v//+e0nSXXfdpcTERLcvR0L3448/SrK3gd1zzz1avHixBg4cqGbNmunKK6/U119/Lcn+Or733nsaMmSIZs6cqbPPPlstW7bUHXfc4WxvCzZfX6vGjRtr5cqVOuuss3Tffffp9NNPV3Z2th588EGVlZVJki666CItXrzYmcTl5OSoe/fubnOwalL1357rNkcc33//vf7v//6v2mt9+umnSzr5Wjt4el514ev5QvHvD4D1MEcJQFSJj4/XwIEDtXTpUu3Zs8fjPKU9e/Zow4YNGjp0qNv8JMk+B6J169bO2+Xl5Tpw4IDHD/2R9OKLL+qBBx5Qfn5+tcnyhw8f1ltvvaUHH3xQ9957r3N7SUmJfvrpp4Afs3nz5iovL9cPP/zgliwZY1RYWOisKARLy5Yt1atXr1qPq1oVdLxX+/btq3bsd99955wf4jjOkey48jTvxNNjOc41depUr/PKTjvtNElSgwYNNG3aNE2bNk3ff/+9s7o0fPhwffXVV5Kktm3b6rnnnpMkbdu2Ta+++qry8/NVWlqqefPmeTx/Xbi+VlX/rbi+VpJ0xhln6JVXXpExRp9//rlefPFFPfTQQ0pNTXWOsxEjRmjEiBEqKSnRunXrNGPGDI0ePVrt2rVTnz59aozF02vu2OaIs0WLFjrzzDP1yCOPeDxHdna22+2q71dd+XK+UP37A2A9VJQARJ2pU6fKGKPx48eroqLCbV9FRYV++9vfyhijqVOnVrvvyy+/7Hb71VdfVXl5udvFJv2pioTC0qVL9etf/1o333yzHnzwwWr7bTabjDHVFpl49tlnq70ejmN8eT6XXHKJJOkf//iH2/Y33nhDx44dc+6PtD59+ig1NbVanHv27NH777/vjPO0005TZmZmtdXpdu3apTVr1vj0WKeddpo6deqkzz77TL169fL4lZ6eXu1+GRkZGjt2rEaNGqWtW7fq+PHj1Y7p3Lmzfv/73+uMM87QJ5984uvT98vFF18sqfp7un79em3ZssXje2qz2dSjRw/Nnj1bTZo08RhbcnKy+vfvrz/+8Y+S7Cvm1ea9995zS1orKiq0cOFCdejQwZnEDRs2TF9++aU6dOjg8bWumihFgj///gDENipKAKJOv379NGfOHE2aNEkXXHCBJkyYoFNOOUW7du3Sk08+qQ8//FBz5sxR3759q9130aJFSkhI0KBBg5yr3vXo0cNtHovjL+sLFy7UqaeeqpSUFJ1xxhlheW7bt2/X1VdfrVNPPVW//OUvtW7dOrf9PXv2VKNGjXTRRRfpscceU4sWLdSuXTutXLlSzz33nJo0aeJ2fPfu3SXZV39LT09XSkqK2rdv77GCNmjQIA0ZMkT33HOPioqK1K9fP+eqdz179tSNN94YsuftjyZNmuiBBx7Qfffdp5tuukmjRo3SgQMHNG3aNKWkpDiTy7i4OE2bNk3jxo3TyJEjdfPNN+vQoUOaNm2asrKyFBfn298C//rXv2ro0KEaMmSIxo4dq9atW+unn37Sli1b9Mknn+i1116TJPXu3VvDhg3TmWeeqaZNm2rLli36+9//rj59+igtLU2ff/65JkyYoKuvvlqdOnVSUlKS3n//fX3++edulYmXXnpJN998s55//nmf5ikVFRXp9ddfr7a9ZcuW6t+/v2699Vb95S9/UVxcnIYOHepc9a5Nmza68847JdnnBj311FO68sordeqpp8oYo0WLFunQoUMaNGiQJOkPf/iD9uzZo0suuUQ5OTk6dOiQHn/8cSUmJqp///61xtmiRQtdfPHFeuCBB5yr3n311VduS4Q/9NBDKigoUN++fXXHHXfotNNO04kTJ7Rjxw4tWbJE8+bN87raZbj48+8PQIyL3DoSAFCztWvXmpEjR5qMjAyTkJBgWrVqZfLy8syaNWuqHetYnW7Dhg1m+PDhpmHDhiY9Pd2MGjXKuTKew44dO8zgwYNNenq6keRcHa2mVe9++OEHt3OMGTPGNGjQoFocVVcpq3pOxypZ3r62b99ujDFmz5495qqrrjJNmzY16enp5rLLLjNffvmladu2rRkzZozbY86ZM8e0b9/exMfHuz1W1VXvjLGvXHfPPfeYtm3bmsTERJOVlWV++9vfmoMHD7od17ZtW3P55Zd7fH6eVgysSpK57bbbajzG8Vq89tprHvc/++yz5swzzzRJSUmmcePGZsSIEc5V0Vw988wzpmPHjiYpKcl07tzZPP/882bEiBGmZ8+ezmM8rYTm6rPPPjPXXHONadWqlUlMTDSZmZnm4osvNvPmzXMec++995pevXqZpk2bmuTkZHPqqaeaO++80/z444/GGGO+//57M3bsWNOlSxfToEED07BhQ3PmmWea2bNnm/Lycud5XnjhhRpXQnTVv39/r2PF8T5UVFSYP/7xj6Zz584mMTHRtGjRwtxwww1m9+7dzvN89dVXZtSoUaZDhw4mNTXVNG7c2Jx33nnmxRdfdB7z1ltvmaFDh5rWrVubpKQk06pVK5Obm2tWr15da5yO9/upp54yHTp0MImJiaZLly7m5ZdfrnbsDz/8YO644w7Tvn17k5iYaJo1a2bOOeccc//995ujR48aY2p/v2pS06p3nsaap5XrfP33x6p3QGyzGfPz0lEAYGH5+fmaNm2afvjhB65xUs8dOnRInTt31pVXXqlnnnkm0uHUCzabTbfddpvmzp0b6VAAIGhovQMAWFZhYaEeeeQRDRw4UM2bN9fOnTs1e/ZsHTlyRBMnTox0eAAACyNRAgBYVnJysnbs2KHx48frp59+Ulpams4//3zNmzfPueQ0AACBoPUOAAAAAKpgeXAAAAAAqIJECQAAAACqIFECAAAAgCpifjGHyspKfffdd0pPT5fNZot0OAAAAAAixBijI0eOKDs7u9YLk8d8ovTdd9+pTZs2kQ4DAAAAQJTYvXu3cnJyajwm5hOl9PR0SfYXo1GjRhGNpaysTMuWLdPgwYOVmJgY0VhgLYwdBIJxg0AwbhAoxg4CEe5xU1RUpDZt2jhzhJrEfKLkaLdr1KhRVCRKaWlpatSoEb9A4BfGDgLBuEEgGDcIFGMHgYjUuPFlSk5EF3No166dbDZbta/bbrtNkr2HMD8/X9nZ2UpNTdWAAQO0adOmSIYMAAAAoB6IaKK0fv167du3z/lVUFAgSbr66qslSTNnztSsWbM0d+5crV+/XpmZmRo0aJCOHDkSybABAAAAxLiItt61bNnS7fajjz6qDh06qH///jLGaM6cObr//vuVl5cnSZo/f74yMjK0YMECjRs3zuM5S0pKVFJS4rxdVFQkyV7WKysrC9Ez8Y3j8SMdB6yHsYNAMG4QCMYNAsXYQSDCPW78eRybMcaEMBaflZaWKjs7W5MnT9Z9992nb7/9Vh06dNAnn3yinj17Oo8bMWKEmjRpovnz53s8T35+vqZNm1Zt+4IFC5SWlhay+AEAABBacXFxtS7pjPqtsrJSlZWVXvcfP35co0eP1uHDh2tdvyBqFnNYvHixDh06pLFjx0qSCgsLJUkZGRlux2VkZGjnzp1ezzN16lRNnjzZeduxssXgwYOjYjGHgoICDRo0iEmO8AtjB4Fg3CAQjBsEKpRjp6ysTN9//72Ki4uDel5EnjFGJ06cUEpKStCueZqamqqMjAyP49DRbeaLqEmUnnvuOQ0dOlTZ2dlu26u+YMaYGl/E5ORkJScnV9uemJgYNb/woykWWAtjB4Fg3CAQjBsEKthjp7KyUt9++63i4+PVunVrJSUlBe0DNSKvsrJSR48eVcOGDetcLTTGqLS0VD/88IN2796tTp06VTunP2MzKhKlnTt36t1339WiRYuc2zIzMyXZK0tZWVnO7fv3769WZQIAAEBsKi0tVWVlpdq0acM0ihhUWVmp0tJSpaSkBKWtMjU1VYmJidq5c6fzvIGKiibPF154Qa1atdLll1/u3Na+fXtlZmY6V8KT7P9QVq5cqb59+0YiTAAAAEQIc5Pgq2CNlYhXlCorK/XCCy9ozJgxSkg4GY7NZtOkSZM0ffp0derUSZ06ddL06dOVlpam0aNHRzBiAAAAALEu4onSu+++q127dunmm2+utm/KlCkqLi7W+PHjdfDgQfXu3VvLli1Tenp6BCIFAAAAUF9EvIY5ePBgGWPUuXPnavtsNpvy8/O1b98+nThxQitXrlT37t0jECUAAACsrqJCWrFC+uc/7d8rKiIdESTpgw8+UHx8vA4dOuTzfQYMGKBJkyaFLCYpChIlAAAAINQWLZLatZMGDpRGj7Z/b9fOvj1Uxo4dqyuvvDJ0DxCF2rVrJ5vN5vVrwIAB1e5z3nnnae/evWrcuHH4A65BxFvvAAAAgFBatEgaOVIyxn373r327a+/LuXlRSY2KystLVVSUpLbtvXr16vi51LdmjVrdNVVV2nr1q3O65lWPb6srExJSUlq0aJF1C37TkUJQUM5GwAAhIMx0rFjvn0VFUl33FE9SXKcR5ImTrQf58v5PJ0nUCtXrtR5552n5ORkZWVl6d5771V5eblz/+uvv64zzjhDqampat68uS699FIdO3ZMkrRixQqdd955atCggZo0aaJ+/fpp586dHh9nx44dstlseuWVV9S3b1+lpKTo9NNP14oVK9yO27x5s3Jzc9WwYUNlZGToxhtv1I8//ujcP2DAAE2YMEGTJ09WixYtNGjQoGqP1bJlS2VmZiozM1PNmjWTJLVq1cq5rXnz5po3b55GjBihBg0a6JFHHqnWenfgwAGNGjVKOTk5SktL0xlnnKF//vOfdXmpA0KihKCIRDkbAADUT8ePSw0b+vbVuLG9cuSNMdKePfbjfDnf8ePBeQ579+5Vbm6uzj33XH322Wd6+umn9dxzz+nhhx+WJO3bt0+jRo3SzTffrC1btmjFihXKy8uTMUbl5eW68sor1b9/f33++edau3atbr311lorMnfffbd+97vfaePGjerbt6+uuOIKHThwwPl4/fv311lnnaWPP/5YS5cu1ffff69rrrnG7Rzz589XQkKC/vvf/+qvf/1rQM/9wQcf1IgRI/TFF1/ol7/8ZbX9J06c0DnnnKO33npLX375pW699VbdeOON+vDDDwN6vEDReoc6o5wNAADgn6eeekpt2rTR3LlzZbPZ1KVLF3333Xe655579Ic//EH79u1TeXm58vLy1LZtW0nSGWecIUn66aefdPjwYQ0bNkwdOnSQJHXt2rXWx5wwYYKuuuoqSdLTTz+tpUuX6rnnntOUKVP09NNP6+yzz9b06dOdxz///PNq06aNtm3b5lx4rWPHjpo5c2adnvvo0aOdK15XVlZq06ZNbvtbt26tu+66y3n79ttv19KlS/Xaa6+pd+/edXpsf5AooU4qKuzlam/lbJtNmjRJGjFCio8Pe3gAACAGpaVJR4/6duyqVVJubu3HLVkiXXSRb48dDFu2bFGfPn3cqkD9+vXT0aNHtWfPHvXo0UOXXHKJzjjjDA0ZMkSDBw/WyJEj1bRpUzVr1kxjx47VkCFDNGjQIF166aW65pprlJWVVeNj9unTx/lzQkKCevXqpS1btkiSNmzYoOXLl6thw4bV7ve///3PmSj16tWrzs+9tnNUVFTo0Ucf1cKFC7V3716VlJSopKREDRo0qPNj+4PWO9TJ6tX2crU3xki7d9uPAwAACAabTWrQwLevwYOlnBz7fbydq00b+3G+nC9Y6w0YY6q1ypmf//Jss9kUHx+vgoICvf322+rWrZv+8pe/6LTTTtP27dslSS+88ILWrl2rvn37auHChercubPWrVvndxyOGCorKzV8+HB9+umnbl9ff/21LnLJIIORrNR2jj//+c+aPXu2pkyZovfff1+ffvqphgwZotLS0jo/tj9IlFAn+/YF9zgAAIBgio+XHn/c/nPVJMdxe86c8He+dOvWTWvWrHEmR5J9lbj09HS1bt365/hs6tevn6ZNm6aNGzcqKSlJb775pvP4nj17aurUqVqzZo26d++uBQsW1PiYrolUeXm5NmzYoC5dukiSzj77bG3atEnt2rVTx44d3b7CXclZvXq1RowYoRtuuEE9evTQqaeeqq+//jqsMUgkSqijWiq8fh8HAAAQbHl59jnTP+cfTjk5oZ9Lffjw4WpVml27dmn8+PHavXu3br/9dn311Vf617/+pQcffFCTJ09WXFycPvzwQ02fPl0ff/yxdu3apUWLFumHH35Q165dtX37dk2dOlVr167Vzp07tWzZMm3btq3WeUpPPvmk3nzzTX311Ve67bbbdPDgQedcodtuu00//fSTRo0apY8++kjffvutli1bpptvvtm53He4dOzYUQUFBVqzZo22bNmicePGqbCwMKwxSMxRQh1deKH9l8zevZ7nKdls9v0XXhj+2AAAABzy8uxzplevtne6ZGXZP5+EupK0YsUK9ezZ023bmDFj9OKLL2rJkiW6++671aNHDzVr1ky/+tWv9Pvf/16S1KhRI61atUpz5sxRUVGR2rZtqz//+c8aOnSovv/+e3311VeaP3++Dhw4oKysLE2YMEHjxo2rMZZHH31Uf/zjH7Vx40Z16NBB//rXv9SiRQtJUnZ2tv773//qnnvu0ZAhQ1RSUqK2bdvqsssuU1xceGsrDzzwgLZv364hQ4YoLS1Nt956q6688kodPnw4rHGQKKFOHOXskSPtSZFrshTJcjYAAEBV8fHSgAHhe7wXX3xRL774otf9/fv310cffeRxX9euXbV06VKP+zIyMtxa8HzVtWvXGucxderUSYtquLZL1esu1WbAgAFurYWSqt2WpAsuuEAVFRXOhKxZs2ZavHhxjef2N5ZA0HqHOotkORsAAAAIBRIlBEVenrRjh5SSYr99553S9u0kSQAAALAmWu8QNPHxJ1vv2ral3Q4AACAatGvXzmPLG2pGRQlBVVZm/15SEtk4AAAAgLogUULQVFbavyTpxInIxgIAAGILFRH4KlhjhUQJQeO6xD6JEgAACIbExERJ0vHjxyMcCazCMVYcYydQzFFC0Dja7iRa7wAAQHDEx8erSZMm2r9/vyQpLS1NNsc1SGB5lZWVKi0t1YkTJ+p8vSZjjI4fP679+/erSZMmiq/jhHkSJQRNefnJn6koAQCAYMnMzJQkZ7KE2GGMUXFxsVJTU4OWADdp0sQ5ZuqCRAlB41pRIlECAADBYrPZlJWVpVatWqnM9QMHLK+srEyrVq3SRRddVOdWOcneblfXSpIDiRKCxrWiROsdAAAItvj4+KB9CEZ0iI+PV3l5uVJSUoKSKAUTizkgaGi9AwAAQKwgUULQ0HoHAACAWEGihKCh9Q4AAACxgkQJQUPrHQAAAGIFiRKChtY7AAAAxAoSJQQNrXcAAACIFSRKCBoqSgAAAIgVJEoIGipKAAAAiBUkSggaFnMAAABArCBRQtDQegcAAIBYQaKEoKH1DgAAALGCRAlBUzVRMiZysQAAAAB1QaKEoHFtvZOoKgEAAMC6SJQQNK4VJYlECQAAANZFooSgqZoosaADAAAArIpECUFTtfWORAkAAABWRaKEoKH1DgAAALGCRAlBQ0UJAAAAsYJECUHDHCUAAADEChIlBA2tdwAAAIgVJEoIGlrvAAAAECtIlBA0tN4BAAAgVpAoIWhovQMAAECsIFFC0NB6BwAAgFhBooSgofUOAAAAsYJECUFD6x0AAABiBYkSgobWOwAAAMQKEiUEDRUlAAAAxAoSJQQNFSUAAADEChIlBA2LOQAAACBWRDxR2rt3r2644QY1b95caWlpOuuss7RhwwbnfmOM8vPzlZ2drdTUVA0YMECbNm2KYMTwxpEoxcfbv9N6BwAAAKuKaKJ08OBB9evXT4mJiXr77be1efNm/fnPf1aTJk2cx8ycOVOzZs3S3LlztX79emVmZmrQoEE6cuRI5AKHR47Wu4YN7d+pKAEAAMCqEiL54H/84x/Vpk0bvfDCC85t7dq1c/5sjNGcOXN0//33Ky8vT5I0f/58ZWRkaMGCBRo3bly4Q0YNHBWl9HTp8GESJQAAAFhXRBOlf//73xoyZIiuvvpqrVy5Uq1bt9b48eP161//WpK0fft2FRYWavDgwc77JCcnq3///lqzZo3HRKmkpEQlLj1fRUVFkqSysjKVVV1tIMwcjx/pOEKltDReUpzS0owkm4qLK1VWVhHpsGJCrI8dhAbjBoFg3CBQjB0EItzjxp/HiWii9O233+rpp5/W5MmTdd999+mjjz7SHXfcoeTkZN10000qLCyUJGVkZLjdLyMjQzt37vR4zhkzZmjatGnVti9btkxpaWnBfxIBKCgoiHQIIbFnz3mSslRRcVhSE+3c+b2WLPko0mHFlFgdOwgtxg0CwbhBoBg7CES4xs3x48d9PjaiiVJlZaV69eql6dOnS5J69uypTZs26emnn9ZNN93kPM5ms7ndzxhTbZvD1KlTNXnyZOftoqIitWnTRoMHD1ajRo1C8Cx8V1ZWpoKCAg0aNEiJiYkRjSUUnnnGvopDTk4j/e9/UpMmGcrNzY1wVLEh1scOQoNxg0AwbhAoxg4CEe5x4+g280VEE6WsrCx169bNbVvXrl31xhtvSJIyMzMlSYWFhcrKynIes3///mpVJofk5GQlJydX256YmBg1/2ijKZZgOjlHyb5GSGlpnBITI76wYkyJ1bGD0GLcIBCMGwSKsYNAhGvc+PMYEf0U269fP23dutVt27Zt29S2bVtJUvv27ZWZmelWiistLdXKlSvVt2/fsMaK2jkSJVa9AwAAgNVFtKJ05513qm/fvpo+fbquueYaffTRR3rmmWf0zDPPSLK33E2aNEnTp09Xp06d1KlTJ02fPl1paWkaPXp0JEOHB45EqUED+3cSJQAAAFhVRBOlc889V2+++aamTp2qhx56SO3bt9ecOXN0/fXXO4+ZMmWKiouLNX78eB08eFC9e/fWsmXLlJ6eHsHI4UnV6yhxwVkAAABYVUQTJUkaNmyYhg0b5nW/zWZTfn6+8vPzwxcUAuJ6HSWJihIAAACsi5n2CBpa7wAAABArSJQQNLTeAQAAIFaQKCFoaL0DAABArCBRQtBUbb2jogQAAACrIlFC0FRtvauoOJk8AQAAAFZCooSgqdp6J9F+BwAAAGsiUULQOCpKjtY7ifY7AAAAWBOJEoLGUVFKSZESfr5CFxUlAAAAWBGJEoLGkSglJNiTJYlECQAAANZEooSgcbTeJSRIycn2n2m9AwAAgBWRKCFoHBWlxEQqSgAAALC2hEgHgLqpqJBWr5b27ZOysqQLL5Ti4yMTC613AAAAiBUkSha2aJE0caK0Z8/JbTk50uOPS3l54Y2lokIyxv4zrXcAAACwOlrvLGrRImnkSPckSZL27rVvX7QovPG4XliW1jsAAABYHYmSBVVU2CtJjgqOK8e2SZPsx4WLa6JE6x0AAACsjkTJglavrl5JcmWMtHu3/bhwcax4J9F6BwAAAOsjUbKgffuCe1wwUFECAABALCFRsqCsrOAeFwyOilJcnP3LUVEiUQIAAIAVkShZ0IUX2le3s9k877fZpDZt7MeFi+s1lKSTFSVa7wAAAGBFJEoWFB9vXwLcE0fyNGdOeK+n5HoNJYnWOwAAAFgbiZJF5eVJr78upae7b8/JsW8P93WUHK13jkSJ1jsAAABYGYmSheXlSbfcYv+5Sxdp+XJp+/bwJ0kSrXcAAACILQmRDgB140hQmjaVBgyIfBy03gEAACAWUFGyOEfLW2lpdMRRtfWOihIAAACsiETJ4hwJiusFXyPBW+sdFSUAAABYEYmSxTkqSZFOlKpWlEiUAAAAYGUkShYXLa13Veco0XoHAAAAKyNRsjha7wAAAIDgI1GyuGipKNF6BwAAgFhComRx0TJHqWpFidY7AAAAWBmJksVFW+sdFSUAAADEAhIli6P1DgAAAAg+EiWLi7aKEq13AAAAiAUkShbnqCRVVEiVlZGLg9Y7AAAAxBISJYtzrSRFsqpE6x0AAABiCYmSxUVLokTrHQAAAGIJiZLFuSZHkVzQgYoSAAAAYgmJksW5JkfRUFFyJEqOilJpaWTnTgEAAACBIFGyuGhtvXNUlKTIL10OAAAA+ItEyeKivfVOov0OAAAA1kOiZHHR1nrnqCg5vkskSgAAALAeEiWLi7bWO0dFyWY7WVVi5TsAAABYDYmSxUVr653EyncAAACwLhIlCzPmZCVHio6KkmvLHddSAgAAgFWRKFlY1cSIihIAAAAQHCRKFlY1UYqGihKJEgAAAGIBiZKFRWOiROsdAAAAYgGJkoXRegcAAACEBomShVVNjKKtokSiBAAAAKsiUbKwaGy9c60o0XoHAAAAqyJRsjBa7wAAAIDQiGiilJ+fL5vN5vaVmZnp3G+MUX5+vrKzs5WamqoBAwZo06ZNEYw4utB6BwAAAIRGxCtKp59+uvbt2+f8+uKLL5z7Zs6cqVmzZmnu3Llav369MjMzNWjQIB05ciSCEUePaKoo0XoHAACAWBLxRCkhIUGZmZnOr5YtW0qyV5PmzJmj+++/X3l5eerevbvmz5+v48ePa8GCBRGOOjpE0xwlWu8AAAAQSxJqPyS0vv76a2VnZys5OVm9e/fW9OnTdeqpp2r79u0qLCzU4MGDnccmJyerf//+WrNmjcaNG+fxfCUlJSpxKWEUFRVJksrKylQWyUzi5xhcv9dVcbFNrm/hiRMVKiurDMq5/VVWFi8pTjZbucrKjCQpKSlOUryOHYtcXLEi2GMH9QPjBoFg3CBQjB0EItzjxp/HiWii1Lt3b7300kvq3Lmzvv/+ez388MPq27evNm3apMLCQklSRkaG230yMjK0c+dOr+ecMWOGpk2bVm37smXLlJaWFtwnEKCCgoKgnOeLL5pLusDl9lYtWfJ1UM7tr8LCvpJa6ssvN2rJku8kSXv3ni6po7Zs+VZLlmyOSFyxJlhjB/UL4waBYNwgUIwdBCJc4+b48eM+HxvRRGno0KHOn8844wz16dNHHTp00Pz583X++edLkmw2m9t9jDHVtrmaOnWqJk+e7LxdVFSkNm3aaPDgwWrUqFGQn4F/ysrKVFBQoEGDBinRddWDACUlub8Op556mnJzO9X5vIF47LF4SVKvXj2Vm3uWJGndujj9619S69anKje3XUTiihXBHjuoHxg3CATjBoFi7CAQ4R43jm4zX0S89c5VgwYNdMYZZ+jrr7/WlVdeKUkqLCxUVlaW85j9+/dXqzK5Sk5OVrJjFQEXiYmJUfOPNlixGON+u7IyXomJ8XU+byAqKuzfU1MTnCvfOQp4paWRiyvWRNM4hnUwbhAIxg0CxdhBIMI1bvx5jIgv5uCqpKREW7ZsUVZWltq3b6/MzEy3MlxpaalWrlypvn37RjDK6BFNq97VtJgDq94BAADAaiJaUbrrrrs0fPhwnXLKKdq/f78efvhhFRUVacyYMbLZbJo0aZKmT5+uTp06qVOnTpo+fbrS0tI0evToSIYdNbiOEgAAABAaEU2U9uzZo1GjRunHH39Uy5Ytdf7552vdunVq27atJGnKlCkqLi7W+PHjdfDgQfXu3VvLli1Tenp6JMOOGtG0PDjXUQIAAEAsiWii9Morr9S432azKT8/X/n5+eEJyGKs0npHRQkAAABWE1VzlOAfWu8AAACA0CBRsrBoqijRegcAAIBYQqJkYdE0R4nWOwAAAMQSEiULi6ZEidY7AAAAxBISJQtztNrZbO63I8FTRYnWOwAAAFgViZKFOZKTtDT325HgaY4SFSUAAABYFYmShUVjokTrHQAAAGIBiZKFVU2UaL0DAAAAgoNEycIciVGDBvbvkaooGSNVVNh/9lZRMib8cQEAAACBIlGyMEdi5EiUIlVRciRJkuc5SpWVJ1vzAAAAACsgUbKwaJmj5Pq4nlrvJNrvAAAAYC0kShZWtaIUqUTJtVrk2nrnmiixoAMAAACshETJwqrOUYpU6523ilJ8/MnEiUQJAAAAVkKiZGHRWFGKj3ffx8p3AAAAsCISJQuLljlKrhebtdnc93EtJQAAAFgRiZKFRVvrnWvbnYOjokSiBAAAACshUbKwaGu985QoOSpKtN4BAADASkiULKxq612kKkqORMl1xTsHWu8AAABgRR5qAN4dPnxYb775plavXq0dO3bo+PHjatmypXr27KkhQ4aob9++oYoTHkTLHCVfWu+oKAEAAMBKfKoo7du3T7/+9a+VlZWlhx56SMeOHdNZZ52lSy65RDk5OVq+fLkGDRqkbt26aeHChaGOGT+rOkfJGKmiIvxxUFECAABArPGpotSjRw/ddNNN+uijj9S9e3ePxxQXF2vx4sWaNWuWdu/erbvuuiuogaK6qnOUJHvylJoa3jh8maNEogQAAAAr8SlR2rRpk1q2bFnjMampqRo1apRGjRqlH374ISjBoWaeEqWysvAnSrTeAQAAINb41HpXW5JU1+MRmKpzlFy3hROtdwAAAIg1fq96N3/+fP3nP/9x3p4yZYqaNGmivn37aufOnUENDjVzzFFKSZHi4ty3hVNNFSUSJQAAAFiR34nS9OnTlfpzb9fatWs1d+5czZw5Uy1atNCdd94Z9ADhnSNBSUw8Wc2JZEWJ1jsAAADECr+WB5ek3bt3q2PHjpKkxYsXa+TIkbr11lvVr18/DRgwINjxoQZVE6WSkshUlGi9AwAAQKzxu6LUsGFDHThwQJK0bNkyXXrppZKklJQUFRcXBzc61MiRFCUmSklJ9p8jUVGi9Q4AAACxxu+K0qBBg3TLLbeoZ8+e2rZtmy6//HJJ9pXx2rVrF+z4UANHgpKUROsdAAAAEEx+V5SefPJJ9enTRz/88IPeeOMNNW/eXJK0YcMGjRo1KugBwjvX1jtHRYnWOwAAAKDu/K4oNWnSRHPnzq22fdq0aUEJCL6LlsUcaL0DAABArPG7orR06VJ98MEHzttPPvmkzjrrLI0ePVoHDx4ManDwrqJCqqy0/xwtrXeeKkq03gEAAMCK/E6U7r77bhUVFUmSvvjiC/3ud79Tbm6uvv32W02ePDnoAcIz14Qo0q13VJQAAAAQa/xuvdu+fbu6desmSXrjjTc0bNgwTZ8+XZ988olyc3ODHiA8q5ooRUNFiUQJAAAAscLvilJSUpKOHz8uSXr33Xc1ePBgSVKzZs2clSaEnrdEKdoWc6D1DgAAAFbkd0Xpggsu0OTJk9WvXz999NFHWrhwoSRp27ZtysnJCXqA8MyRENlsUnw811ECAAAAgsnvitLcuXOVkJCg119/XU8//bRat24tSXr77bd12WWXBT1AeOa64p3NFr2td1SUAAAAYEV+V5ROOeUUvfXWW9W2z549OygBwTeuiZLEdZQAAACAYPI7UZKkiooKLV68WFu2bJHNZlPXrl01YsQIxcfHBzs+eOFIiBzJCddRAgAAAILH70Tpm2++UW5urvbu3avTTjtNxhht27ZNbdq00X/+8x916NAhFHGiCkdy4qgk0XoHAAAABI/fc5TuuOMOdejQQbt379Ynn3yijRs3ateuXWrfvr3uuOOOUMQID2i9AwAAAELH74rSypUrtW7dOjVr1sy5rXnz5nr00UfVr1+/oAYH76omSrTeAQAAAMHjd0UpOTlZR44cqbb96NGjSnKUNRByjspR1da7aKso0XoHAAAAK/I7URo2bJhuvfVWffjhhzLGyBijdevW6Te/+Y2uuOKKUMQID7y13kVrRam0VKqsDF9MAAAAQF34nSg98cQT6tChg/r06aOUlBSlpKSoX79+6tixo+bMmROCEOFJNLXe1bSYgyNRkqgqAQAAwDr8nqPUpEkT/etf/9I333yjLVu2yBijbt26qWPHjqGID15YZTEHR+udZE+UUlPDExMAAABQFwFdR0mSOnbs6JYcffbZZzr77LNVUVERlMBQM29zlKKt9S4xUbLZJGNY0AEAAADW4XfrXU2MMcE8HWpgldY7m42V7wAAAGA9QU2UbDZbME+HGlil9U5i5TsAAABYT1ATJYSPIyGKhopSTa13EhUlAAAAWI/Pc5SKiopq3O/p2koIHUdyEk3XUSJRAgAAQKzwOVFq0qRJja11xhha78Iomq6jROsdAAAAYo3PidLy5ctDGYdmzJih++67TxMnTnRej8kYo2nTpumZZ57RwYMH1bt3bz355JM6/fTTQxqLFUTTYg603gEAACDW+Jwo9e/fP2RBrF+/Xs8884zOPPNMt+0zZ87UrFmz9OKLL6pz5856+OGHNWjQIG3dulXp6ekhi8cKvM1RisbFHEiUAAAAYDU+LeZw7Ngxv07qz/FHjx7V9ddfr7/97W9q2rSpc7sxRnPmzNH999+vvLw8de/eXfPnz9fx48e1YMECv+KJRVXnKEWy9a62ihKtdwAAALAanypKHTt21O23366xY8cqOzvb4zHGGL377ruaNWuWLrroIk2dOtWnAG677TZdfvnluvTSS/Xwww87t2/fvl2FhYUaPHiwc1tycrL69++vNWvWaNy4cR7PV1JSohKXT+SORSjKyspUFokswoXj8YMRx4kTcZLiFR9fobKyyp/nhyWotLRSZWXhvehvWVm87Dl3ucrKql9LKznZvv/oUc/7Ubtgjh3UH4wbBIJxg0AxdhCIcI8bfx7Hp0RpxYoV+v3vf69p06bprLPOUq9evZSdna2UlBQdPHhQmzdv1tq1a5WYmKipU6fq1ltv9enBX3nlFX3yySdav359tX2FhYWSpIyMDLftGRkZ2rlzp9dzzpgxQ9OmTau2fdmyZUpLS/MprlArKCio8zm++qqrpM7as2eHliz5Ul9+mSXpPH3//UEtWfJBnc/vjwMH+ktqok8/Xa+4uP3V9h86dJ6kLG3Y8IWaNdsV1thiTTDGDuofxg0CwbhBoBg7CES4xs3x48d9PtanROm0007Ta6+9pj179ui1117TqlWrtGbNGhUXF6tFixbq2bOn/va3vyk3N1dxcb5dmmn37t2aOHGili1bphTHJBYPqq6kV9vqelOnTtXkyZOdt4uKitSmTRsNHjxYjRo18im2UCkrK1NBQYEGDRqkRG8Teny0cqX9de7cuZ1yc0+RMfbXpGHDpsrNza1zrP74/e/tw6hPn3N1ySXVK0Z//3u81q+XOnU6U7m53cMaW6wI5thB/cG4QSAYNwgUYweBCPe4qe2SR658XsxBknJycnTnnXfqzjvv9DuoqjZs2KD9+/frnHPOcW6rqKjQqlWrNHfuXG3dulWSvbKUlZXlPGb//v3VqkyukpOTleyYFOMiMTExav7RBiOWip+761JS4pWYGK/UVPvtsrI4JSaG9zrCJ2NJ8Ligg6OQV1ZmjxWBi6ZxDOtg3CAQjBsEirGDQIRr3PjzGOH9RO3ikksu0RdffKFPP/3U+dWrVy9df/31+vTTT3XqqacqMzPTrQxXWlqqlStXqm/fvpEKO2pwHSUAAAAgdPyqKAVTenq6und3b8Nq0KCBmjdv7tw+adIkTZ8+XZ06dVKnTp00ffp0paWlafTo0ZEIOapwHSUAAAAgdCKWKPliypQpKi4u1vjx450XnF22bFm9v4aSdPJ6SY5KUjRcR4lECQAAALEiqhKlFStWuN222WzKz89Xfn5+ROKJZtHUelc1lqpovQMAAIDVRGyOEuommlrvqCgBAAAg1gSUKK1evVo33HCD+vTpo71790qS/v73v+uDD8J7/Z76zNFiV7WiFMnWO28VJRIlAAAAWI3fidIbb7yhIUOGKDU1VRs3blTJz/1UR44c0fTp04MeIDxzVI6qzlGKxsUcaL0DAACA1fidKD388MOaN2+e/va3v7mtQ963b1998sknQQ0O3nlrvWMxBwAAAKDu/E6Utm7dqosuuqja9kaNGunQoUPBiAk+8LaYQ3m5ZEx4Y6H1DgAAALHG70QpKytL33zzTbXtH3zwgU499dSgBIXaVZ2j5JqkOBKXcKistH9JtN4BAAAgdvidKI0bN04TJ07Uhx9+KJvNpu+++04vv/yy7rrrLo0fPz4UMcIDb3OUpPC237kmZbTeAQAAIFb4fR2lKVOm6PDhwxo4cKBOnDihiy66SMnJybrrrrs0YcKEUMQID7y13rnuCwfXRInWOwAAAMSKgC44+8gjj+j+++/X5s2bVVlZqW7duqlhw4bBjg018LaYg+u+cMYh0XoHAACA2BFQoiRJaWlp6tWrVzBjgR8c7XWOSpLNZk9UystpvQMAAADqyu9EaeDAgbLZbF73v//++3UKCL6pWlFy/FxeHpmKks0mxcd7PsaRKFFRAgAAgFX4nSidddZZbrfLysr06aef6ssvv9SYMWOCFRdq4S1RKi6OTEXJWzVJOtl6R0UJAAAAVuF3ojR79myP2/Pz83X06NE6BwTfVF0eXDrZhheJxRy8LeQg0XoHAAAA6/F7eXBvbrjhBj3//PPBOh1qUXV5cOlkshKJ1jtfKkolJeG/GC4AAAAQiKAlSmvXrlWKo3SAkPPWeidFX+udY1hUVob3YrgAAABAoPxuvcvLy3O7bYzRvn379PHHH+uBBx4IWmComadEKdpb7yR7+11NxwIAAADRwO9EqXHjxm634+LidNppp+mhhx7S4MGDgxYYvDOm5opStLbeSfb2u/T00MYEAAAA1JXfidILL7wQijjgB9f2Ndc5So6fo631Li7OnsSVlbGgAwAAAKwhaHOUED6uFaNIV5R8ab2TWPkOAAAA1uJTRalp06Y1XmTW1U8//VSngFC72hKlcFaUfGm9k+ztd0eOcNFZAAAAWINPidKcOXNCHAb84ZoIWWExB4mKEgAAAKzFp0RpzJgxoY4DfnAkQvHx9vk/DtG6mINEogQAAABr8XsxB1fFxcUqq/KpvFGjRnUKCLXztOKd6+1oW8xBcr/oLAAAABDt/F7M4dixY5owYYJatWqlhg0bqmnTpm5fCD1HIlQ1UaL1DgAAAAgOvxOlKVOm6P3339dTTz2l5ORkPfvss5o2bZqys7P10ksvhSJGVOFIhFyXBpdovQMAAACCxe/Wu//7v//TSy+9pAEDBujmm2/WhRdeqI4dO6pt27Z6+eWXdf3114ciTrig9Q4AAAAILb8rSj/99JPat28vyT4fybEc+AUXXKBVq1YFNzp45C1RovUOAAAACA6/E6VTTz1VO3bskCR169ZNr776qiR7palJkybBjA1eeJujROsdAAAAEBx+J0q//OUv9dlnn0mSpk6d6pyrdOedd+ruu+8OeoCoztscJcdtWu8AAACAuvF5jtKkSZN0yy236M4773RuGzhwoL766it9/PHH6tChg3r06BGSIOGutjlKkago0XoHAACAWOJzRWnp0qXq0aOHzjvvPD3zzDMqKiqSJJ1yyinKy8sjSQojKy7m4EiUqCgBAADACnxOlL766iutWrVKZ5xxhu666y5lZ2frpptuYgGHCLDidZQcrXdUlAAAAGAFfs1R6tevn5577jkVFhbqL3/5i3bs2KEBAwaoU6dOevTRR/Xdd9+FKk644DpKAAAAQGj5vZiDJKWlpemXv/ylVq1apa+//lrXXHONZs6cqXbt2gU5PHhixdY7FnMAAACAlQSUKDkcO3ZMK1eu1MqVK3Xo0CF16NAhWHGhBlxHCQAAAAitgBKlVatW6Ze//KUyMzM1ceJEde7cWatXr9aWLVuCHR88cFSMaL0DAAAAQsPn5cH37Nmj+fPn68UXX9T//vc/9e7dW7Nnz9Z1112nhg0bhjJGVFFbRYnWOwAAAKBufE6U2rVrp+bNm+vGG2/Ur371K3Xt2jWUcaEG0XQdJVrvAAAAEIt8TpReffVVXXHFFUqorXSAkPO2PHgkFnOg9Q4AAACxyOesJy8vL5RxwA/elgeP5GIOtN4BAAAgltRp1TtERjS13nmLpSoqSgAAALASEiULsuJ1lEiUAAAAYCUkShbkbY5SNF9HidY7AAAAWEnAidI333yjd955R8XFxZIkY0zQgkLNvM1R4jpKAAAAQHD4nSgdOHBAl156qTp37qzc3Fzt27dPknTLLbfod7/7XdADRHVWvI4SiRIAAACsxO9E6c4771RCQoJ27dqltLQ05/Zrr71WS5cuDWpw8CyaFnOg9Q4AAACxyO+LIi1btkzvvPOOcnJy3LZ36tRJO3fuDFpg8M5RMfLWesd1lAAAAIC68buidOzYMbdKksOPP/6oZEfZACFVW+tdNF5HyZEolZVJlZWhjQkAAACoK78TpYsuukgvvfSS87bNZlNlZaUee+wxDRw4MKjBwbNoar3z9TpKrjk07XcAAACIdn633j322GMaMGCAPv74Y5WWlmrKlCnatGmTfvrpJ/33v/8NRYyowtvy4Fa4jpJkb79LTQ1dTAAAAEBd+V1R6tatmz7//HOdd955GjRokI4dO6a8vDxt3LhRHTp0CEWMqMLb8uDR3HqXkCDF/TzaqCgBAAAg2gV0HaXMzExNmzZNb731lpYsWaKHH35YWVlZfp/n6aef1plnnqlGjRqpUaNG6tOnj95++23nfmOM8vPzlZ2drdTUVA0YMECbNm0KJOSYYsXWO5vtZPsdCzoAAAAg2vmdKLVv314PPPCAtm7dWucHz8nJ0aOPPqqPP/5YH3/8sS6++GKNGDHCmQzNnDlTs2bN0ty5c7V+/XplZmZq0KBBOnLkSJ0f28pqW8yhoiJ8Cyb4WlGSWPkOAAAA1uF3onT77bdr6dKl6tq1q8455xzNmTPHedFZfw0fPly5ubnq3LmzOnfurEceeUQNGzbUunXrZIzRnDlzdP/99ysvL0/du3fX/Pnzdfz4cS1YsCCgx4sVtc1RksJXVfL1OkoS11ICAACAdfi9mMPkyZM1efJkbdu2TS+//LKefvpp3X333Ro4cKBuuOEG3XTTTQEFUlFRoddee03Hjh1Tnz59tH37dhUWFmrw4MHOY5KTk9W/f3+tWbNG48aN83iekpISlbh8Ei8qKpIklZWVqSycPWkeOB6/rnGUlsZLilNcXLnKykyVvfaM5dixMuecoFAqLU2QZJPkKZaTKiokY+zHrlpVodNOq1R8fOjjixXBGjuoXxg3CATjBoFi7CAQ4R43/jyOzRjj/dOtj9atW6ff/va3+vzzz1VRUeHXfb/44gv16dNHJ06cUMOGDbVgwQLl5uZqzZo16tevn/bu3avs7Gzn8bfeeqt27typd955x+P58vPzNW3atGrbFyxY4PH6T1Y0eXJ/ffttEz3wwFqdc85+5/aKCpuuuuoKSdLf/75E6emhH3C/+c0lKixsqEcfXaUuXQ56PGbt2iw9++wZOnDg5FJ3zZsX65ZbvlCfPoFVIwEAAAB/HT9+XKNHj9bhw4fVqFGjGo+tU6L00UcfacGCBVq4cKEOHz6s4cOHa+HChX6do7S0VLt27dKhQ4f0xhtv6Nlnn9XKlSt16NAh9evXT999953bQhG//vWvtXv3bi1dutTj+TxVlNq0aaMff/yx1hcj1MrKylRQUKBBgwYp0ZdeNS/OPjtBX35p09tvl+uSS06+fcZIycn28+7eXaaMjDqHXKtOnRK0c6dNa9aUq1ev6kPpzTdtuu66eNlHmc253WazH/vKKxX6xS/qnKvHvGCNHdQvjBsEgnGDQDF2EIhwj5uioiK1aNHCp0TJ79Y7R8vdggULtGPHDg0cOFCPPvqo8vLylJ6e7newSUlJ6tixoySpV69eWr9+vR5//HHdc889kqTCwkK3RGn//v3KqCEDSE5OVrLr1U1/lpiYGDX/aOsai6NimJqa4HGeUlmZZEyiT/OG6soRS0pK9VgqKqTf/U7ylIobY5PNJt11V4Kuukq04fkomsYxrINxg0AwbhAoxg4CEa5x489j+D2LpUuXLnr77bd12223affu3Vq2bJnGjBkTUJLkiTFGJSUlat++vTIzM1VQUODcV1paqpUrV6pv375BeSyr8nYdJddt4V7MwdOqd6tXS3v2eL+vMdLu3fbjAAAAgGjid0Xpq6++UufOnYPy4Pfdd5+GDh2qNm3a6MiRI3rllVe0YsUKLV26VDabTZMmTdL06dPVqVMnderUSdOnT1daWppGjx4dlMe3qpquXRTuaynVFIuviyEGuGgiAAAAEDJ+J0rBSpIk6fvvv9eNN96offv2qXHjxjrzzDO1dOlSDRo0SJI0ZcoUFRcXa/z48Tp48KB69+6tZcuWBa16ZVXelgeXTlaUHMeEWk0VJV+vQRzAtYoBAACAkPIpUWrWrJm2bdumFi1aqGnTprLZbF6P/emnn3x+8Oeee67G/TabTfn5+crPz/f5nPVBTa134a4o1ZQoXXihlJMj7d3reZ6SzWbff+GFoY0RAAAA8JdPidLs2bOdVZzZs2fXmCgh9HxpvQtXRammWOLjpccfl0aOtCdFrsmSYwjNmcNCDgAAAIg+PiVKY8aMcf48duzYUMUCH9WUnIRzMQdjaq4oSVJenvT669LEie4LO+Tk2JOkvLyQhwkAAAD4ze9V7+Lj47V///5q2w8cOKB4SgNhUdMcpXC23lVWVn9cT/LypB07pBtusN++8kpp+3aSJAAAAEQvvxMlb9enLSkpUZKnSTMIqsrKkwlKTXOUwtF655qMeasoOcTHS9262X9u1ox2OwAAAEQ3n1e9e+KJJyTZF1h49tln1bBhQ+e+iooKrVq1Sl26dAl+hHDjmpxEuvXO0XYn1Z4oSVJamv378eOhiQcAAAAIFp8TpdmzZ0uyV5TmzZvn1maXlJSkdu3aad68ecGPEG5qS5TC2Xrnmij5cpFjEiUAAABYhc+J0vbt2yVJAwcO1KJFi9S0adOQBQXvXFvqIr3qnWsy5ksrXYMG9u/HjoUmHgAAACBY/L7g7PLly0MRB3xU27ygSLTexcXZv2pDRQkAAABW4fdiDiNHjtSjjz5abftjjz2mq6++OihBwTvXpcE9Xc4qEhUlX9ruJBIlAAAAWIffidLKlSt1+eWXV9t+2WWXadWqVUEJCt7VlpxEoqLky0IOEokSAAAArMPvROno0aMelwFPTExUUVFRUIKCdzVdQ8l1ezQmSsxRAgAAgFX4nSh1795dCxcurLb9lVdeUTfHhXIQMo4EyNslq2i9AwAAAOrO78UcHnjgAV111VX63//+p4svvliS9N577+mf//ynXnvttaAHCHe03gEAAACh53eidMUVV2jx4sWaPn26Xn/9daWmpurMM8/Uu+++q/79+4ciRriIxtY7fytKpaX2+/qaYAEAAADhFtBH1csvv9zjgg4IvWhsvfN3jpJkryo1ahT8mAAAAIBg8HuOkiQdOnRIzz77rO677z799NNPkqRPPvlEe/fuDWpwqM7KrXfJySeXNKf9DgAAANHM74rS559/rksvvVSNGzfWjh07dMstt6hZs2Z68803tXPnTr300kuhiBM/qy1RiubFHGw2e/vdsWMkSgAAAIhufleUJk+erLFjx+rrr79WSkqKc/vQoUO5jlIY1DZHKZorStLJeUosEQ4AAIBo5neitH79eo0bN67a9tatW6uwsDAoQcE7X+coRWui5JinREUJAAAA0czvRCklJcXjhWW3bt2qli1bBiUoeGfl1juJJcIBAABgDX4nSiNGjNBDDz2ksp8/JdtsNu3atUv33nuvrrrqqqAHCHdWXsxBIlECAACANfidKP3pT3/SDz/8oFatWqm4uFj9+/dXx44dlZ6erkceeSQUMcJFNF5HKZDWO+YoAQAAIJr5vepdo0aN9MEHH+j999/XJ598osrKSp199tm69NJLQxEfqojG6yjRegcAAIBYE9AFZyXp4osv1sUXXxzMWOADWu8AAEC0qaiQVq60adWq1mrQwKaBA6X4+EhHBdSNTx9xn3jiCd16661KSUnRE088UeOxDRs21Omnn67evXsHJUC487X1LhwVJUeiREUJAID6a9EiaeJEac+eBEm9NGuWlJMjPf64lJcX6eiAwPmUKM2ePVvXX3+9UlJSNHv27BqPLSkp0f79+3XnnXfqscceC0qQOKm21rtwVpQcj8EcJQAA6qdFi6SRIyVj3Lfv3Wvf/vrrJEuwLp8+4m7fvt3jz94UFBRo9OjRJEoh4Ovy4LTeAQCAUKqosFeSqiZJkn2bzSZNmiSNGEEbHqzJ71XvfHHBBRfo97//fShOXe9xHSUAABANVq+W9uzxvt8Yafdu+3GAFQWUKL333nsaNmyYOnTooI4dO2rYsGF69913nftTU1M1ceLEoAWJk2qbo2SVxRxovQMAwNr27QvucUC08TtRmjt3ri677DKlp6dr4sSJuuOOO9SoUSPl5uZq7ty5oYgRLnxdHjxaEyXHHCUqSgAAWFtWVnCPA6KN38uDz5gxQ7Nnz9aECROc2+644w7169dPjzzyiNt2BB+tdwAAIBpceKF9dbu9ez3PU7LZ7PsvvDD8sQHB4HdFqaioSJdddlm17YMHD1ZRUVFQgoJ3XEcJAABEg/h4+xLgnths9u9z5rCQA6zL70Tpiiuu0Jtvvllt+7/+9S8NHz48KEHBu2i8jhJzlAAAqJ/y8uxLgKekuG/PyWFpcFifzxecdejataseeeQRrVixQn369JEkrVu3Tv/973/1u9/9LjRRwikar6PkT+sdc5QAAIgteXnSBRdI774rNWxYqjffjNPAgQlUkmB5Pl9w1lXTpk21efNmbd682bmtSZMmev7551kWPMS4jhIAAIg2R4/av1dW2tS/vyFJQkzw+4KziKxobL1jMQcAAOo3R6J04kS8jKmIbDBAkAR8wdkff/xRBw4cCGYs8EE0LebgeAzmKAEAUL+drCjF6cSJyMYCBItfidKhQ4d02223qUWLFsrIyFCrVq3UokULTZgwQYcOHQpRiHDlz3WUPC3VGUxcRwkAAEgnE6WqPwNW5vNH3J9++kl9+vTR3r17df3116tr164yxmjLli168cUX9d5772nNmjVq2rRpKOOt93ydo2SMVFHhXxIT7Fg8cVSUysrsX/7cFwAARCcSJcQinz9GP/TQQ0pKStL//vc/ZWRkVNs3ePBgPfTQQ9UWfkBw1TZHybXSVFYW2kSpLos5SPaqUuPGwY0JAACEV3m53NrtSJQQK3xuvVu8eLH+9Kc/VUuSJCkzM1MzZ870eH0lBJevrXdS6Bd0CCRRSk6W4n4edbTfAQBgfVUTo2PHbJEJBAgynxOlffv26fTTT/e6v3v37iosLAxKUPDO19Y712MjFYsnNhsr3wEAEEuqJkpUlBArfE6UWrRooR07dnjdv337djVv3jwYMaEGtSUn8fEnKzahTpQCqShJJEoAAMQSEiXEKp8Tpcsuu0z333+/Sj30c5WUlOiBBx7QZZddFtTgUF1tc5Rc90Vj653EEuEAAMQSEiXEKp8/4k6bNk29evVSp06ddNttt6lLly6SpM2bN+upp55SSUmJ/v73v4csUNjVNkfJsa+kJDpb7ySWCAcAIJZUT5SYo4TY4HOilJOTo7Vr12r8+PGaOnWqzM8X6bHZbBo0aJDmzp2rNm3ahCxQ2PmSnLheSymUaL0DAABUlBCr/PqI2759e7399ts6ePCgvv76a0lSx44d1axZs5AEh+qiqfUu0IoSiRIAALHjyBH32yRKiBUBXWWnadOmOu+884IdC3zgS3LiaMuL9ooSc5QAALC+6suDRyYOINh8XswB0cGXOUrRvpgDc5QAAIgdzFFCrCJRsphomqNE6x0AAGCOEmIViZLF+DJHidY7AAAQLo7EqFEj43YbsLqIJkozZszQueeeq/T0dLVq1UpXXnmltm7d6naMMUb5+fnKzs5WamqqBgwYoE2bNkUo4sgyJjZa76goAQAQOxyJUUaG/Tt/CEWsiGiitHLlSt12221at26dCgoKVF5ersGDB+uYy7+wmTNnatasWZo7d67Wr1+vzMxMDRo0SEeqLrFSD1RUnPw5GipKXEcJAAA4PpJlZhq324DVBbTqXbAsXbrU7fYLL7ygVq1aacOGDbroootkjNGcOXN0//33Ky8vT5I0f/58ZWRkaMGCBRo3blwkwo4Y18QnGuYoUVECAACOilJmpuM2izkgNkQ0Uarq8OHDkuS8LtP27dtVWFiowYMHO49JTk5W//79tWbNGo+JUklJiUpKSpy3i4qKJEllZWUqC3XmUAvH4wcah73Q5siQyrwmQgkJ8ZLidPx4ucrKTECP5Yvy8gRJthpj8SQ5OU5SvI4cqVRZWUWtx6PuYwf1E+MGgWDcwF9Hjtg/d7RqVSEpTkePGpWVlUc6LFhEuH/n+PM4UZMoGWM0efJkXXDBBerevbskqbCwUJKU4Wh6/VlGRoZ27tzp8TwzZszQtGnTqm1ftmyZ0hyljAgrKCgI6H5FRUmShv58jiWKj/d83OHD50vK0IYNn6tx492BBemDY8cuk5SstWtXa+9e3+vs//vfKZJ6aseO/Vqy5MOQxReLAh07qN8YNwgE4wa+2r37QknNdOTINkmn69Chci1Z8nakw4LFhOt3znE/WpqiJlGaMGGCPv/8c33wwQfV9tls7iVcY0y1bQ5Tp07V5MmTnbeLiorUpk0bDR48WI0aNQpu0H4qKytTQUGBBg0apER/J/ZI2rfP/j0uzmj48Fyvx/3tb/YMqmvXM5Wbe0ZAsfoiLs4+fAYOvFCnneb7/YqKbHrySSk9vZVyc70/D5xU17GD+olxg0AwbuCv3//e/nmgX7+OeuklqaQkUUOH5srLRzXATbh/5zi6zXwRFYnS7bffrn//+99atWqVcnJynNszf252LSwsVFZWlnP7/v37q1WZHJKTk5WcnFxte2JiYtT8wq9rLImJthrv73j6lZUJfi+04A9H5TItLdGvx3Hkq8XFcUpMZIV6f0TTOIZ1MG4QCMYNfOVYg6t1a/sfasvLbTImscYVeoGqwvU7x5/HiOinVGOMJkyYoEWLFun9999X+/bt3fa3b99emZmZbqW40tJSrVy5Un379g13uBHnyzWUJK6jBAAAwufk8uCm2jbAyiJaUbrtttu0YMEC/etf/1J6erpzTlLjxo2Vmpoqm82mSZMmafr06erUqZM6deqk6dOnKy0tTaNHj45k6BHhyzWUpOi/jhLLgwMAEDscy4E3aSIlJVWotDReR49KzZtHNCygziKaKD399NOSpAEDBrhtf+GFFzR27FhJ0pQpU1RcXKzx48fr4MGD6t27t5YtW6b09PQwRxt5vl63KBwVJWNOXtfJ3yopy4MDABAbysulEyfsPzdsKKWklKu0NJ5rKSEmRDRRMqb2pattNpvy8/OVn58f+oCinK+td+G4jlK5y6qfXEcJAID6ybWNvmFDKTW1XEVFybTeISYwk95CfK0ohaP1LhiJEnOUAACwNkdClJBg72hJSSl32w5YGYmShfg6RykcrXeu5/a39c4xR6m8PPQLTgAAgNBxJEQNG0o2m5SSUuG2HbAyEiUL8beiFO2tdxLtdwAAWJlroiRRUUJsIVGyEH/nKIWy9c41CYuP9+++SUlS3M8jj/Y7AACsy7Fog2ONrdRUEiXEDhIlC4mm1jvXpcH9vfK2zcaCDgAAxILqFSVa7xA7SJQsJBoXc/C37c6BaykBAGB9tN4hlpEoWUg0XUfJ11i8oaIEAID1eUuUuI4SYgGJkoVE43WUAq0osUQ4AADWVzVRYo4SYgmJkoX4OkeJ1jsAABAOJEqIZSRKFkLrHQAAiCZVV71jMQfEEhIlC4nF1jsSJQAArIvFHBDLSJQsJJZWvWOOEgAA1keihFhGomQh0XQdpbq23jFHCQAA66s+R4nWO8QOEiULicWKEokSAADWRUUJsYxEyUJ8naNkhYoSrXcAAFgf11FCLCNRshB/K0os5gAAAEKp6qp3LA+OWEKiZCFcRwkAAEQTbxWlsrLQfg4BwoFEyUK4jhIAAIgm1ROlimr7AKsiUbKQWLyOEnOUAACwrqqJUkKCUXKycdsHWBWJkoXEUusdFSUAAKytokIqLrb/7EiUXH8mUYLVkShZSCy13jFHCQAAa3PtCiFRQiwiUbIQf1vvqCgBAIBQcax4l5AgJSef3O74YyiJEqyORMlCYnF5cOYoAQBgTa7zk2y2k9sbNrTPUeJaSrA6EiUL8XWOkmN/eblkTGhjofUOAID6qepCDg6OaypRUYLVkShZiL8VJdf7BButdwAA1G/eEiVa7xArSJQsxNc5Sq4Vp1AlSsG6jtKxY6GregEAgNDxliixmANiBYmShcRiRamiIrRzqQAAQGh4T5S4jhJiA4mShfh7HSUpdCvf1TVRcpTlJdrvAACwIsdiDY45SQ5UlBArSJQsxNeKks12MoGJ1ta7xEQpPt7+M4kSAADWwxwlxDoSJQvxdY6S6zHRWlGy2VgiHAAAK2OOEmIdiZKF+Np6J4X+Wkp1TZQkVr4DAMDKakuUuI4SrI5EyUL8aXdzJFPR2noncS0lAACsjMUcEOtIlCzEn+Qk2lvvJCpKAABYGa13iHUkShbizxylcFWUgpEoMUcJAADrYdU7xDoSJQuJxjlKdWm9o6IEAIB1UVFCrCNRspBYa71jjhIAANblfXlw5ighNpAoWUg0tt4Fo6JE6x0AANZDRQmxjkTJQmKtokTrHQAA1lVbolRSEro/2ALhQKJkEcZIFRX2n6NpjhKJEgAA9VNtiZLrMYAVkShZhGvCEyutd8xRAgDAurytepeUdPJzCIkSrIxEySJcW+hirfWOOUoAAFhLRYVUXGz/uWpFyXUbiRKsjETJIqKtokTrHQAA9ZfrHzlJlBCr6vAxF+Hkb6IU6jlKtN4BAFB/ORKg+HgpObn6fhKlkyoqpNWrpX37pKws6cIL7a8boh+JkkU4EpOEBMlmq/14K7XekSgBAGAtrgs5ePpcQqJkt2iRNHGitGfPyW05OdLjj0t5eZGLC76h9c4i/LmGkhS+xRyYowQAQP3jbcU7BxIle5I0cqR7kiRJe/faty9aFJm44DsSJYtwJCa+LA0uha+iFIwLzlJRAgDAWhwJUNUV7xzqe6JUUWGvJBlTfZ9j26RJJy/9guhEomQR/s4JssJ1lJijBACANTmWBq+touQ4rr5Zvbp6JcmVMdLu3fbjEL1IlCwiWlvvqCgBAFD/1NZ656g01deK0r59wT0OkUGiZBGBVpSssJgDc5QAALAW5ijVLCsruMchMkiULMLfOUpcRwkAAIQKiVLNLrzQvrqdt5WKbTapTRv7cYheJEoWEW1zlIJ9HSVPkx0BAEB0IlGqWXy8fQlwTxzJ05w5XE8p2kU0UVq1apWGDx+u7Oxs2Ww2LV682G2/MUb5+fnKzs5WamqqBgwYoE2bNkUm2Ajzd46SlVrvKipCFycAAAg+Vr2rXV6e9Prr1S/Im5Nj3851lKJfRBOlY8eOqUePHpo7d67H/TNnztSsWbM0d+5crV+/XpmZmRo0aJCO1MMlVPyt4FjpOkoS7XcAAFiJr6ve1edESbInQx06nLz90EPS9u0kSVZRh4+5dTd06FANHTrU4z5jjObMmaP7779feT+Ppvnz5ysjI0MLFizQuHHjwhlqxMXidZQSE+0l54oKe6LUtGlwYgMAAKFF653vXFe2a9qUdjsriWiiVJPt27ersLBQgwcPdm5LTk5W//79tWbNGq+JUklJiUpKSpy3i4qKJEllZWUqC1V5xUeOxw8kjuJim6QEJSRUqqys9quTxcXFSYpXSYlvx/urvDxBkk3GlNWpatWgQYKKimw6fLhMrVoFLbyYU5exg/qLcYNAMG7gi6KieElxSk2tUFlZpST3sZOSYv/cUlRkVFZWHrlAI6y4WDp48ORflXfvPvl6wS7cv3P8eZyoTZQKCwslSRkZGW7bMzIytHPnTq/3mzFjhqZNm1Zt+7Jly5Tm2usVQQUFBX7fZ/36HEnn6PDhA1qyZE2tx2/b1k5SD+3eXaglS9b7/Xi1KS0dLsmmVave15YtJwI+T3z8EEkpeuedD/T110VBiy9WBTJ2AMYNAsG4QU127DhfUob+97/PtGTJbrd9BQUF2ratqaSL9MMPx7VkybsRiTEa7NvXQNKlztvr1+/VkiUbIxdQFAvX75zjfsz3iNpEycFWZV1FY0y1ba6mTp2qyZMnO28XFRWpTZs2Gjx4sBo1ahSyOH1RVlamgoICDRo0SIl+9qz9+KP9OWdnN1dubm6tx+/bZz++WbNMn473V0WF/fxDhlyszMzAz9O0aYIOHpTOOedC9enD0nfe1GXsoP5i3CAQjBv4YuZMe/9Y375nKjf3DEnuY6dtW/vYqaxMC8nnEKtYvdr9M2tcXI5yc7l4kqtw/85xdJv5ImoTpcyfP30XFhYqy+VqXPv3769WZXKVnJys5KrLi0hKTEyMml/4gcRS+XOVNikpTomJta/BkZpq/15R4dvx/sbiWM47NTUxKEuEl5Ym1Ok89UU0jWNYB+MGgWDcoCaOi8U3bVr9/+/ExEQ1bWrfePSorV6Po++/t39PSLDP7/7uu+B/LosV4fqd489jRO071b59e2VmZrqV4UpLS7Vy5Ur17ds3gpFFRqDLg4ei3dP1nHUdz1x0FgAA6/F11bsTJ04uAFUf7d1r/37mmfbv330XuVjgv4hWlI4ePapvvvnGeXv79u369NNP1axZM51yyimaNGmSpk+frk6dOqlTp06aPn260tLSNHr06AhGHRmBXnA2FKveuf7Cq8vy4NLJRMnxlykAABD9fF31TrL/H9+4cehjikaOROncc6VPPpEOH7a/Ho6OGkS3iCZKH3/8sQYOHOi87ZhbNGbMGL344ouaMmWKiouLNX78eB08eFC9e/fWsmXLlO7t6mYxzN/lwUN5HaVQJEpUlAAAsI7aEqWkpJPtZkeP1t9EyVFB6tLF/lodPWrf1qlTZOOCbyKaKA0YMEDGeJ/Ab7PZlJ+fr/z8/PAFFaWiqaIUzNY7x19USJQAALAGx/UPJe+Jks1m33foUP2+lpKjotS6tZSdLW3bZt9GomQNUTtHCe6iaY6So6Jks0lxdRxBtN4BAGAtrn/crKnJx5FEOeYz1UeuiVLr1vafmadkHSRKFuFvRSmUrXeOc9a17U6i9Q4AAKtxVIji4yUPCw07OZKo+lpRMuZkUuSoKEknkydEPxIli/B3jlI4FnMIxgqOJEoAAFiL64p3NVza0llRqq+J0oEDJz+HZWVRUbIiEiWLCHSOUihb74JRUWKOEgAA1lLbQg4O9T1RclSOWra0/6GbipL1kChZhL9zlKzWesccJQAArIFEyTeu85Ncv1NRsg4SJYuIplXvaL0DAKD+IlHyjSMhclSSqChZD4mSRUTjdZRYzAEAgPrHkfjUdlnL+p4o1VRRquHqOIgiJEoWEU0VJX9jqQlzlAAAsBYqSr6pmihlZdm/l5baF3pA9CNRsohovI4Sc5QAAKh/XFe9q0l9v45S1da7pCT7wg6u+xDdSJQsItDWu8pK+xW0g4nWOwAA6i9fK0r1/TpKVStKEvOUrIZEySICbb1zvW+kYqkJrXcAAFgLrXe+8ZQosfKdtZAoWUSgrXdS8BMlWu8AAKi/SJRqV1Ii/fCD/WcqStZFomQR/lZxXFv0QlVRovUOAID6h1XvaldYaP+elCQ1b35yOxUlayFRsgh/5yjFx5/8Odgr34XqOkoslQkAQPSjolQ7R8UoO1uy2U5up6JkLSRKFuFvRclmC921lILZeueYo1RZGZqlzAEAQHD5u+pdfU6UXNvuXG9TUbIGEiWL8HeOkuuxwU5AQtF6JzFPCQAAK/C3olQflwevujS4AxUlayFRsohAVpoL1bWUgtl6l5h4MuFinhIAANGP5cFrV1tFaf/+0FzrEsFFomQR/s5Rcj02mlvvJBZ0AADASvytKBUXB/+ajtHOW6LUooX9j8TGnFzwAdGLRMki6lJRClXrXTAqShLXUgIAwEr8XfVOqn/t9d4Spbg4KSvL/jPzlKIfiZJF1GWOklUqSvXtlygAAFbka0UpOfnkKrz1rf3O2xwl123MU4p+JEoWEUgVJ1Std8FczEGi9Q4AAKuorDz5h83aEiWbrX6ufGeM94qS6zYqStGPRMkiApmjFKrWu2Au5iCRKAEAYBWu3R+1JUqux9SnROnw4ZOfaagoWRuJkkUE0npnlcUcmKMEAIA1OBKeuDgpJaX24+tjouSoFDVp4n4ZFAcqStZBomQR0biYA3OUAACoX1znJ9lstR9fH6+lVFPbnURFyUpIlCyiLq130XwdJYnWOwAArMLXFe8c6uO1lGpLlKgoWQeJkgVUVNgnBkqx2XpHogQAgDX4uuKdQ31uvfM0P8l1OxWl6EeiZAGurXPR1HoX7Oso0XoHAEB0I1Gqna8VpaKi+vW6WBGJkgW4VoRi+TpKVJQAAIhujrlGJEre1ZYopaeffF1ov4tuJEoW4Jro+DNHidY7AAAQTFSUaldbouS6j0QpupEoWYAj0bHZTl7h2hdWa70jUQIAILqRKNWutjlKrvuYpxTdSJQsIJBrKEnWqygxRwkAgOjm76p39S1RKi+XCgvtP1NRsj4SJQsItIITqjlKobqOEhUlAACiW6AVpfpyHaXvv5cqK+0dQK1aeT+OipI1kChZQCDXUJJC13rHdZQAAKif/E2U6tt1lBwVoszMmqdLUFGyBhIlC4j11jvmKAEAYA2selczXxZykKgoWQWJkgXUtfUuVIs5MEcJAID6hcUcauZrokRFyRpIlCygrq13oaoo0XoHAED9QqJUM38rSt99JxkT2pgQOBIlCwi0omSV1jsSJQAArIFV72rmy9LgkpSVZf9eWiodOBDamBA4EiULCHSOktWuo0TrHQAA0Y2KUs18rSglJUktW7rfB9GHRMkCom158FBWlCg/AwAQvQJNlI4dsy+bHet8TZQk9/Y7RCcSJQsIdI6S1VrvjJFKSoJzTgSuokJasUL65z/t3ysqIh0RACBaBLrqnVQ/Okd8bb2TTiZTVJSiV5A+6iKUAq0oOdbv/+Yb+wfeCy+seU3/UMfjjSNRkuxVpZSU4Jw3mlRUSKtXS/v22fuSg/VeBNuiRdLEidKePSe35eRIjz8u5eVFJqZQvHZWeT8AINr4W1FKTZXi4uzVpKNHfZ/bZEXHjkmHD9t/pqIUG6goWUAgc5QWLZKmTbP/vG6dNHCg1K6dfXtdBbuilJh48rnF4l+bFi2yv/YDB0qjRwf3vQimRYukkSPdkyTJ/peukSMjE29tr10g1S+rvB8AEG0qK0/+P+1romSz1Z95So7KUMOGUqNGtR9PRSn6kShZgL8VHMcH3kOH3LcH6wNvsK+jJMXuynfRmHx4UlFhryR5miPm2DZpUnjb8Gp77aZM8T/hscr7AQDRyPX/aH8qQ/UtUfKl7c71OCpK0YtEyQL8maMUjg+8wb6OkhSbiVI0Jh/erF5dPXlwZYy0e7f9uHCo7bUzRnrsMf8SHiu9HwAQjRyJTlycf23y9SVRciQ8vrTduR5HRSl6kShZgD+td+H4wBvs1jvp5BLhsZQoRVvyUZN9+4J7XF3V9tp5U1PCY6X3AwCikev8JJvN9/vVl0TJnxXvJCpKVkCiFAVqm2fhT+tdOD7wBrv1rqLi5JKha9bEzl/0oy35qInjwnfBOq6u6vKaeEt4rPR+AEA08nfFOwcSJc8cx+3fH/wVihEcrHoXYb6sMuZPouTrB9lWrexJWSCrfgWz9a7q858yRXriiciushaoqiuptWrl2/1ClXz4s7LbBRfY2x9rqui1aWM/RzhiDcbYqprwRFsy6IpV+ABYgb8r3jnUl0TJn6XBJalFC/v/d2VlUmGh/f9ZRBcSpTCpqJBWrrRp1arWatDApoEDpX/9yz6fouqcCcc8i9dfl0aMkL76yr79wAH7eWr6AHXhhfZEa+9e7xdvTU+Xxo71npzV9KGtouLkijeffiqdfXbgH+gcE+trev6+xBMN+zwlvM2b1/4aJCVJ3brVnLR6Gju1vea1JeBVn8fbb9fe9piba/8eaILtT6zBSBKqJjznnmt/vR2trJ6EMhn0JhqXZAcAT+qaKDkqUrHK34pSXJz9/6pdu+z3jdVEydJ/DDQx7vDhw0aSOXz4cMRieOMNY3JyHFPQ7V+tWxvTvLn7Ntcvm82+v+r9cnLs56vt8Ww2+5e383t6PJvNmLvv9v6Ynp6HL/F4Ul5e/VxV42nTxpjXXgssnnDuu/vu2l/rmvYnJnp/TWt7zcvLjVm+3JgFC+zfy8tPvv/+vMeOrwkTqu9r3Nj+PS7OmJYt/YvF9f32tM9brL6+dt6+2rQxpqTk5GO+/74xo0bVfs7f/tb/sVwXtb1Xb7wR2OvqUFpaahYvXmxKS0t9jinQx6stlkAfMxSxhjuWUAnVYwYybmAddRk3r75q/x3Vv7/n/d7Gzq9+Zb/fI48EGnV0qO21O+UU+/Ncu9b3c55/vv0+gXyWsgJfPjuG+3eOP7kBiVKI+fJB0J8v1w9QtT2up+QsJSWwx6xrPFUtX1631yBa9vny5SnhbdPGmDFjan5NvSVgNSU8tSXgtX15+mBeVmbMBRfUHqu/Cearr9aeLHt77Ryvjbf3pmdPz+eOizMmP997MpicbMy6deH50O7LHwtq+mOJL0l0QUGZmTx5vSkoKPM5cQ32Hxjq8pihiDXcsQQ6PkL1uvmyz99xU9u+UDz/aNsXbfGEatxMmWK/z/nne/7d6O0D7+232+93xRXR+9rUtq+216601P5/jGTMK6/4/n9HXp79PmPGRP45BnuM+/LHQPtrR6IUMZFMlGr7IBTol6PaUts/wqqD9t13gx+LP/G4WrAgNLFE69e777q/FyUltY8Nxy/ccH15ex/Ly+0JWCDnC2Rfba9dTf/hN21a+/k8JYOlpfb/wCVj4uPdjw/Vh/Zp0wJ/n2raF2jiWlNiXpdYAn3Mmp5HoLEGes663C+cVey6dgaEKlGOlup/fX+OoRo3rjx94H3jDWPS0yP//Ou6r7bXLiur9tenqjfeMKZhw+h5jsEc4750Tjk+c5AoRVAkE6W6VE18+Vq+3L94Qp2c+BNPqF+baPtasMA6z7/q+xjpWKu+dq6qJi4lJcY0a+b9XDUl9S+95P0+ofjQHu7XMVKP2bx5ZB47Gr5qev7hHh+RqMTXVhmPplhj/TmGatxU7Sip+oG3pgQjWl4bX/YF0qlRW8eNVV6bQMe4r1/2P1ZGb6JkieXBn3rqKbVv314pKSk655xztNoiFzoJ9TLD/p4/1Kt5+ROPY9EJf67DYGVVX/toXoK6amyRjrWmcRsfLw0YII0aZf++Zo3000/ejzfG89LhFRXSffd5v48xni9wu2ePfbsxnu9XUxzhFqnHPHAgMo8dDWp6/uEeH4E+Xl32GSPNmhXc5x9t+4yR/vzn6H+OgfLl8bxdqNuXi3wH+pjh3nfggPdjaruvp9fHSq9NoP+OfRXpzxi1ifpEaeHChZo0aZLuv/9+bdy4URdeeKGGDh2qXbt2RTq0WoU6MfH3/KFOTvyJJz7evqqXVD2eWEqebDbPK6lFYglqX1WNLVKxenvtahLotZICvcAtgJrFynXxauK4DmB95O2PTxK/VyXvr4/VXptQ/juO5s9DkgWWB581a5Z+9atf6ZZbbpEkzZkzR++8846efvppzZgxo9rxJSUlKikpcd4uKiqSJJWVlakszFfzOv98qXXrBH33nWRM9U//NptRs2ZSSoq0d+/J/a1bGxUXSwcPer9f69bS+eeX+32Bsj//2abrrouXzVb13K5/FvCUqRiv+wKNZ/hw6ZVXbJo8Ob7a83/ssQrddVe819eupngita/qa2qz2bf/6U8Vqqw0bv+Z1jY2JKP4ePt/wJ73+8JUibfm99jb+1h7rHVl/HrtatKypU2+/Fpr2bJcZWUnX4/du327X2hUf/7V3zsAiF67d9t/pzo+Z5WVlUX492p0cbw+J2/z2rh/5jg5bsLBn8eJ6neptLRUGzZs0L333uu2ffDgwVqzZo3H+8yYMUPTpk2rtn3ZsmVKS0sLSZw1ueGGLP3xj+fK04dWY6Rbblmv887bp82bm+vgwRQ1bXpC3bod0Ecf1Xy/669fr3fe8b9emZwsTZmSpWefPUMHDqQ6t7doUawLLtirxYs7enxM95+DG88TT6ja84+Pr/m1qymeSOy78spvtHp1jttr2rx5sX71qy+VnLxPS5aomtqe3/Dh3/jwfnhOstLTS5WUVOnXe1zT++jbe+F/gtmiRbF++csv9fzzZ/j12nlTUSE1bz5YBw6k1PiYRUUFbufdubO5pAt8f6Aguu66r1RQ0K7a8y8tjdeRI0ny/3UNhbr8ESHcCV+4X5uakPCifti5c52WLDnZn1ZQUBDR36uhEfi/56qvT+y9NrXx7TNHQUFBWKI5XtuFI12FYc5UwPbu3Wskmf/+979u2x955BHTuXNnj/c5ceKEOXz4sPNr9+7dRpL58ccfTWlpaUS+Fi4sM61bV7pNXsvJqTQLF5aF5H6+fBUXl5qCgjLz0ktlpqCgzBQX1/6YoYwnkNcgmvbV9JrW5T32tn/y5HJjs1Uam819n2PbwoVlAb3HgcRaUyyS/aumOAN97WqKs7bXxtO/h9atq9+n7l+O16D6Pput0uTkVJriYs/Pv6bn4e11Pfl43p5H7fv8fR9r29esWU2va92eRyhem2DH4svzD9Z7FYz3P9j74uND9/yjZZ/VnmMwx43r77HS0lJz7Ngxs3jxYnPs2DEffq9G32vj7Tk2b17p8fdxba9d1dfH9/9zouf512WMO1672j5zuI6bcHwu//HHH40UA6veORKlNWvWuG1/+OGHzWmnnebTOSJ9HSWHmq5NUdv9oukihlaKJxLXGAj283Ps9zR2PC3H2aaNb9e0CvR5+LM8tiOWusQZqEAe07ECUaCr+FS9n+ttT/t8uf5YIK+rt2tM+RKPp5X9fHkfa9vnLZ6aHrOm5xForIGes66xBPJ+BPpeBfr+h2Kf62pZ0RBPfX+OoRg3vq56Fw3Pvy6vW11+r9S26l00PMdQjXHH86/tM0fVcRNqMbM8eElJiYmPjzeLFi1y237HHXeYiy66yKdzREuiZAxXO0fgvI2dSCSu3lgpwfYm2B+wg5EoBuuikr7GE64LNfrymKGINRKx1CXJDHas4d4XbfHU9+cYqt8bDp7+r4qm51/X5xjo7wdvouk5hmqM+yKaEyWbMcYEv/sveHr37q1zzjlHTz31lHNbt27dNGLECI+LOVRVVFSkxo0b6/Dhw2rUqFEoQ61VWVmZlixZotzcXCUmJkY0FlgLYyd8KirsKxLt22dfjefCC+2rNC5aZF/O1XWlojZtpDlzpLw87/er6Zyhfh7Ll5fr7bc/1dChZ2ngwISIxxPIY4Yi1kjEEuj4CEWste0LZNzUFmconn807Yu2eMI9bhy8/V8VTc8/VL+rI/Fv1SpjvDbh/ozjT24Q9YnSwoULdeONN2revHnq06ePnnnmGf3tb3/Tpk2b1LZt21rvT6KEWMDYiQ6RSDDqgnGDQDBuECjGDgIRzYlSVK96J0nXXnutDhw4oIceekj79u1T9+7dtWTJEp+SJAAIJscFbgEAQOyL+kRJksaPH6/x48dHOgwAAAAA9URcpAMAAAAAgGhDogQAAAAAVZAoAQAAAEAVJEoAAAAAUAWJEgAAAABUQaIEAAAAAFWQKAEAAABAFSRKAAAAAFAFiRIAAAAAVEGiBAAAAABVkCgBAAAAQBUkSgAAAABQRUKkAwg1Y4wkqaioKMKRSGVlZTp+/LiKioqUmJgY6XBgIYwdBIJxg0AwbhAoxg4CEe5x48gJHDlCTWI+UTpy5IgkqU2bNhGOBAAAAEA0OHLkiBo3blzjMTbjSzplYZWVlfruu++Unp4um80W0ViKiorUpk0b7d69W40aNYpoLLAWxg4CwbhBIBg3CBRjB4EI97gxxujIkSPKzs5WXFzNs5BivqIUFxennJycSIfhplGjRvwCQUAYOwgE4waBYNwgUIwdBCKc46a2SpIDizkAAAAAQBUkSgAAAABQBYlSGCUnJ+vBBx9UcnJypEOBxTB2EAjGDQLBuEGgGDsIRDSPm5hfzAEAAAAA/EVFCQAAAACqIFECAAAAgCpIlAAAAACgChIlAAAAAKiCRCmMnnrqKbVv314pKSk655xztHr16kiHhCgyY8YMnXvuuUpPT1erVq105ZVXauvWrW7HGGOUn5+v7OxspaamasCAAdq0aVOEIkY0mjFjhmw2myZNmuTcxriBJ3v37tUNN9yg5s2bKy0tTWeddZY2bNjg3M+4gSfl5eX6/e9/r/bt2ys1NVWnnnqqHnroIVVWVjqPYexg1apVGj58uLKzs2Wz2bR48WK3/b6MkZKSEt1+++1q0aKFGjRooCuuuEJ79uwJ47MgUQqbhQsXatKkSbr//vu1ceNGXXjhhRo6dKh27doV6dAQJVauXKnbbrtN69atU0FBgcrLyzV48GAdO3bMeczMmTM1a9YszZ07V+vXr1dmZqYGDRqkI0eORDByRIv169frmWee0Zlnnum2nXGDqg4ePKh+/fopMTFRb7/9tjZv3qw///nPatKkifMYxg08+eMf/6h58+Zp7ty52rJli2bOnKnHHntMf/nLX5zHMHZw7Ngx9ejRQ3PnzvW435cxMmnSJL355pt65ZVX9MEHH+jo0aMaNmyYKioqwvU0JIOwOO+888xvfvMbt21dunQx9957b4QiQrTbv3+/kWRWrlxpjDGmsrLSZGZmmkcffdR5zIkTJ0zjxo3NvHnzIhUmosSRI0dMp06dTEFBgenfv7+ZOHGiMYZxA8/uuecec8EFF3jdz7iBN5dffrm5+eab3bbl5eWZG264wRjD2EF1ksybb77pvO3LGDl06JBJTEw0r7zyivOYvXv3mri4OLN06dKwxU5FKQxKS0u1YcMGDR482G374MGDtWbNmghFhWh3+PBhSVKzZs0kSdu3b1dhYaHbOEpOTlb//v0ZR9Btt92myy+/XJdeeqnbdsYNPPn3v/+tXr166eqrr1arVq3Us2dP/e1vf3PuZ9zAmwsuuEDvvfeetm3bJkn67LPP9MEHHyg3N1cSYwe182WMbNiwQWVlZW7HZGdnq3v37mEdRwlhe6R67Mcff1RFRYUyMjLctmdkZKiwsDBCUSGaGWM0efJkXXDBBerevbskOceKp3G0c+fOsMeI6PHKK6/ok08+0fr166vtY9zAk2+//VZPP/20Jk+erPvuu08fffSR7rjjDiUnJ+umm25i3MCre+65R4cPH1aXLl0UHx+viooKPfLIIxo1apQkfuegdr6MkcLCQiUlJalp06bVjgnnZ2cSpTCy2Wxut40x1bYBkjRhwgR9/vnn+uCDD6rtYxzB1e7duzVx4kQtW7ZMKSkpXo9j3MBVZWWlevXqpenTp0uSevbsqU2bNunpp5/WTTfd5DyOcYOqFi5cqH/84x9asGCBTj/9dH366aeaNGmSsrOzNWbMGOdxjB3UJpAxEu5xROtdGLRo0ULx8fHVMuD9+/dXy6aB22+/Xf/+97+1fPly5eTkOLdnZmZKEuMIbjZs2KD9+/frnHPOUUJCghISErRy5Uo98cQTSkhIcI4Nxg1cZWVlqVu3bm7bunbt6lxgiN838Obuu+/Wvffeq+uuu05nnHGGbrzxRt15552aMWOGJMYOaufLGMnMzFRpaakOHjzo9ZhwIFEKg6SkJJ1zzjkqKChw215QUKC+fftGKCpEG2OMJkyYoEWLFun9999X+/bt3fa3b99emZmZbuOotLRUK1euZBzVY5dccom++OILffrpp86vXr166frrr9enn36qU089lXGDavr161ft8gPbtm1T27ZtJfH7Bt4dP35ccXHuHx/j4+Ody4MzdlAbX8bIOeeco8TERLdj9u3bpy+//DK84yhsy0bUc6+88opJTEw0zz33nNm8ebOZNGmSadCggdmxY0ekQ0OU+O1vf2saN25sVqxYYfbt2+f8On78uPOYRx991DRu3NgsWrTIfPHFF2bUqFEmKyvLFBUVRTByRBvXVe+MYdyguo8++sgkJCSYRx55xHz99dfm5ZdfNmlpaeYf//iH8xjGDTwZM2aMad26tXnrrbfM9u3bzaJFi0yLFi3MlClTnMcwdnDkyBGzceNGs3HjRiPJzJo1y2zcuNHs3LnTGOPbGPnNb35jcnJyzLvvvms++eQTc/HFF5sePXqY8vLysD0PEqUwevLJJ03btm1NUlKSOfvss53LPgPG2JfP9PT1wgsvOI+prKw0Dz74oMnMzDTJycnmoosuMl988UXkgkZUqpooMW7gyf/93/+Z7t27m+TkZNOlSxfzzDPPuO1n3MCToqIiM3HiRHPKKaeYlJQUc+qpp5r777/flJSUOI9h7GD58uUeP9OMGTPGGOPbGCkuLjYTJkwwzZo1M6mpqWbYsGFm165dYX0eNmOMCV/9CgAAAACiH3OUAAAAAKAKEiUAAAAAqIJECQAAAACqIFECAAAAgCpIlAAAAACgChIlAAAAAKiCRAkAAAAAqiBRAgAAAIAqSJQAADHvxRdfVJMmTfy6T7t27TRnzpyQxAMAiH4kSgAAS7HZbDV+jR07ttp9rr32Wm3bti38wQIALCsh0gEAAOCPffv2OX9euHCh/vCHP2jr1q3ObampqW7Hl5WVKTU1tdp2AABqQkUJAGApmZmZzq/GjRvLZrM5b584cUJNmjTRq6++qgEDBiglJUX/+Mc/qrXe/e9//9OIESOUkZGhhg0b6txzz9W7774buScFAIg6JEoAgJhzzz336I477tCWLVs0ZMiQavuPHj2q3Nxcvfvuu9q4caOGDBmi4cOHa9euXRGIFgAQjWi9AwDEnEmTJikvL8/r/h49eqhHjx7O2w8//LDefPNN/fvf/9aECRPCESIAIMpRUQIAxJxevXrVuP/YsWOaMmWKunXrpiZNmqhhw4b66quvqCgBAJyoKAEAYk6DBg1q3H/33XfrnXfe0Z/+9Cd17NhRqampGjlypEpLS8MUIQAg2pEoAQDqndWrV2vs2LH6xS9+Ick+Z2nHjh2RDQoAEFVovQMA1DsdO3bUokWL9Omnn+qzzz7T6NGjVVlZGemwAABRhEQJAFDvzJ49W02bNlXfvn01fPhwDRkyRGeffXakwwIARBGbMcZEOggAAAAAiCZUlAAAAACgChIlAAAAAKiCRAkAAAAAqiBRAgAAAIAqSJQAAAAAoAoSJQAAAACogkQJAAAAAKogUQIAAACAKkiUAAAAAKAKEiUAAAAAqIJECQAAAACq+H9Xgdwv/xu3LwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:  {'num_layers': 3, 'num_neurons_layer_0': 92, 'num_neurons_layer_1': 48, 'num_neurons_layer_2': 108, 'learning_rate': 0.002118820939893383, 'activation': 'tanh'}\n",
      "Best trial loss:  0.10807193070650101\n",
      "Epoch 1/50\n",
      "43/43 [==============================] - 0s 520us/step - loss: 71.7693\n",
      "Epoch 2/50\n",
      "43/43 [==============================] - 0s 499us/step - loss: 58.2682\n",
      "Epoch 3/50\n",
      "43/43 [==============================] - 0s 528us/step - loss: 47.5584\n",
      "Epoch 4/50\n",
      "43/43 [==============================] - 0s 500us/step - loss: 37.1432\n",
      "Epoch 5/50\n",
      "43/43 [==============================] - 0s 531us/step - loss: 26.8650\n",
      "Epoch 6/50\n",
      "43/43 [==============================] - 0s 509us/step - loss: 16.6663\n",
      "Epoch 7/50\n",
      "43/43 [==============================] - 0s 519us/step - loss: 8.3043\n",
      "Epoch 8/50\n",
      "43/43 [==============================] - 0s 549us/step - loss: 4.4345\n",
      "Epoch 9/50\n",
      "43/43 [==============================] - 0s 527us/step - loss: 3.4899\n",
      "Epoch 10/50\n",
      "43/43 [==============================] - 0s 544us/step - loss: 3.4885\n",
      "Epoch 11/50\n",
      "43/43 [==============================] - 0s 540us/step - loss: 3.4870\n",
      "Epoch 12/50\n",
      "43/43 [==============================] - 0s 533us/step - loss: 3.4799\n",
      "Epoch 13/50\n",
      "43/43 [==============================] - 0s 529us/step - loss: 3.4813\n",
      "Epoch 14/50\n",
      "43/43 [==============================] - 0s 533us/step - loss: 3.4809\n",
      "Epoch 15/50\n",
      "43/43 [==============================] - 0s 539us/step - loss: 3.4843\n",
      "Epoch 16/50\n",
      "43/43 [==============================] - 0s 549us/step - loss: 3.4797\n",
      "Epoch 17/50\n",
      "43/43 [==============================] - 0s 533us/step - loss: 3.4810\n",
      "Epoch 18/50\n",
      "43/43 [==============================] - 0s 535us/step - loss: 3.4858\n",
      "Epoch 19/50\n",
      "43/43 [==============================] - 0s 527us/step - loss: 3.4835\n",
      "Epoch 20/50\n",
      "43/43 [==============================] - 0s 528us/step - loss: 3.4839\n",
      "Epoch 21/50\n",
      "43/43 [==============================] - 0s 511us/step - loss: 3.4710\n",
      "Epoch 22/50\n",
      "43/43 [==============================] - 0s 506us/step - loss: 2.9662\n",
      "Epoch 23/50\n",
      "43/43 [==============================] - 0s 518us/step - loss: 1.3065\n",
      "Epoch 24/50\n",
      "43/43 [==============================] - 0s 544us/step - loss: 0.8512\n",
      "Epoch 25/50\n",
      "43/43 [==============================] - 0s 530us/step - loss: 0.8286\n",
      "Epoch 26/50\n",
      "43/43 [==============================] - 0s 522us/step - loss: 0.7961\n",
      "Epoch 27/50\n",
      "43/43 [==============================] - 0s 534us/step - loss: 0.8451\n",
      "Epoch 28/50\n",
      "43/43 [==============================] - 0s 527us/step - loss: 0.7965\n",
      "Epoch 29/50\n",
      "43/43 [==============================] - 0s 527us/step - loss: 0.7300\n",
      "Epoch 30/50\n",
      "43/43 [==============================] - 0s 510us/step - loss: 0.7810\n",
      "Epoch 31/50\n",
      "43/43 [==============================] - 0s 538us/step - loss: 0.7211\n",
      "Epoch 32/50\n",
      "43/43 [==============================] - 0s 529us/step - loss: 0.6868\n",
      "Epoch 33/50\n",
      "43/43 [==============================] - 0s 536us/step - loss: 0.6255\n",
      "Epoch 34/50\n",
      "43/43 [==============================] - 0s 530us/step - loss: 0.6374\n",
      "Epoch 35/50\n",
      "43/43 [==============================] - 0s 507us/step - loss: 0.7215\n",
      "Epoch 36/50\n",
      "43/43 [==============================] - 0s 519us/step - loss: 0.7283\n",
      "Epoch 37/50\n",
      "43/43 [==============================] - 0s 531us/step - loss: 0.6541\n",
      "Epoch 38/50\n",
      "43/43 [==============================] - 0s 537us/step - loss: 0.6401\n",
      "Epoch 39/50\n",
      "43/43 [==============================] - 0s 536us/step - loss: 0.6458\n",
      "Epoch 40/50\n",
      "43/43 [==============================] - 0s 535us/step - loss: 0.6258\n",
      "Epoch 41/50\n",
      "43/43 [==============================] - 0s 522us/step - loss: 0.5727\n",
      "Epoch 42/50\n",
      "43/43 [==============================] - 0s 534us/step - loss: 0.5059\n",
      "Epoch 43/50\n",
      "43/43 [==============================] - 0s 511us/step - loss: 0.4980\n",
      "Epoch 44/50\n",
      "43/43 [==============================] - 0s 533us/step - loss: 0.5780\n",
      "Epoch 45/50\n",
      "43/43 [==============================] - 0s 535us/step - loss: 0.4499\n",
      "Epoch 46/50\n",
      "43/43 [==============================] - 0s 533us/step - loss: 0.5164\n",
      "Epoch 47/50\n",
      "43/43 [==============================] - 0s 534us/step - loss: 0.4696\n",
      "Epoch 48/50\n",
      "43/43 [==============================] - 0s 520us/step - loss: 0.4324\n",
      "Epoch 49/50\n",
      "43/43 [==============================] - 0s 521us/step - loss: 0.4175\n",
      "Epoch 50/50\n",
      "43/43 [==============================] - 0s 521us/step - loss: 0.4376\n",
      "Epoch 1/50\n",
      "43/43 [==============================] - 0s 469us/step - loss: 62.5163\n",
      "Epoch 2/50\n",
      "43/43 [==============================] - 0s 447us/step - loss: 49.2987\n",
      "Epoch 3/50\n",
      "43/43 [==============================] - 0s 498us/step - loss: 38.5189\n",
      "Epoch 4/50\n",
      "43/43 [==============================] - 0s 490us/step - loss: 28.0634\n",
      "Epoch 5/50\n",
      "43/43 [==============================] - 0s 490us/step - loss: 17.7579\n",
      "Epoch 6/50\n",
      "43/43 [==============================] - 0s 483us/step - loss: 7.5385\n",
      "Epoch 7/50\n",
      "43/43 [==============================] - 0s 482us/step - loss: 0.5394\n",
      "Epoch 8/50\n",
      "43/43 [==============================] - 0s 454us/step - loss: 0.1165\n",
      "Epoch 9/50\n",
      "43/43 [==============================] - 0s 448us/step - loss: 0.1059\n",
      "Epoch 10/50\n",
      "43/43 [==============================] - 0s 433us/step - loss: 0.1071\n",
      "Epoch 11/50\n",
      "43/43 [==============================] - 0s 470us/step - loss: 0.1083\n",
      "Epoch 12/50\n",
      "43/43 [==============================] - 0s 543us/step - loss: 0.1045\n",
      "Epoch 13/50\n",
      "43/43 [==============================] - 0s 480us/step - loss: 0.1124\n",
      "Epoch 14/50\n",
      "43/43 [==============================] - 0s 455us/step - loss: 0.1074\n",
      "Epoch 15/50\n",
      "43/43 [==============================] - 0s 527us/step - loss: 0.1074\n",
      "Epoch 16/50\n",
      "43/43 [==============================] - 0s 521us/step - loss: 0.1064\n",
      "Epoch 17/50\n",
      "43/43 [==============================] - 0s 526us/step - loss: 0.1052\n",
      "Epoch 18/50\n",
      "43/43 [==============================] - 0s 509us/step - loss: 0.1056\n",
      "Epoch 19/50\n",
      "43/43 [==============================] - 0s 537us/step - loss: 0.1121\n",
      "Epoch 20/50\n",
      "43/43 [==============================] - 0s 525us/step - loss: 0.1050\n",
      "Epoch 21/50\n",
      "43/43 [==============================] - 0s 523us/step - loss: 0.1057\n",
      "Epoch 22/50\n",
      "43/43 [==============================] - 0s 522us/step - loss: 0.1076\n",
      "Epoch 23/50\n",
      "43/43 [==============================] - 0s 539us/step - loss: 0.1063\n",
      "Epoch 24/50\n",
      "43/43 [==============================] - 0s 542us/step - loss: 0.1061\n",
      "Epoch 25/50\n",
      "43/43 [==============================] - 0s 490us/step - loss: 0.1086\n",
      "Epoch 26/50\n",
      "43/43 [==============================] - 0s 521us/step - loss: 0.1067\n",
      "Epoch 27/50\n",
      "43/43 [==============================] - 0s 532us/step - loss: 0.1065\n",
      "Epoch 28/50\n",
      "43/43 [==============================] - 0s 516us/step - loss: 0.1091\n",
      "Epoch 29/50\n",
      "43/43 [==============================] - 0s 515us/step - loss: 0.1069\n",
      "Epoch 30/50\n",
      "43/43 [==============================] - 0s 525us/step - loss: 0.1099\n",
      "Epoch 31/50\n",
      "43/43 [==============================] - 0s 553us/step - loss: 0.1050\n",
      "Epoch 32/50\n",
      "43/43 [==============================] - 0s 515us/step - loss: 0.1059\n",
      "Epoch 33/50\n",
      "43/43 [==============================] - 0s 525us/step - loss: 0.1062\n",
      "Epoch 34/50\n",
      "43/43 [==============================] - 0s 507us/step - loss: 0.1069\n",
      "Epoch 35/50\n",
      "43/43 [==============================] - 0s 527us/step - loss: 0.1087\n",
      "Epoch 36/50\n",
      "43/43 [==============================] - 0s 521us/step - loss: 0.1057\n",
      "Epoch 37/50\n",
      "43/43 [==============================] - 0s 524us/step - loss: 0.1051\n",
      "Epoch 38/50\n",
      "43/43 [==============================] - 0s 546us/step - loss: 0.1116\n",
      "Epoch 39/50\n",
      "43/43 [==============================] - 0s 535us/step - loss: 0.1088\n",
      "Epoch 40/50\n",
      "43/43 [==============================] - 0s 507us/step - loss: 0.1066\n",
      "Epoch 41/50\n",
      "43/43 [==============================] - 0s 534us/step - loss: 0.1089\n",
      "Epoch 42/50\n",
      "43/43 [==============================] - 0s 552us/step - loss: 0.1091\n",
      "Epoch 43/50\n",
      "43/43 [==============================] - 0s 526us/step - loss: 0.1067\n",
      "Epoch 44/50\n",
      "43/43 [==============================] - 0s 529us/step - loss: 0.1078\n",
      "Epoch 45/50\n",
      "43/43 [==============================] - 0s 526us/step - loss: 0.1116\n",
      "Epoch 46/50\n",
      "43/43 [==============================] - 0s 550us/step - loss: 0.1118\n",
      "Epoch 47/50\n",
      "43/43 [==============================] - 0s 509us/step - loss: 0.1077\n",
      "Epoch 48/50\n",
      "43/43 [==============================] - 0s 505us/step - loss: 0.1052\n",
      "Epoch 49/50\n",
      "43/43 [==============================] - 0s 549us/step - loss: 0.1092\n",
      "Epoch 50/50\n",
      "43/43 [==============================] - 0s 550us/step - loss: 0.1077\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x330db6950>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:  {'num_layers': 2, 'num_neurons_layer_0': 60, 'num_neurons_layer_1': 108, 'learning_rate': 0.0024793077544138947, 'activation': 'tanh'}\n",
      "Best trial loss:  0.12486603856086731\n",
      "Epoch 1/50\n",
      "43/43 [==============================] - 0s 953us/step - loss: 71.1171\n",
      "Epoch 2/50\n",
      "43/43 [==============================] - 0s 976us/step - loss: 57.0624\n",
      "Epoch 3/50\n",
      "43/43 [==============================] - 0s 952us/step - loss: 44.8791\n",
      "Epoch 4/50\n",
      "43/43 [==============================] - 0s 929us/step - loss: 32.9002\n",
      "Epoch 5/50\n",
      "43/43 [==============================] - 0s 929us/step - loss: 21.0197\n",
      "Epoch 6/50\n",
      "43/43 [==============================] - 0s 952us/step - loss: 10.1189\n",
      "Epoch 7/50\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 4.7194\n",
      "Epoch 8/50\n",
      "43/43 [==============================] - 0s 976us/step - loss: 3.4884\n",
      "Epoch 9/50\n",
      "43/43 [==============================] - 0s 949us/step - loss: 3.4814\n",
      "Epoch 10/50\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 3.4802\n",
      "Epoch 11/50\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 3.4793\n",
      "Epoch 12/50\n",
      "43/43 [==============================] - 0s 976us/step - loss: 3.4825\n",
      "Epoch 13/50\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 3.4793\n",
      "Epoch 14/50\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 3.4802\n",
      "Epoch 15/50\n",
      "43/43 [==============================] - 0s 952us/step - loss: 3.4870\n",
      "Epoch 16/50\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 3.0289\n",
      "Epoch 17/50\n",
      "43/43 [==============================] - 0s 1000us/step - loss: 1.1649\n",
      "Epoch 18/50\n",
      "43/43 [==============================] - 0s 955us/step - loss: 0.9423\n",
      "Epoch 19/50\n",
      "43/43 [==============================] - 0s 976us/step - loss: 0.7754\n",
      "Epoch 20/50\n",
      "43/43 [==============================] - 0s 976us/step - loss: 0.7298\n",
      "Epoch 21/50\n",
      "43/43 [==============================] - 0s 929us/step - loss: 0.7396\n",
      "Epoch 22/50\n",
      "43/43 [==============================] - 0s 953us/step - loss: 0.7069\n",
      "Epoch 23/50\n",
      "43/43 [==============================] - 0s 952us/step - loss: 0.7003\n",
      "Epoch 24/50\n",
      "43/43 [==============================] - 0s 952us/step - loss: 0.6827\n",
      "Epoch 25/50\n",
      "43/43 [==============================] - 0s 952us/step - loss: 0.6551\n",
      "Epoch 26/50\n",
      "43/43 [==============================] - 0s 1000us/step - loss: 0.6626\n",
      "Epoch 27/50\n",
      "43/43 [==============================] - 0s 976us/step - loss: 0.6960\n",
      "Epoch 28/50\n",
      "43/43 [==============================] - 0s 929us/step - loss: 0.6525\n",
      "Epoch 29/50\n",
      "43/43 [==============================] - 0s 976us/step - loss: 0.5959\n",
      "Epoch 30/50\n",
      "43/43 [==============================] - 0s 952us/step - loss: 0.6037\n",
      "Epoch 31/50\n",
      "43/43 [==============================] - 0s 905us/step - loss: 0.5967\n",
      "Epoch 32/50\n",
      "43/43 [==============================] - 0s 952us/step - loss: 0.5979\n",
      "Epoch 33/50\n",
      "43/43 [==============================] - 0s 905us/step - loss: 0.5933\n",
      "Epoch 34/50\n",
      "43/43 [==============================] - 0s 905us/step - loss: 0.5827\n",
      "Epoch 35/50\n",
      "43/43 [==============================] - 0s 905us/step - loss: 0.5981\n",
      "Epoch 36/50\n",
      "43/43 [==============================] - 0s 905us/step - loss: 0.5874\n",
      "Epoch 37/50\n",
      "43/43 [==============================] - 0s 881us/step - loss: 0.5596\n",
      "Epoch 38/50\n",
      "43/43 [==============================] - 0s 881us/step - loss: 0.5633\n",
      "Epoch 39/50\n",
      "43/43 [==============================] - 0s 881us/step - loss: 0.5865\n",
      "Epoch 40/50\n",
      "43/43 [==============================] - 0s 881us/step - loss: 0.5524\n",
      "Epoch 41/50\n",
      "43/43 [==============================] - 0s 881us/step - loss: 0.5508\n",
      "Epoch 42/50\n",
      "43/43 [==============================] - 0s 905us/step - loss: 0.5363\n",
      "Epoch 43/50\n",
      "43/43 [==============================] - 0s 881us/step - loss: 0.5349\n",
      "Epoch 44/50\n",
      "43/43 [==============================] - 0s 881us/step - loss: 0.5227\n",
      "Epoch 45/50\n",
      "43/43 [==============================] - 0s 905us/step - loss: 0.5340\n",
      "Epoch 46/50\n",
      "43/43 [==============================] - 0s 881us/step - loss: 0.5319\n",
      "Epoch 47/50\n",
      "43/43 [==============================] - 0s 881us/step - loss: 0.5093\n",
      "Epoch 48/50\n",
      "43/43 [==============================] - 0s 881us/step - loss: 0.5401\n",
      "Epoch 49/50\n",
      "43/43 [==============================] - 0s 858us/step - loss: 0.4979\n",
      "Epoch 50/50\n",
      "43/43 [==============================] - 0s 881us/step - loss: 0.5009\n",
      "Epoch 1/50\n",
      "43/43 [==============================] - 0s 809us/step - loss: 59.1841\n",
      "Epoch 2/50\n",
      "43/43 [==============================] - 0s 857us/step - loss: 45.1652\n",
      "Epoch 3/50\n",
      "43/43 [==============================] - 0s 857us/step - loss: 32.9677\n",
      "Epoch 4/50\n",
      "43/43 [==============================] - 0s 905us/step - loss: 20.9799\n",
      "Epoch 5/50\n",
      "43/43 [==============================] - 0s 905us/step - loss: 9.0935\n",
      "Epoch 6/50\n",
      "43/43 [==============================] - 0s 905us/step - loss: 0.7015\n",
      "Epoch 7/50\n",
      "43/43 [==============================] - 0s 881us/step - loss: 0.1181\n",
      "Epoch 8/50\n",
      "43/43 [==============================] - 0s 906us/step - loss: 0.1093\n",
      "Epoch 9/50\n",
      "43/43 [==============================] - 0s 905us/step - loss: 0.1096\n",
      "Epoch 10/50\n",
      "43/43 [==============================] - 0s 905us/step - loss: 0.1054\n",
      "Epoch 11/50\n",
      "43/43 [==============================] - 0s 952us/step - loss: 0.1054\n",
      "Epoch 12/50\n",
      "43/43 [==============================] - 0s 929us/step - loss: 0.1068\n",
      "Epoch 13/50\n",
      "43/43 [==============================] - 0s 929us/step - loss: 0.1067\n",
      "Epoch 14/50\n",
      "43/43 [==============================] - 0s 905us/step - loss: 0.1058\n",
      "Epoch 15/50\n",
      "43/43 [==============================] - 0s 881us/step - loss: 0.1067\n",
      "Epoch 16/50\n",
      "43/43 [==============================] - 0s 881us/step - loss: 0.1065\n",
      "Epoch 17/50\n",
      "43/43 [==============================] - 0s 898us/step - loss: 0.1093\n",
      "Epoch 18/50\n",
      "43/43 [==============================] - 0s 857us/step - loss: 0.1172\n",
      "Epoch 19/50\n",
      "43/43 [==============================] - 0s 857us/step - loss: 0.1086\n",
      "Epoch 20/50\n",
      "43/43 [==============================] - 0s 879us/step - loss: 0.1064\n",
      "Epoch 21/50\n",
      "43/43 [==============================] - 0s 905us/step - loss: 0.1058\n",
      "Epoch 22/50\n",
      "43/43 [==============================] - 0s 905us/step - loss: 0.1128\n",
      "Epoch 23/50\n",
      "43/43 [==============================] - 0s 881us/step - loss: 0.1059\n",
      "Epoch 24/50\n",
      "43/43 [==============================] - 0s 857us/step - loss: 0.1061\n",
      "Epoch 25/50\n",
      "43/43 [==============================] - 0s 833us/step - loss: 0.1152\n",
      "Epoch 26/50\n",
      "43/43 [==============================] - 0s 833us/step - loss: 0.1179\n",
      "Epoch 27/50\n",
      "43/43 [==============================] - 0s 857us/step - loss: 0.1081\n",
      "Epoch 28/50\n",
      "43/43 [==============================] - 0s 859us/step - loss: 0.1104\n",
      "Epoch 29/50\n",
      "43/43 [==============================] - 0s 833us/step - loss: 0.1080\n",
      "Epoch 30/50\n",
      "43/43 [==============================] - 0s 857us/step - loss: 0.1068\n",
      "Epoch 31/50\n",
      "43/43 [==============================] - 0s 857us/step - loss: 0.1091\n",
      "Epoch 32/50\n",
      "43/43 [==============================] - 0s 762us/step - loss: 0.1073\n",
      "Epoch 33/50\n",
      "43/43 [==============================] - 0s 762us/step - loss: 0.1086\n",
      "Epoch 34/50\n",
      "43/43 [==============================] - 0s 810us/step - loss: 0.1121\n",
      "Epoch 35/50\n",
      "43/43 [==============================] - 0s 690us/step - loss: 0.1100\n",
      "Epoch 36/50\n",
      "43/43 [==============================] - 0s 786us/step - loss: 0.1065\n",
      "Epoch 37/50\n",
      "43/43 [==============================] - 0s 833us/step - loss: 0.1136\n",
      "Epoch 38/50\n",
      "43/43 [==============================] - 0s 833us/step - loss: 0.1087\n",
      "Epoch 39/50\n",
      "43/43 [==============================] - 0s 833us/step - loss: 0.1064\n",
      "Epoch 40/50\n",
      "43/43 [==============================] - 0s 833us/step - loss: 0.1087\n",
      "Epoch 41/50\n",
      "43/43 [==============================] - 0s 834us/step - loss: 0.1092\n",
      "Epoch 42/50\n",
      "43/43 [==============================] - 0s 833us/step - loss: 0.1074\n",
      "Epoch 43/50\n",
      "43/43 [==============================] - 0s 881us/step - loss: 0.1055\n",
      "Epoch 44/50\n",
      "43/43 [==============================] - 0s 881us/step - loss: 0.1056\n",
      "Epoch 45/50\n",
      "43/43 [==============================] - 0s 881us/step - loss: 0.1189\n",
      "Epoch 46/50\n",
      "43/43 [==============================] - 0s 857us/step - loss: 0.1045\n",
      "Epoch 47/50\n",
      "43/43 [==============================] - 0s 857us/step - loss: 0.1104\n",
      "Epoch 48/50\n",
      "43/43 [==============================] - 0s 905us/step - loss: 0.1052\n",
      "Epoch 49/50\n",
      "43/43 [==============================] - 0s 929us/step - loss: 0.1039\n",
      "Epoch 50/50\n",
      "43/43 [==============================] - 0s 905us/step - loss: 0.1077\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2746c8111c0>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import optuna\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "trial_losses = []\n",
    "\n",
    "# Function to create a model with the given hyperparameters\n",
    "# Function to create a model with a specific number of neurons in each layer\n",
    "def create_model(input_shape, neurons_per_layer, activation, learning_rate):\n",
    "    model = tf.keras.Sequential()\n",
    "    \n",
    "    # Add the first layer with input shape\n",
    "    model.add(layers.Dense(neurons_per_layer[0], activation=activation, input_shape=(input_shape,)))\n",
    "    \n",
    "    # Add subsequent layers with specified number of neurons\n",
    "    for neurons in neurons_per_layer[1:]:\n",
    "        model.add(layers.Dense(neurons, activation=activation))\n",
    "    \n",
    "    model.add(layers.Dense(1))  # Output layer\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate),\n",
    "                  loss='mean_absolute_error')\n",
    "    return model\n",
    "\n",
    "# Objective function to optimize both entrance and exit models\n",
    "def objective(trial):\n",
    "    # Suggest number of layers\n",
    "    num_layers = trial.suggest_int('num_layers', 1, 5)\n",
    "    \n",
    "    # Suggest a different number of neurons for each layer\n",
    "    neurons_per_layer = []\n",
    "    for i in range(num_layers):\n",
    "        neurons = trial.suggest_int(f'num_neurons_layer_{i}', 16, 128, step=4)  # Each layer can have 16 to 128 neurons\n",
    "        neurons_per_layer.append(neurons)\n",
    "    \n",
    "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
    "    activation = trial.suggest_categorical('activation', ['relu', 'tanh'])\n",
    "\n",
    "    # Create models for both entrance and exit\n",
    "    model_entrance = create_model(train_features_entrance.shape[1], neurons_per_layer, activation, learning_rate)\n",
    "    model_exit = create_model(train_features_exit.shape[1], neurons_per_layer, activation, learning_rate)\n",
    "\n",
    "    # Split data into training and validation for both entrance and exit\n",
    "    x_train_entrance, x_val_entrance, y_train_entrance, y_val_entrance = train_test_split(train_features_entrance, train_labels_entrance, test_size=0.2, random_state=42)\n",
    "    x_train_exit, x_val_exit, y_train_exit, y_val_exit = train_test_split(train_features_exit, train_labels_exit, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Train both models\n",
    "    model_entrance.fit(x_train_entrance, y_train_entrance, validation_data=(x_val_entrance, y_val_entrance), \n",
    "                       epochs=100, batch_size=32, verbose=0)\n",
    "    model_exit.fit(x_train_exit, y_train_exit, validation_data=(x_val_exit, y_val_exit), \n",
    "                   epochs=100, batch_size=32, verbose=0)\n",
    "\n",
    "    # Evaluate both models on validation data\n",
    "    val_loss_entrance = model_entrance.evaluate(x_val_entrance, y_val_entrance, verbose=0)\n",
    "    val_loss_exit = model_exit.evaluate(x_val_exit, y_val_exit, verbose=0)\n",
    "\n",
    "    # Combine the two objectives by returning a weighted sum\n",
    "    combined_loss = 0.5 * val_loss_entrance + 0.5 * val_loss_exit\n",
    "    trial_losses.append(combined_loss)  # Append the loss to the list\n",
    "    \n",
    "    return combined_loss\n",
    "\n",
    "# Create a study and optimize both models simultaneously\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "# Plot the losses\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(trial_losses, label='Loss per Trial', marker='o', color='blue')\n",
    "plt.title('Optimization Progress: Loss per Trial')\n",
    "plt.xlabel('Trial')\n",
    "plt.ylabel('Objective Value (Loss)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Print best hyperparameters\n",
    "print(\"Best hyperparameters: \", study.best_params)\n",
    "print(\"Best trial loss: \", study.best_value)\n",
    "\n",
    "# Build the final optimized models\n",
    "def build_best_model(best_params, input_shape):\n",
    "    num_layers = best_params['num_layers']\n",
    "    \n",
    "    # Reconstruct neurons per layer using the best parameters\n",
    "    neurons_per_layer = [best_params[f'num_neurons_layer_{i}'] for i in range(num_layers)]\n",
    "    activation = best_params['activation']\n",
    "    learning_rate = best_params['learning_rate']\n",
    "\n",
    "    model = create_model(input_shape, neurons_per_layer, activation, learning_rate)\n",
    "    return model\n",
    "\n",
    "# Create the final models using the best hyperparameters\n",
    "final_model_entrance = build_best_model(study.best_params, train_features_entrance.shape[1])\n",
    "final_model_exit = build_best_model(study.best_params, train_features_exit.shape[1])\n",
    "\n",
    "\n",
    "# Train the final models on the full datasets\n",
    "final_model_entrance.fit(train_features_entrance, train_labels_entrance, epochs=50, batch_size=32, verbose=1)\n",
    "final_model_exit.fit(train_features_exit, train_labels_exit, epochs=50, batch_size=32, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "493bd07f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 424us/step - loss: 0.4381\n",
      "Test set loss for entrance: 0.4381049573421478\n",
      "11/11 [==============================] - 0s 436us/step - loss: 0.1198\n",
      "Test set loss for exit: 0.11984791606664658\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2366\n",
      "v2. Test set loss for entrance: 0.23655955493450165\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1074\n",
      "v2. Test set loss for exit: 0.1074269637465477\n",
      "Test features Entrance: [[26.62   6.465 40.253  3.837]\n",
      " [22.35   5.745 40.173  4.886]\n",
      " [12.46   4.021 40.352  3.497]\n",
      " ...\n",
      " [14.32   4.371 39.764  3.757]\n",
      " [20.51   6.468 45.508  5.585]\n",
      " [26.62   6.456 40.173  3.851]]\n",
      "\n",
      "v2. Test features Entrance: [[29.08  6.44 38.33  5.46]\n",
      " [ 7.    2.42 38.36  2.1 ]\n",
      " [ 7.64  2.76 38.77  2.32]]\n",
      "\n",
      "Test result Entrance: {'dnn_model': 0.4381049573421478}\n",
      "\n",
      "v2. Test result Entrance: {'dnn_model': 0.23655955493450165}\n",
      "\n",
      "Test features Exit: [[38.64   8.33  41.75   7.113]\n",
      " [38.19   8.285 41.957  7.091]\n",
      " [38.61   8.352 42.049  7.109]\n",
      " ...\n",
      " [38.55   8.878 42.148  7.514]\n",
      " [38.16   8.24  42.088  6.95 ]\n",
      " [38.64   8.292 41.691  7.14 ]]\n",
      "\n",
      "v2. Test features Exit: [[38.8   8.45 42.5   7.19]\n",
      " [38.43  8.36 42.28  7.11]\n",
      " [38.07  8.3  42.19  7.06]]\n",
      "Test result Exit: {'dnn_model': 0.11984791606664658}\n",
      "\n",
      "v2. Test result Exit: {'dnn_model': 0.1074269637465477}\n",
      "\n",
      "11/11 [==============================] - 0s 320us/step\n",
      "Test Predictions Entrance: [78.698 80.883 88.939 87.743 78.707 90.647 87.466 87.491 88.925 88.967\n",
      " 80.799 87.485 87.427 87.411 75.563 87.427 87.424 87.49  80.834 87.76\n",
      " 88.987 90.769 89.678 87.413 88.981 90.758 87.487 87.403 88.976 88.756\n",
      " 78.646 74.442 87.432 88.798 78.677 90.772 90.647 88.93  78.682 90.751\n",
      " 90.634 87.511 87.408 80.84  88.779 87.486 88.774 90.981 89.435 87.386\n",
      " 87.431 75.541 87.757 90.982 74.457 78.708 90.763 80.87  87.422 87.485\n",
      " 87.425 87.486 87.43  75.607 89.527 90.646 87.426 87.485 88.917 87.763\n",
      " 87.425 87.745 74.45  87.418 80.844 90.981 74.449 87.43  78.685 90.749\n",
      " 87.253 87.435 88.958 90.746 89.326 88.923 90.652 87.415 75.645 87.746\n",
      " 87.487 80.867 87.742 90.783 88.77  87.413 90.978 75.535 90.662 87.406\n",
      " 74.449 87.403 90.688 88.792 87.282 74.44  87.432 88.91  78.674 90.974\n",
      " 90.651 87.619 87.419 80.835 90.777 87.54  87.433 87.412 75.576 78.699\n",
      " 90.974 87.368 75.587 78.67  87.201 87.413 87.74  88.808 87.525 90.755\n",
      " 74.443 88.812 90.982 87.41  87.47  74.453 87.41  87.775 90.74  74.432\n",
      " 75.525 90.754 87.356 87.433 87.416 87.736 87.421 87.488 88.92  87.744\n",
      " 90.696 74.436 87.486 75.569 88.969 90.985 90.735 89.472 74.46  88.963\n",
      " 90.646 87.429 87.407 75.543 88.929 87.745 88.788 90.756 74.45  75.567\n",
      " 87.486 88.81  90.984 87.481 74.447 88.98  88.777 90.639 87.428 75.57\n",
      " 88.979 90.637 87.428 87.486 87.417 75.559 88.808 88.94  87.747 88.963\n",
      " 87.315 87.42  88.927 88.725 90.755 89.468 74.442 87.485 87.41  90.981\n",
      " 90.662 87.434 87.407 88.931 88.976 87.424 87.41  74.446 87.486 90.784\n",
      " 90.663 74.462 87.439 80.829 87.491 80.859 78.7   90.982 90.756 89.281\n",
      " 74.452 80.839 78.721 89.359 80.869 87.265 87.427 87.489 80.827 88.926\n",
      " 90.984 89.436 90.98  87.525 87.487 87.412 90.757 89.361 87.393 80.877\n",
      " 78.676 90.635 87.277 87.433 87.758 78.683 89.515 87.313 74.449 87.418\n",
      " 87.74  88.984 90.979 89.415 74.435 88.98  88.777 78.755 89.428 87.431\n",
      " 88.973 89.412 87.421 75.543 90.981 87.434 87.403 88.91  87.435 75.592\n",
      " 90.981 87.486 87.435 88.926 88.98  75.552 88.902 78.646 90.756 87.417\n",
      " 80.874 90.671 87.428 80.876 78.722 90.756 80.865 88.929 88.967 90.661\n",
      " 87.422 80.841 88.936 74.441 88.784 90.675 74.456 87.412 88.93  88.794\n",
      " 89.51  87.411 80.874 88.984 89.537 74.45  89.479 87.362 87.488 90.755\n",
      " 80.852 87.756 87.467 87.412 75.572 80.855 88.929 87.427 87.407 88.833\n",
      " 89.431 87.341 87.433 87.747 75.599 87.43  88.934 88.983 88.82  90.979\n",
      " 78.654 90.981 87.408 75.518 88.918 78.702 75.548 87.743 87.42  78.656]\n",
      "\n",
      "11/11 [==============================] - 0s 318us/step\n",
      "Test Predictions Exit: [75.003 75.003 75.003 75.003 75.003 75.002 75.003 75.003 75.003 75.003\n",
      " 75.003 75.003 75.003 75.003 75.003 75.003 75.002 75.003 75.003 75.003\n",
      " 75.003 75.003 75.003 75.003 75.003 75.003 75.003 75.003 75.003 75.003\n",
      " 75.003 75.003 74.997 75.003 75.003 75.003 75.002 75.003 75.003 75.003\n",
      " 75.002 75.003 75.003 75.003 75.003 75.003 75.003 75.003 75.003 75.003\n",
      " 74.997 75.003 75.003 75.003 75.003 75.003 75.003 75.003 75.003 75.003\n",
      " 75.003 75.003 74.997 75.003 75.003 75.002 75.003 75.003 75.003 75.003\n",
      " 75.003 75.003 75.003 75.003 75.003 75.003 75.003 75.003 75.003 75.003\n",
      " 75.003 74.997 75.003 75.003 75.003 75.003 75.002 75.003 75.003 75.003\n",
      " 75.003 75.003 75.003 75.003 75.003 75.003 75.003 75.003 75.002 75.003\n",
      " 75.003 75.003 75.003 75.003 75.003 75.003 74.997 75.003 75.003 75.003\n",
      " 75.002 75.003 75.002 75.003 75.003 75.003 74.997 75.003 75.003 75.003\n",
      " 75.003 75.003 75.003 75.003 75.003 75.003 75.003 75.003 75.003 75.003\n",
      " 75.003 75.003 75.003 75.003 75.003 75.003 75.003 75.003 75.003 75.003\n",
      " 75.003 75.003 75.003 74.997 75.003 75.003 75.003 75.003 75.003 75.003\n",
      " 75.002 75.003 75.003 75.003 75.003 75.003 75.003 75.003 75.003 75.003\n",
      " 75.002 74.997 75.003 75.003 75.003 75.003 75.003 75.003 75.003 75.003\n",
      " 75.003 75.003 75.003 75.003 75.003 75.003 75.003 75.003 75.002 75.003\n",
      " 75.003 75.003 75.002 75.003 75.003 75.003 75.003 75.003 75.003 75.003\n",
      " 75.003 75.003 75.003 75.003 75.003 75.003 75.003 75.003 75.003 75.003\n",
      " 75.003 74.997 75.003 75.003 75.003 75.003 75.003 75.003 75.003 75.003\n",
      " 75.003 75.003 74.997 75.003 75.003 75.003 75.003 75.003 75.003 75.003\n",
      " 75.003 75.003 75.003 75.003 75.003 75.003 75.003 75.003 75.003 75.003\n",
      " 75.003 75.003 75.003 75.003 75.003 75.003 75.003 75.003 75.003 75.003\n",
      " 75.003 75.003 75.003 74.997 75.003 75.003 75.003 75.003 75.003 75.002\n",
      " 75.003 75.003 75.003 75.003 75.003 75.003 75.003 75.003 75.003 74.997\n",
      " 75.003 75.003 75.003 75.003 75.003 74.997 75.003 75.003 74.997 75.003\n",
      " 75.003 75.003 74.997 75.003 75.003 75.003 75.003 75.003 75.003 75.003\n",
      " 75.003 75.002 75.003 75.003 75.003 75.003 75.003 75.003 75.003 75.002\n",
      " 75.003 75.003 75.003 75.003 75.003 75.002 75.003 75.003 75.003 75.003\n",
      " 75.003 75.003 75.003 75.003 75.003 75.003 75.003 75.003 75.003 75.003\n",
      " 75.003 75.003 75.003 75.003 75.003 75.003 75.003 74.997 75.003 75.003\n",
      " 75.003 75.003 74.997 75.003 75.003 74.997 75.003 75.003 75.003 75.003\n",
      " 75.003 75.003 75.003 75.003 75.003 75.003 75.003 75.003 75.002 75.003]\n",
      "\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "v2. Test Predictions Entrance: [75.567 90.98  90.667]\n",
      "\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "v2. Test Predictions Exit: [75.003 75.003 75.002]\n",
      "\n",
      "Error entrance: 11      0.127670\n",
      "23      0.103087\n",
      "24      1.179171\n",
      "25      2.083172\n",
      "28      0.137275\n",
      "          ...   \n",
      "1660    0.132278\n",
      "1671    0.007539\n",
      "1674    2.083156\n",
      "1684    0.020006\n",
      "1694    0.085586\n",
      "Name: Temperature (Â°F), Length: 340, dtype: float64\n",
      "\n",
      "Error exit: 11      0.127670\n",
      "23      0.103087\n",
      "24      1.179171\n",
      "25      2.083172\n",
      "28      0.137275\n",
      "          ...   \n",
      "1660    0.132278\n",
      "1671    0.007539\n",
      "1674    2.083156\n",
      "1684    0.020006\n",
      "1694    0.085586\n",
      "Name: Temperature (Â°F), Length: 340, dtype: float64\n",
      "\n",
      "v2. Error entrance: 5     0.027253\n",
      "12    0.209515\n",
      "15    0.472939\n",
      "Name: Temperature (°F), dtype: float64\n",
      "\n",
      "v2. Error exit: 5     0.027253\n",
      "12    0.209515\n",
      "15    0.472939\n",
      "Name: Temperature (°F), dtype: float64\n",
      "\n",
      "Average error for entrance: 0.26865339301614216\n",
      "\n",
      "Average error for exit: -0.008697843484317418\n",
      "\n",
      "v2. Average error for entrance: 0.23656899007161294\n",
      "\n",
      "v2. Average error for exit: 0.23656899007161294\n",
      "\n",
      "Mean Squared Error for entrance: 0.46209803627215734\n",
      "Mean Squared Error for exit: 0.02553924950443735\n",
      "\n",
      "v2. Mean Squared Error for entrance: 0.08943679678923226\n",
      "v2. Mean Squared Error for exit: 0.012408992100509449\n",
      "\n",
      "Mean Absolute Error for entrance: 0.43810329571892287\n",
      "Mean Absolute Error for exit: 0.11984812352797408\n",
      "\n",
      "v2. Mean Absolute Error for entrance: 0.23656899007161294\n",
      "v2. Mean Absolute Error for exit: 0.10743652343749943\n",
      "\n",
      "MAPE for entrance: 0.51%\n",
      "MAPE for exit: 0.16%\n",
      "v2. MAPE for entrance: 0.26%\n",
      "v2. MAPE for exit: 0.14%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Optionally, evaluate on a test set (if you have one)\n",
    "test_loss_entrance = final_model_entrance.evaluate(test_features_entrance, test_labels_entrance, verbose=1)\n",
    "print(f\"Test set loss for entrance: {test_loss_entrance}\")\n",
    "test_loss_exit = final_model_exit.evaluate(test_features_exit, test_labels_exit, verbose=1)\n",
    "print(f\"Test set loss for exit: {test_loss_exit}\")\n",
    "\n",
    "ori_test_loss_entrance = final_model_entrance.evaluate(ori_test_features_entrance, ori_test_labels_entrance, verbose=1)\n",
    "print(f\"v2. Test set loss for entrance: {ori_test_loss_entrance}\")\n",
    "ori_test_loss_exit = final_model_exit.evaluate(ori_test_features_exit, ori_test_labels_exit, verbose=1)\n",
    "print(f\"v2. Test set loss for exit: {ori_test_loss_exit}\")\n",
    "\n",
    "#----------------------\n",
    "test_features_entrance = np.asarray(test_features_entrance).astype(np.float32)\n",
    "print(\"Test features Entrance:\", test_features_entrance)\n",
    "print()\n",
    "\n",
    "ori_test_features_entrance = np.asarray(ori_test_features_entrance).astype(np.float32)\n",
    "print(\"v2. Test features Entrance:\", ori_test_features_entrance)\n",
    "print()\n",
    "\n",
    "#----------------------\n",
    "test_results_entrance = {}\n",
    "test_results_entrance['dnn_model'] = final_model_entrance.evaluate(test_features_entrance, test_labels_entrance, verbose=0)\n",
    "print(\"Test result Entrance:\", test_results_entrance)\n",
    "print()\n",
    "\n",
    "ori_test_results_entrance = {}\n",
    "ori_test_results_entrance['dnn_model'] = final_model_entrance.evaluate(ori_test_features_entrance, ori_test_labels_entrance, verbose=0)\n",
    "print(\"v2. Test result Entrance:\", ori_test_results_entrance)\n",
    "print()\n",
    "\n",
    "#----------------------\n",
    "test_features_exit = np.asarray(test_features_exit).astype(np.float32)\n",
    "print(\"Test features Exit:\", test_features_exit)\n",
    "print()\n",
    "\n",
    "ori_test_features_exit = np.asarray(ori_test_features_exit).astype(np.float32)\n",
    "print(\"v2. Test features Exit:\", ori_test_features_exit)\n",
    "\n",
    "#----------------------\n",
    "test_results_exit = {}\n",
    "test_results_exit['dnn_model'] = final_model_exit.evaluate(test_features_exit, test_labels_exit, verbose=0)\n",
    "print(\"Test result Exit:\", test_results_exit)\n",
    "print()\n",
    "\n",
    "ori_test_results_exit = {}\n",
    "ori_test_results_exit['dnn_model'] = final_model_exit.evaluate(ori_test_features_exit, ori_test_labels_exit, verbose=0)\n",
    "print(\"v2. Test result Exit:\", ori_test_results_exit)\n",
    "print()\n",
    "\n",
    "#----------------------\n",
    "pd.DataFrame(test_results_entrance, index=['Mean absolute error [Temperature]']).T\n",
    "\n",
    "pd.DataFrame(test_results_exit, index=['Mean absolute error [Temperature]']).T\n",
    "\n",
    "pd.DataFrame(ori_test_results_entrance, index=['Mean absolute error [Temperature]']).T\n",
    "\n",
    "pd.DataFrame(ori_test_results_exit, index=['Mean absolute error [Temperature]']).T\n",
    "\n",
    "#----------------------\n",
    "test_predictions_entrance = final_model_entrance.predict(test_features_entrance).flatten()\n",
    "print(\"Test Predictions Entrance:\", test_predictions_entrance)\n",
    "print()\n",
    "\n",
    "test_predictions_exit = final_model_exit.predict(test_features_exit).flatten()\n",
    "print(\"Test Predictions Exit:\", test_predictions_exit)\n",
    "print()\n",
    "\n",
    "ori_test_predictions_entrance = final_model_entrance.predict(ori_test_features_entrance).flatten()\n",
    "print(\"v2. Test Predictions Entrance:\", ori_test_predictions_entrance)\n",
    "print()\n",
    "\n",
    "ori_test_predictions_exit = final_model_exit.predict(ori_test_features_exit).flatten()\n",
    "print(\"v2. Test Predictions Exit:\", ori_test_predictions_exit)\n",
    "print()\n",
    "\n",
    "#----------------------\n",
    "error_entrance = test_predictions_entrance - test_labels_entrance\n",
    "print(\"Error entrance:\", error_entrance)\n",
    "print()\n",
    "\n",
    "error_exit = test_predictions_entrance - test_labels_entrance\n",
    "print(\"Error exit:\", error_exit)\n",
    "print()\n",
    "\n",
    "ori_error_entrance = ori_test_predictions_entrance - ori_test_labels_entrance\n",
    "print(\"v2. Error entrance:\", ori_error_entrance)\n",
    "print()\n",
    "\n",
    "ori_error_exit = ori_test_predictions_entrance - ori_test_labels_entrance\n",
    "print(\"v2. Error exit:\", ori_error_exit)\n",
    "print()\n",
    "\n",
    "#----------------------\n",
    "plt.hist(error_entrance, bins=25, color='lightblue')\n",
    "plt.xlabel('Prediction Error [Temperature]')\n",
    "_ = plt.ylabel('Count')\n",
    "\n",
    "error_exit = test_predictions_exit - test_labels_exit\n",
    "error_exit\n",
    "\n",
    "plt.hist(error_exit, bins=25, color='lightblue')\n",
    "plt.xlabel('Prediction Error [Temperature]')\n",
    "_ = plt.ylabel('Count')\n",
    "\n",
    "# average error\n",
    "average_error_entrance = np.mean(error_entrance)\n",
    "print(\"Average error for entrance:\", average_error_entrance)\n",
    "print()\n",
    "\n",
    "average_error_exit = np.mean(error_exit)\n",
    "print(\"Average error for exit:\", average_error_exit)\n",
    "print()\n",
    "\n",
    "ori_average_error_entrance = np.mean(ori_error_entrance)\n",
    "print(\"v2. Average error for entrance:\", ori_average_error_entrance)\n",
    "print()\n",
    "\n",
    "ori_average_error_exit = np.mean(ori_error_exit)\n",
    "print(\"v2. Average error for exit:\", ori_average_error_exit)\n",
    "print()\n",
    "\n",
    "# mean squared error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse_entrance = mean_squared_error(test_labels_entrance, test_predictions_entrance)\n",
    "mse_exit = mean_squared_error(test_labels_exit, test_predictions_exit)\n",
    "print(\"Mean Squared Error for entrance:\", mse_entrance)\n",
    "print(\"Mean Squared Error for exit:\", mse_exit)\n",
    "print()\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "ori_mse_entrance = mean_squared_error(ori_test_labels_entrance, ori_test_predictions_entrance)\n",
    "ori_mse_exit = mean_squared_error(ori_test_labels_exit, ori_test_predictions_exit)\n",
    "print(\"v2. Mean Squared Error for entrance:\", ori_mse_entrance)\n",
    "print(\"v2. Mean Squared Error for exit:\", ori_mse_exit)\n",
    "print()\n",
    "\n",
    "# mean absolute error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "mae_entrance = mean_absolute_error(test_labels_entrance, test_predictions_entrance)\n",
    "mae_exit = mean_absolute_error(test_labels_exit, test_predictions_exit)\n",
    "print(\"Mean Absolute Error for entrance:\", mae_entrance)\n",
    "print(\"Mean Absolute Error for exit:\", mae_exit)\n",
    "print()\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "ori_mae_entrance = mean_absolute_error(ori_test_labels_entrance, ori_test_predictions_entrance)\n",
    "ori_mae_exit = mean_absolute_error(ori_test_labels_exit, ori_test_predictions_exit)\n",
    "print(\"v2. Mean Absolute Error for entrance:\", ori_mae_entrance)\n",
    "print(\"v2. Mean Absolute Error for exit:\", ori_mae_exit)\n",
    "print()\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def mean_absolute_percentage_error(y_actual, y_pred):\n",
    "    y_actual, y_pred = np.array(y_actual), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_actual - y_pred) / y_actual)) * 100\n",
    "\n",
    "mape_entrance = mean_absolute_percentage_error(test_labels_entrance, test_predictions_entrance)\n",
    "print(f'MAPE for entrance: {mape_entrance:.2f}%')\n",
    "\n",
    "mape_exit = mean_absolute_percentage_error(test_labels_exit, test_predictions_exit)\n",
    "print(f'MAPE for exit: {mape_exit:.2f}%')\n",
    "\n",
    "ori_mape_entrance = mean_absolute_percentage_error(ori_test_labels_entrance, ori_test_predictions_entrance)\n",
    "print(f'v2. MAPE for entrance: {ori_mape_entrance:.2f}%')\n",
    "\n",
    "ori_mape_exit = mean_absolute_percentage_error(ori_test_labels_exit, ori_test_predictions_exit)\n",
    "print(f'v2. MAPE for exit: {ori_mape_exit:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "ab40bc48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial Losses (Objective Values) as a Column:\n",
      "1|0.5570507794618607\n",
      "2|0.7986577600240707\n",
      "3|0.5595938861370087\n",
      "4|56.18984031677246\n",
      "5|1.5932369232177734\n",
      "6|0.7583253681659698\n",
      "7|0.6016537845134735\n",
      "8|0.5303560048341751\n",
      "9|67.7089786529541\n",
      "10|29.388821601867676\n",
      "11|0.8223410546779633\n",
      "12|0.5006768703460693\n",
      "13|0.49343812465667725\n",
      "14|0.4918321967124939\n",
      "15|0.5865670740604401\n",
      "16|0.5388591587543488\n",
      "17|0.603728324174881\n",
      "18|0.6585977971553802\n",
      "19|1.7397026233375072\n",
      "20|0.6233415007591248\n",
      "21|0.5443441569805145\n",
      "22|0.4135911464691162\n",
      "23|0.6608028560876846\n",
      "24|0.5593795329332352\n",
      "25|1.847203254699707\n",
      "26|0.47387704253196716\n",
      "27|0.36335501074790955\n",
      "28|0.43111634254455566\n",
      "29|0.6501554250717163\n",
      "30|1.7428291253745556\n",
      "31|1.4525761678814888\n",
      "32|0.3679780922830105\n",
      "33|1.7399519197642803\n",
      "34|0.28102970495820045\n",
      "35|0.10807193070650101\n",
      "36|0.2786802798509598\n",
      "37|0.22688952460885048\n",
      "38|0.7631734199821949\n",
      "39|0.30578405037522316\n",
      "40|0.41914601996541023\n",
      "41|0.26186301186680794\n",
      "42|0.2928758077323437\n",
      "43|0.3209781385958195\n",
      "44|0.4608282968401909\n",
      "45|0.3362283334136009\n",
      "46|0.2933061420917511\n",
      "47|0.31433623284101486\n",
      "48|0.25424153730273247\n",
      "49|0.3634043186903\n",
      "50|0.3303770422935486\n",
      "51|0.25434665381908417\n",
      "52|0.39344391599297523\n",
      "53|0.22235627844929695\n",
      "54|0.36164453998208046\n",
      "55|0.2378852516412735\n",
      "56|0.2941996417939663\n",
      "57|0.26273059472441673\n",
      "58|0.33386528119444847\n",
      "59|0.25265391170978546\n",
      "60|0.17834578454494476\n",
      "61|0.17026184871792793\n",
      "62|0.21659672632813454\n",
      "63|0.20216145366430283\n",
      "64|0.18482161685824394\n",
      "65|0.20905804634094238\n",
      "66|0.20349648594856262\n",
      "67|0.19153429940342903\n",
      "68|0.216923076659441\n",
      "69|0.2804652974009514\n",
      "70|0.224187184125185\n",
      "71|0.19561121240258217\n",
      "72|0.25704649463295937\n",
      "73|0.21781941130757332\n",
      "74|0.2948531024158001\n",
      "75|0.2552865855395794\n",
      "76|0.2627711072564125\n",
      "77|0.2201676182448864\n",
      "78|0.3400610387325287\n",
      "79|0.1942392736673355\n",
      "80|0.28592512011528015\n",
      "81|24.385011672973633\n",
      "82|0.20334535837173462\n",
      "83|0.27227288484573364\n",
      "84|0.27139466255903244\n",
      "85|0.15686361491680145\n",
      "86|0.2195236049592495\n",
      "87|0.21523157507181168\n",
      "88|0.22825361415743828\n",
      "89|0.43736881017684937\n",
      "90|0.2809253856539726\n",
      "91|11.257524967193604\n",
      "92|0.185495525598526\n",
      "93|0.22126038372516632\n",
      "94|0.19675587862730026\n",
      "95|0.20615656673908234\n",
      "96|0.24825945124030113\n",
      "97|0.23746227100491524\n",
      "98|0.20370811596512794\n",
      "99|0.18154776841402054\n",
      "100|0.5845992863178253\n"
     ]
    }
   ],
   "source": [
    "print(\"Trial Losses (Objective Values) as a Column:\")\n",
    "for i, loss in enumerate(trial_losses):\n",
    "    print(f\"{i + 1}|{loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70da06e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
