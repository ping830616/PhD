{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2449187",
   "metadata": {},
   "source": [
    "# Regression with Deep Neural Network (DNN)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf46af2",
   "metadata": {},
   "source": [
    "In a regression problem, the aim is to predict the output of a continuous value, like a energy consumption, a temperature value or a probability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b62a5c",
   "metadata": {},
   "source": [
    "This file demonstrates how to build models to predict the energy efficiency of the MAU system. To do this, you will provide the models with a description of many MAUs from that a certain period. This description includes attributes like temperature, humidity, airflow, and enthalpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "757b6769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use seaborn for pairplot.\n",
    "!pip install -q seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bcc84e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Make NumPy printouts easier to read.\n",
    "np.set_printoptions(precision=3, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04780b27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.12.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58eaa09e",
   "metadata": {},
   "source": [
    "## Load all MAU entrance data (340 counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd298cf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ï»¿Date</th>\n",
       "      <th>Temperature (Â°F)</th>\n",
       "      <th>Humidity (%)</th>\n",
       "      <th>Density (g/m^3)</th>\n",
       "      <th>Enthalpy, h (kJ/kg)</th>\n",
       "      <th>x (g/kg)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22-Feb-24</td>\n",
       "      <td>73.990</td>\n",
       "      <td>31.99</td>\n",
       "      <td>6.739634</td>\n",
       "      <td>38.084616</td>\n",
       "      <td>5.703496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22-Feb-24</td>\n",
       "      <td>87.400</td>\n",
       "      <td>20.51</td>\n",
       "      <td>6.478677</td>\n",
       "      <td>45.612924</td>\n",
       "      <td>5.626363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22-Feb-24</td>\n",
       "      <td>88.410</td>\n",
       "      <td>20.05</td>\n",
       "      <td>6.614761</td>\n",
       "      <td>46.233882</td>\n",
       "      <td>5.757059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22-Feb-24</td>\n",
       "      <td>87.370</td>\n",
       "      <td>20.35</td>\n",
       "      <td>6.498739</td>\n",
       "      <td>45.412801</td>\n",
       "      <td>5.552050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22-Feb-24</td>\n",
       "      <td>87.330</td>\n",
       "      <td>20.63</td>\n",
       "      <td>6.505203</td>\n",
       "      <td>45.513075</td>\n",
       "      <td>5.695444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>4-Apr-24</td>\n",
       "      <td>90.770</td>\n",
       "      <td>7.00</td>\n",
       "      <td>2.320417</td>\n",
       "      <td>38.438527</td>\n",
       "      <td>2.085040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>4-Apr-24</td>\n",
       "      <td>90.734</td>\n",
       "      <td>7.57</td>\n",
       "      <td>2.685156</td>\n",
       "      <td>38.786357</td>\n",
       "      <td>2.213950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>4-Apr-24</td>\n",
       "      <td>88.988</td>\n",
       "      <td>7.97</td>\n",
       "      <td>2.692662</td>\n",
       "      <td>38.051719</td>\n",
       "      <td>2.368482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>4-Apr-24</td>\n",
       "      <td>90.194</td>\n",
       "      <td>7.64</td>\n",
       "      <td>2.786365</td>\n",
       "      <td>38.712086</td>\n",
       "      <td>2.349042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>4-Apr-24</td>\n",
       "      <td>86.720</td>\n",
       "      <td>7.95</td>\n",
       "      <td>2.474083</td>\n",
       "      <td>36.073229</td>\n",
       "      <td>2.185066</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>340 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ï»¿Date  Temperature (Â°F)  Humidity (%)  Density (g/m^3)  \\\n",
       "0    22-Feb-24             73.990         31.99         6.739634   \n",
       "1    22-Feb-24             87.400         20.51         6.478677   \n",
       "2    22-Feb-24             88.410         20.05         6.614761   \n",
       "3    22-Feb-24             87.370         20.35         6.498739   \n",
       "4    22-Feb-24             87.330         20.63         6.505203   \n",
       "..         ...                ...           ...              ...   \n",
       "335   4-Apr-24             90.770          7.00         2.320417   \n",
       "336   4-Apr-24             90.734          7.57         2.685156   \n",
       "337   4-Apr-24             88.988          7.97         2.692662   \n",
       "338   4-Apr-24             90.194          7.64         2.786365   \n",
       "339   4-Apr-24             86.720          7.95         2.474083   \n",
       "\n",
       "     Enthalpy, h (kJ/kg)  x (g/kg)  \n",
       "0              38.084616  5.703496  \n",
       "1              45.612924  5.626363  \n",
       "2              46.233882  5.757059  \n",
       "3              45.412801  5.552050  \n",
       "4              45.513075  5.695444  \n",
       "..                   ...       ...  \n",
       "335            38.438527  2.085040  \n",
       "336            38.786357  2.213950  \n",
       "337            38.051719  2.368482  \n",
       "338            38.712086  2.349042  \n",
       "339            36.073229  2.185066  \n",
       "\n",
       "[340 rows x 6 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load entrance data\n",
    "data_entrance = pd.read_csv('/Users/hsiaopingni/Desktop/Hsiao-Ping PhD/Data/MAU_paper/random_noise_data_entrance_340.csv', encoding='unicode_escape')\n",
    "#data_entrance=pd.read_csv(r'C:\\Users\\Hsiao-ping.ni\\ASU Dropbox\\Hsiao-Ping Ni\\PhD\\Data\\3rd paper- MAU\\random_noise_data_entrance_340.csv', encoding='unicode_escape')\n",
    "#data_entrance=pd.read_csv(r'C:\\Users\\nick8\\ASU Dropbox\\Hsiao-Ping Ni\\PhD\\Data\\3rd paper- MAU\\random_noise_data_entrance_340.csv', encoding='unicode_escape')\n",
    "data_entrance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80c1e7b",
   "metadata": {},
   "source": [
    "## Load all MAU exit data (340 counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6f18855",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ï»¿Date</th>\n",
       "      <th>Temperature (Â°F)</th>\n",
       "      <th>Humidity (%)</th>\n",
       "      <th>Density (g/m^3)</th>\n",
       "      <th>Enthalpy, h (kJ/kg)</th>\n",
       "      <th>x (g/kg)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22-Feb-24</td>\n",
       "      <td>75.038</td>\n",
       "      <td>38.79</td>\n",
       "      <td>8.461013</td>\n",
       "      <td>42.420607</td>\n",
       "      <td>7.130722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22-Feb-24</td>\n",
       "      <td>74.984</td>\n",
       "      <td>38.16</td>\n",
       "      <td>8.367809</td>\n",
       "      <td>42.094462</td>\n",
       "      <td>7.088645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22-Feb-24</td>\n",
       "      <td>75.092</td>\n",
       "      <td>39.94</td>\n",
       "      <td>8.633728</td>\n",
       "      <td>42.971724</td>\n",
       "      <td>7.405640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22-Feb-24</td>\n",
       "      <td>75.020</td>\n",
       "      <td>39.08</td>\n",
       "      <td>8.573215</td>\n",
       "      <td>42.546864</td>\n",
       "      <td>2.256353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22-Feb-24</td>\n",
       "      <td>75.038</td>\n",
       "      <td>38.89</td>\n",
       "      <td>8.495630</td>\n",
       "      <td>42.400419</td>\n",
       "      <td>7.146205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>4-Apr-24</td>\n",
       "      <td>75.074</td>\n",
       "      <td>38.43</td>\n",
       "      <td>8.361217</td>\n",
       "      <td>42.219083</td>\n",
       "      <td>7.076425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>4-Apr-24</td>\n",
       "      <td>75.146</td>\n",
       "      <td>39.14</td>\n",
       "      <td>8.487478</td>\n",
       "      <td>42.653262</td>\n",
       "      <td>7.252031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>4-Apr-24</td>\n",
       "      <td>75.074</td>\n",
       "      <td>42.52</td>\n",
       "      <td>8.469769</td>\n",
       "      <td>42.468097</td>\n",
       "      <td>7.212769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>4-Apr-24</td>\n",
       "      <td>75.146</td>\n",
       "      <td>38.07</td>\n",
       "      <td>8.328769</td>\n",
       "      <td>42.158082</td>\n",
       "      <td>6.980890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>4-Apr-24</td>\n",
       "      <td>75.182</td>\n",
       "      <td>39.89</td>\n",
       "      <td>8.646894</td>\n",
       "      <td>43.017927</td>\n",
       "      <td>7.447627</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>340 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ï»¿Date  Temperature (Â°F)  Humidity (%)  Density (g/m^3)  \\\n",
       "0    22-Feb-24             75.038         38.79         8.461013   \n",
       "1    22-Feb-24             74.984         38.16         8.367809   \n",
       "2    22-Feb-24             75.092         39.94         8.633728   \n",
       "3    22-Feb-24             75.020         39.08         8.573215   \n",
       "4    22-Feb-24             75.038         38.89         8.495630   \n",
       "..         ...                ...           ...              ...   \n",
       "335   4-Apr-24             75.074         38.43         8.361217   \n",
       "336   4-Apr-24             75.146         39.14         8.487478   \n",
       "337   4-Apr-24             75.074         42.52         8.469769   \n",
       "338   4-Apr-24             75.146         38.07         8.328769   \n",
       "339   4-Apr-24             75.182         39.89         8.646894   \n",
       "\n",
       "     Enthalpy, h (kJ/kg)  x (g/kg)  \n",
       "0              42.420607  7.130722  \n",
       "1              42.094462  7.088645  \n",
       "2              42.971724  7.405640  \n",
       "3              42.546864  2.256353  \n",
       "4              42.400419  7.146205  \n",
       "..                   ...       ...  \n",
       "335            42.219083  7.076425  \n",
       "336            42.653262  7.252031  \n",
       "337            42.468097  7.212769  \n",
       "338            42.158082  6.980890  \n",
       "339            43.017927  7.447627  \n",
       "\n",
       "[340 rows x 6 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load exit data\n",
    "data_exit = pd.read_csv('/Users/hsiaopingni/Desktop/Hsiao-Ping PhD/Data/MAU_paper/random_noise_data_exit_340.csv', encoding='unicode_escape')\n",
    "#data_exit=pd.read_csv(r'C:\\Users\\Hsiao-ping.ni\\ASU Dropbox\\Hsiao-Ping Ni\\PhD\\Data\\3rd paper- MAU\\random_noise_data_exit_340.csv', encoding='unicode_escape')\n",
    "#data_exit=pd.read_csv(r'C:\\Users\\nick8\\ASU Dropbox\\Hsiao-Ping Ni\\PhD\\Data\\3rd paper- MAU\\random_noise_data_exit_340.csv', encoding='unicode_escape')\n",
    "data_exit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4941ff",
   "metadata": {},
   "source": [
    "## Split the data into training and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926f127a",
   "metadata": {},
   "source": [
    "Now, split the dataset into a training set and a test set. You will use the test set in the final evaluation of your model.\n",
    "\n",
    "The line of code \"train_dataset = dataset.sample(frac=0.8, random_state=0)\" creates a training dataset by randomly selecting 80% of the rows from the dataset, ensuring that the selection is reproducible by setting a random state. The frac=0.8 parameter specifies that 80% of the data should be sampled, and random_state=0 ensures that the random selection of rows is consistent every time the code is run, facilitating reproducible results in experiments or analyses.\n",
    "\n",
    "The line \"test_dataset = dataset.drop(train_dataset.index)\" removes all rows from dataset that are already included in train_dataset, effectively creating a test dataset. This is achieved by dropping rows indexed in train_dataset.index from the original dataset. The result is a dataset containing 20% of the original data, not selected for training, used for testing model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0899dde3",
   "metadata": {},
   "source": [
    "### Train datasets for MAU entrance (272 counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909af274",
   "metadata": {},
   "source": [
    "Drop 'Count' and 'Which MAU' columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3ae9f3e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature (Â°F)</th>\n",
       "      <th>Humidity (%)</th>\n",
       "      <th>Density (g/m^3)</th>\n",
       "      <th>Enthalpy, h (kJ/kg)</th>\n",
       "      <th>x (g/kg)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>87.330</td>\n",
       "      <td>20.63</td>\n",
       "      <td>6.618528</td>\n",
       "      <td>45.665051</td>\n",
       "      <td>5.661910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>86.720</td>\n",
       "      <td>7.95</td>\n",
       "      <td>2.391320</td>\n",
       "      <td>36.279681</td>\n",
       "      <td>2.227304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>73.990</td>\n",
       "      <td>31.99</td>\n",
       "      <td>6.753991</td>\n",
       "      <td>38.115914</td>\n",
       "      <td>5.658066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>88.410</td>\n",
       "      <td>20.05</td>\n",
       "      <td>6.582001</td>\n",
       "      <td>46.277658</td>\n",
       "      <td>5.752278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>88.720</td>\n",
       "      <td>13.32</td>\n",
       "      <td>4.397792</td>\n",
       "      <td>41.572672</td>\n",
       "      <td>3.736026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>87.760</td>\n",
       "      <td>12.46</td>\n",
       "      <td>3.984378</td>\n",
       "      <td>40.290405</td>\n",
       "      <td>3.480314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>88.720</td>\n",
       "      <td>13.32</td>\n",
       "      <td>4.393553</td>\n",
       "      <td>41.531900</td>\n",
       "      <td>3.807427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>90.770</td>\n",
       "      <td>7.00</td>\n",
       "      <td>2.420199</td>\n",
       "      <td>38.353314</td>\n",
       "      <td>2.127184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>90.734</td>\n",
       "      <td>7.57</td>\n",
       "      <td>2.741618</td>\n",
       "      <td>38.748406</td>\n",
       "      <td>2.348994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>90.194</td>\n",
       "      <td>7.64</td>\n",
       "      <td>2.786365</td>\n",
       "      <td>38.712086</td>\n",
       "      <td>2.349042</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>272 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Temperature (Â°F)  Humidity (%)  Density (g/m^3)  Enthalpy, h (kJ/kg)  \\\n",
       "225             87.330         20.63         6.618528            45.665051   \n",
       "271             86.720          7.95         2.391320            36.279681   \n",
       "204             73.990         31.99         6.753991            38.115914   \n",
       "274             88.410         20.05         6.582001            46.277658   \n",
       "299             88.720         13.32         4.397792            41.572672   \n",
       "..                 ...           ...              ...                  ...   \n",
       "143             87.760         12.46         3.984378            40.290405   \n",
       "180             88.720         13.32         4.393553            41.531900   \n",
       "131             90.770          7.00         2.420199            38.353314   \n",
       "302             90.734          7.57         2.741618            38.748406   \n",
       "338             90.194          7.64         2.786365            38.712086   \n",
       "\n",
       "     x (g/kg)  \n",
       "225  5.661910  \n",
       "271  2.227304  \n",
       "204  5.658066  \n",
       "274  5.752278  \n",
       "299  3.736026  \n",
       "..        ...  \n",
       "143  3.480314  \n",
       "180  3.807427  \n",
       "131  2.127184  \n",
       "302  2.348994  \n",
       "338  2.349042  \n",
       "\n",
       "[272 rows x 5 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_entrance = data_entrance.drop(['ï»¿Date'], axis=1)\n",
    "train_dataset_entrance = data_entrance.sample(frac=0.8, random_state=0)\n",
    "test_dataset_entrance = data_entrance.drop(train_dataset_entrance.index)\n",
    "train_dataset_entrance\n",
    "\n",
    "# Spliting data into Feature \n",
    "#X=data[['Humidity (%)','Airflow (g/m^3)','Enthalpy, h (kJ/kg)','x (g/kg)']]\n",
    "#y=data['Temperature (°F)']\n",
    "\n",
    "# Import train_test_split function\n",
    "#from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split dataset into training set and test (validation) set\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)  # 80% training and 20% test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f4ed3e",
   "metadata": {},
   "source": [
    "### Test datasets for MAU entrance (68 counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "360ce48e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature (Â°F)</th>\n",
       "      <th>Humidity (%)</th>\n",
       "      <th>Density (g/m^3)</th>\n",
       "      <th>Enthalpy, h (kJ/kg)</th>\n",
       "      <th>x (g/kg)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>89.650</td>\n",
       "      <td>13.09</td>\n",
       "      <td>4.401632</td>\n",
       "      <td>42.274344</td>\n",
       "      <td>3.860325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>85.660</td>\n",
       "      <td>14.32</td>\n",
       "      <td>4.370370</td>\n",
       "      <td>39.863345</td>\n",
       "      <td>3.698648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>78.570</td>\n",
       "      <td>26.62</td>\n",
       "      <td>6.381562</td>\n",
       "      <td>40.238158</td>\n",
       "      <td>3.941589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>88.988</td>\n",
       "      <td>7.97</td>\n",
       "      <td>2.692270</td>\n",
       "      <td>38.022185</td>\n",
       "      <td>2.276832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>90.194</td>\n",
       "      <td>7.64</td>\n",
       "      <td>2.736127</td>\n",
       "      <td>38.803568</td>\n",
       "      <td>2.363204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>89.650</td>\n",
       "      <td>13.09</td>\n",
       "      <td>4.376609</td>\n",
       "      <td>42.282407</td>\n",
       "      <td>3.763491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>73.990</td>\n",
       "      <td>31.99</td>\n",
       "      <td>6.773940</td>\n",
       "      <td>38.008877</td>\n",
       "      <td>5.750958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>88.410</td>\n",
       "      <td>20.05</td>\n",
       "      <td>6.670464</td>\n",
       "      <td>46.247404</td>\n",
       "      <td>5.737961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>87.330</td>\n",
       "      <td>20.63</td>\n",
       "      <td>6.495229</td>\n",
       "      <td>45.571644</td>\n",
       "      <td>5.664049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>75.540</td>\n",
       "      <td>29.08</td>\n",
       "      <td>6.345534</td>\n",
       "      <td>38.280127</td>\n",
       "      <td>5.458094</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Temperature (Â°F)  Humidity (%)  Density (g/m^3)  Enthalpy, h (kJ/kg)  \\\n",
       "9               89.650         13.09         4.401632            42.274344   \n",
       "25              85.660         14.32         4.370370            39.863345   \n",
       "28              78.570         26.62         6.381562            40.238158   \n",
       "31              88.988          7.97         2.692270            38.022185   \n",
       "32              90.194          7.64         2.736127            38.803568   \n",
       "..                 ...           ...              ...                  ...   \n",
       "315             89.650         13.09         4.376609            42.282407   \n",
       "323             73.990         31.99         6.773940            38.008877   \n",
       "325             88.410         20.05         6.670464            46.247404   \n",
       "327             87.330         20.63         6.495229            45.571644   \n",
       "328             75.540         29.08         6.345534            38.280127   \n",
       "\n",
       "     x (g/kg)  \n",
       "9    3.860325  \n",
       "25   3.698648  \n",
       "28   3.941589  \n",
       "31   2.276832  \n",
       "32   2.363204  \n",
       "..        ...  \n",
       "315  3.763491  \n",
       "323  5.750958  \n",
       "325  5.737961  \n",
       "327  5.664049  \n",
       "328  5.458094  \n",
       "\n",
       "[68 rows x 5 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset_entrance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e611d851",
   "metadata": {},
   "source": [
    "### Load original entrance data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2193f6e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "      <th>Which MAU</th>\n",
       "      <th>Temperature (°F)</th>\n",
       "      <th>Humidity (%)</th>\n",
       "      <th>Density (g/m^3)</th>\n",
       "      <th>Enthalpy, h (kJ/kg)</th>\n",
       "      <th>x (g/kg)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>73.990</td>\n",
       "      <td>31.99</td>\n",
       "      <td>6.73</td>\n",
       "      <td>38.08</td>\n",
       "      <td>5.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>87.400</td>\n",
       "      <td>20.51</td>\n",
       "      <td>6.51</td>\n",
       "      <td>45.55</td>\n",
       "      <td>5.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>88.410</td>\n",
       "      <td>20.05</td>\n",
       "      <td>6.59</td>\n",
       "      <td>46.29</td>\n",
       "      <td>5.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>87.370</td>\n",
       "      <td>20.35</td>\n",
       "      <td>6.45</td>\n",
       "      <td>45.39</td>\n",
       "      <td>5.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>87.330</td>\n",
       "      <td>20.63</td>\n",
       "      <td>6.51</td>\n",
       "      <td>45.59</td>\n",
       "      <td>5.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>75.540</td>\n",
       "      <td>29.08</td>\n",
       "      <td>6.44</td>\n",
       "      <td>38.33</td>\n",
       "      <td>5.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>80.780</td>\n",
       "      <td>22.35</td>\n",
       "      <td>5.81</td>\n",
       "      <td>40.09</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>87.760</td>\n",
       "      <td>12.46</td>\n",
       "      <td>3.97</td>\n",
       "      <td>40.32</td>\n",
       "      <td>3.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>85.660</td>\n",
       "      <td>14.32</td>\n",
       "      <td>4.39</td>\n",
       "      <td>39.87</td>\n",
       "      <td>3.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>89.650</td>\n",
       "      <td>13.09</td>\n",
       "      <td>4.42</td>\n",
       "      <td>42.21</td>\n",
       "      <td>3.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>88.720</td>\n",
       "      <td>13.32</td>\n",
       "      <td>4.37</td>\n",
       "      <td>41.51</td>\n",
       "      <td>3.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>78.570</td>\n",
       "      <td>26.62</td>\n",
       "      <td>6.44</td>\n",
       "      <td>40.20</td>\n",
       "      <td>3.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>90.770</td>\n",
       "      <td>7.00</td>\n",
       "      <td>2.42</td>\n",
       "      <td>38.36</td>\n",
       "      <td>2.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>90.734</td>\n",
       "      <td>7.57</td>\n",
       "      <td>2.63</td>\n",
       "      <td>38.76</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>88.988</td>\n",
       "      <td>7.97</td>\n",
       "      <td>2.71</td>\n",
       "      <td>38.04</td>\n",
       "      <td>2.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>90.194</td>\n",
       "      <td>7.64</td>\n",
       "      <td>2.76</td>\n",
       "      <td>38.77</td>\n",
       "      <td>2.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>86.720</td>\n",
       "      <td>7.95</td>\n",
       "      <td>2.44</td>\n",
       "      <td>36.15</td>\n",
       "      <td>2.12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Count  Which MAU  Temperature (°F)  Humidity (%)  Density (g/m^3)  \\\n",
       "0       1          1            73.990         31.99             6.73   \n",
       "1       2          2            87.400         20.51             6.51   \n",
       "2       3          3            88.410         20.05             6.59   \n",
       "3       4          4            87.370         20.35             6.45   \n",
       "4       5          5            87.330         20.63             6.51   \n",
       "5       6          9            75.540         29.08             6.44   \n",
       "6       7          1            80.780         22.35             5.81   \n",
       "7       8          1            87.760         12.46             3.97   \n",
       "8       9          1            85.660         14.32             4.39   \n",
       "9      10          3            89.650         13.09             4.42   \n",
       "10     11          4            88.720         13.32             4.37   \n",
       "11     12          1            78.570         26.62             6.44   \n",
       "12     13          2            90.770          7.00             2.42   \n",
       "13     14          3            90.734          7.57             2.63   \n",
       "14     15          4            88.988          7.97             2.71   \n",
       "15     16          5            90.194          7.64             2.76   \n",
       "16     17          6            86.720          7.95             2.44   \n",
       "\n",
       "    Enthalpy, h (kJ/kg)  x (g/kg)  \n",
       "0                 38.08      5.68  \n",
       "1                 45.55      5.66  \n",
       "2                 46.29      5.74  \n",
       "3                 45.39      5.60  \n",
       "4                 45.59      5.66  \n",
       "5                 38.33      5.46  \n",
       "6                 40.09      4.98  \n",
       "7                 40.32      3.46  \n",
       "8                 39.87      3.72  \n",
       "9                 42.21      3.86  \n",
       "10                41.51      3.81  \n",
       "11                40.20      3.88  \n",
       "12                38.36      2.10  \n",
       "13                38.76      2.31  \n",
       "14                38.04      2.30  \n",
       "15                38.77      2.32  \n",
       "16                36.15      2.12  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load entrance data\n",
    "ori_data_entrance = pd.read_csv('/Users/hsiaopingni/Desktop/Hsiao-Ping PhD/Data/MAU_paper/AI_model_MAU_Entrance.csv', encoding='unicode_escape')\n",
    "#ori_data_entrance=pd.read_csv(r'C:\\Users\\Hsiao-ping.ni\\ASU Dropbox\\Hsiao-Ping Ni\\PhD\\Data\\3rd paper- MAU\\AI_model_MAU_Entrance.csv', encoding='unicode_escape')\n",
    "#ori_data_entrance=pd.read_csv(r'C:\\Users\\nick8\\ASU Dropbox\\Hsiao-Ping Ni\\PhD\\Data\\3rd paper- MAU\\AI_model_MAU_Entrance.csv', encoding='unicode_escape')\n",
    "ori_data_entrance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd80952b",
   "metadata": {},
   "source": [
    "### Original test datasets for MAU entrance (3 counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "62b23c42-29ae-4f41-80f6-108c2c8d56a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "      <th>Which MAU</th>\n",
       "      <th>Temperature (°F)</th>\n",
       "      <th>Humidity (%)</th>\n",
       "      <th>Density (g/m^3)</th>\n",
       "      <th>Enthalpy, h (kJ/kg)</th>\n",
       "      <th>x (g/kg)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>75.540</td>\n",
       "      <td>29.08</td>\n",
       "      <td>6.44</td>\n",
       "      <td>38.33</td>\n",
       "      <td>5.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>90.770</td>\n",
       "      <td>7.00</td>\n",
       "      <td>2.42</td>\n",
       "      <td>38.36</td>\n",
       "      <td>2.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>90.194</td>\n",
       "      <td>7.64</td>\n",
       "      <td>2.76</td>\n",
       "      <td>38.77</td>\n",
       "      <td>2.32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Count  Which MAU  Temperature (°F)  Humidity (%)  Density (g/m^3)  \\\n",
       "5       6          9            75.540         29.08             6.44   \n",
       "12     13          2            90.770          7.00             2.42   \n",
       "15     16          5            90.194          7.64             2.76   \n",
       "\n",
       "    Enthalpy, h (kJ/kg)  x (g/kg)  \n",
       "5                 38.33      5.46  \n",
       "12                38.36      2.10  \n",
       "15                38.77      2.32  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ori_test_entrance = ori_data_entrance.iloc[[5, 12, 15]]\n",
    "ori_test_entrance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe38de2f",
   "metadata": {},
   "source": [
    "### Train datasets for MAU exit (272 counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fcaa78ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature (Â°F)</th>\n",
       "      <th>Humidity (%)</th>\n",
       "      <th>Density (g/m^3)</th>\n",
       "      <th>Enthalpy, h (kJ/kg)</th>\n",
       "      <th>x (g/kg)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>75.038</td>\n",
       "      <td>38.89</td>\n",
       "      <td>8.476378</td>\n",
       "      <td>42.396510</td>\n",
       "      <td>7.205999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>75.182</td>\n",
       "      <td>39.89</td>\n",
       "      <td>8.665360</td>\n",
       "      <td>42.979357</td>\n",
       "      <td>7.455157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>75.038</td>\n",
       "      <td>38.79</td>\n",
       "      <td>8.446582</td>\n",
       "      <td>42.355040</td>\n",
       "      <td>7.187971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>75.092</td>\n",
       "      <td>39.94</td>\n",
       "      <td>8.619342</td>\n",
       "      <td>42.970125</td>\n",
       "      <td>7.338046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>75.110</td>\n",
       "      <td>38.67</td>\n",
       "      <td>8.442880</td>\n",
       "      <td>42.501051</td>\n",
       "      <td>7.175249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>74.804</td>\n",
       "      <td>38.61</td>\n",
       "      <td>8.352576</td>\n",
       "      <td>42.012780</td>\n",
       "      <td>7.118046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>75.110</td>\n",
       "      <td>38.67</td>\n",
       "      <td>8.446570</td>\n",
       "      <td>42.555351</td>\n",
       "      <td>7.167860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>75.074</td>\n",
       "      <td>38.43</td>\n",
       "      <td>8.421875</td>\n",
       "      <td>42.249949</td>\n",
       "      <td>7.108325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>75.146</td>\n",
       "      <td>39.14</td>\n",
       "      <td>8.512689</td>\n",
       "      <td>42.774177</td>\n",
       "      <td>7.149740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>75.146</td>\n",
       "      <td>38.07</td>\n",
       "      <td>8.328769</td>\n",
       "      <td>42.158082</td>\n",
       "      <td>6.980890</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>272 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Temperature (Â°F)  Humidity (%)  Density (g/m^3)  Enthalpy, h (kJ/kg)  \\\n",
       "225             75.038         38.89         8.476378            42.396510   \n",
       "271             75.182         39.89         8.665360            42.979357   \n",
       "204             75.038         38.79         8.446582            42.355040   \n",
       "274             75.092         39.94         8.619342            42.970125   \n",
       "299             75.110         38.67         8.442880            42.501051   \n",
       "..                 ...           ...              ...                  ...   \n",
       "143             74.804         38.61         8.352576            42.012780   \n",
       "180             75.110         38.67         8.446570            42.555351   \n",
       "131             75.074         38.43         8.421875            42.249949   \n",
       "302             75.146         39.14         8.512689            42.774177   \n",
       "338             75.146         38.07         8.328769            42.158082   \n",
       "\n",
       "     x (g/kg)  \n",
       "225  7.205999  \n",
       "271  7.455157  \n",
       "204  7.187971  \n",
       "274  7.338046  \n",
       "299  7.175249  \n",
       "..        ...  \n",
       "143  7.118046  \n",
       "180  7.167860  \n",
       "131  7.108325  \n",
       "302  7.149740  \n",
       "338  6.980890  \n",
       "\n",
       "[272 rows x 5 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_exit = data_exit.drop(['ï»¿Date'], axis=1)\n",
    "train_dataset_exit = data_exit.sample(frac=0.8, random_state=0)\n",
    "test_dataset_exit = data_exit.drop(train_dataset_exit.index)\n",
    "train_dataset_exit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67a3cca",
   "metadata": {},
   "source": [
    "### Test datasets for MAU exit (68 counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bb8dbaca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature (Â°F)</th>\n",
       "      <th>Humidity (%)</th>\n",
       "      <th>Density (g/m^3)</th>\n",
       "      <th>Enthalpy, h (kJ/kg)</th>\n",
       "      <th>x (g/kg)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>75.074</td>\n",
       "      <td>39.34</td>\n",
       "      <td>8.556251</td>\n",
       "      <td>42.768485</td>\n",
       "      <td>7.364775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>74.894</td>\n",
       "      <td>38.55</td>\n",
       "      <td>8.809186</td>\n",
       "      <td>42.199336</td>\n",
       "      <td>7.506645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>74.516</td>\n",
       "      <td>38.64</td>\n",
       "      <td>8.158391</td>\n",
       "      <td>41.736814</td>\n",
       "      <td>7.083349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>75.074</td>\n",
       "      <td>42.52</td>\n",
       "      <td>8.433321</td>\n",
       "      <td>42.531764</td>\n",
       "      <td>7.190104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>75.146</td>\n",
       "      <td>38.07</td>\n",
       "      <td>8.268372</td>\n",
       "      <td>42.181495</td>\n",
       "      <td>7.027293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>75.074</td>\n",
       "      <td>39.34</td>\n",
       "      <td>8.617384</td>\n",
       "      <td>42.765265</td>\n",
       "      <td>7.186293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>75.038</td>\n",
       "      <td>38.79</td>\n",
       "      <td>8.337885</td>\n",
       "      <td>42.368529</td>\n",
       "      <td>7.248409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>75.092</td>\n",
       "      <td>39.94</td>\n",
       "      <td>8.669885</td>\n",
       "      <td>42.921554</td>\n",
       "      <td>7.434315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>75.038</td>\n",
       "      <td>38.89</td>\n",
       "      <td>8.463199</td>\n",
       "      <td>42.462564</td>\n",
       "      <td>7.199611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>75.110</td>\n",
       "      <td>38.80</td>\n",
       "      <td>8.423292</td>\n",
       "      <td>42.530855</td>\n",
       "      <td>7.111604</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Temperature (Â°F)  Humidity (%)  Density (g/m^3)  Enthalpy, h (kJ/kg)  \\\n",
       "9               75.074         39.34         8.556251            42.768485   \n",
       "25              74.894         38.55         8.809186            42.199336   \n",
       "28              74.516         38.64         8.158391            41.736814   \n",
       "31              75.074         42.52         8.433321            42.531764   \n",
       "32              75.146         38.07         8.268372            42.181495   \n",
       "..                 ...           ...              ...                  ...   \n",
       "315             75.074         39.34         8.617384            42.765265   \n",
       "323             75.038         38.79         8.337885            42.368529   \n",
       "325             75.092         39.94         8.669885            42.921554   \n",
       "327             75.038         38.89         8.463199            42.462564   \n",
       "328             75.110         38.80         8.423292            42.530855   \n",
       "\n",
       "     x (g/kg)  \n",
       "9    7.364775  \n",
       "25   7.506645  \n",
       "28   7.083349  \n",
       "31   7.190104  \n",
       "32   7.027293  \n",
       "..        ...  \n",
       "315  7.186293  \n",
       "323  7.248409  \n",
       "325  7.434315  \n",
       "327  7.199611  \n",
       "328  7.111604  \n",
       "\n",
       "[68 rows x 5 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset_exit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0105b630",
   "metadata": {},
   "source": [
    "### Load original exit data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "069609d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "      <th>Which MAU</th>\n",
       "      <th>Temperature (°F)</th>\n",
       "      <th>Humidity (%)</th>\n",
       "      <th>Density (g/m^3)</th>\n",
       "      <th>Enthalpy, h (kJ/kg)</th>\n",
       "      <th>x (g/kg)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>75.038</td>\n",
       "      <td>38.79</td>\n",
       "      <td>8.40</td>\n",
       "      <td>42.38</td>\n",
       "      <td>7.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>74.984</td>\n",
       "      <td>38.16</td>\n",
       "      <td>8.28</td>\n",
       "      <td>42.05</td>\n",
       "      <td>7.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>75.092</td>\n",
       "      <td>39.94</td>\n",
       "      <td>8.68</td>\n",
       "      <td>42.99</td>\n",
       "      <td>7.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>75.020</td>\n",
       "      <td>39.08</td>\n",
       "      <td>8.48</td>\n",
       "      <td>42.52</td>\n",
       "      <td>2.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>75.038</td>\n",
       "      <td>38.89</td>\n",
       "      <td>8.45</td>\n",
       "      <td>42.45</td>\n",
       "      <td>7.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>75.110</td>\n",
       "      <td>38.80</td>\n",
       "      <td>8.45</td>\n",
       "      <td>42.50</td>\n",
       "      <td>7.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>74.876</td>\n",
       "      <td>38.19</td>\n",
       "      <td>8.26</td>\n",
       "      <td>41.93</td>\n",
       "      <td>7.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>74.804</td>\n",
       "      <td>38.61</td>\n",
       "      <td>8.32</td>\n",
       "      <td>42.04</td>\n",
       "      <td>7.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>74.894</td>\n",
       "      <td>38.55</td>\n",
       "      <td>8.83</td>\n",
       "      <td>42.11</td>\n",
       "      <td>7.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>75.074</td>\n",
       "      <td>39.34</td>\n",
       "      <td>8.56</td>\n",
       "      <td>42.73</td>\n",
       "      <td>7.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>75.110</td>\n",
       "      <td>38.67</td>\n",
       "      <td>8.43</td>\n",
       "      <td>42.48</td>\n",
       "      <td>7.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>74.516</td>\n",
       "      <td>38.64</td>\n",
       "      <td>8.27</td>\n",
       "      <td>41.76</td>\n",
       "      <td>7.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>75.074</td>\n",
       "      <td>38.43</td>\n",
       "      <td>8.36</td>\n",
       "      <td>42.28</td>\n",
       "      <td>7.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>75.146</td>\n",
       "      <td>39.14</td>\n",
       "      <td>8.52</td>\n",
       "      <td>42.67</td>\n",
       "      <td>7.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>75.074</td>\n",
       "      <td>42.52</td>\n",
       "      <td>8.47</td>\n",
       "      <td>42.52</td>\n",
       "      <td>7.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>75.146</td>\n",
       "      <td>38.07</td>\n",
       "      <td>8.30</td>\n",
       "      <td>42.19</td>\n",
       "      <td>7.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>75.182</td>\n",
       "      <td>39.89</td>\n",
       "      <td>8.70</td>\n",
       "      <td>43.09</td>\n",
       "      <td>7.41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Count  Which MAU  Temperature (°F)  Humidity (%)   Density (g/m^3)  \\\n",
       "0       1          1            75.038         38.79              8.40   \n",
       "1       2          2            74.984         38.16              8.28   \n",
       "2       3          3            75.092         39.94              8.68   \n",
       "3       4          4            75.020         39.08              8.48   \n",
       "4       5          5            75.038         38.89              8.45   \n",
       "5       6          9            75.110         38.80              8.45   \n",
       "6       7          1            74.876         38.19              8.26   \n",
       "7       8          1            74.804         38.61              8.32   \n",
       "8       9          1            74.894         38.55              8.83   \n",
       "9      10          3            75.074         39.34              8.56   \n",
       "10     11          4            75.110         38.67              8.43   \n",
       "11     12          1            74.516         38.64              8.27   \n",
       "12     13          2            75.074         38.43              8.36   \n",
       "13     14          3            75.146         39.14              8.52   \n",
       "14     15          4            75.074         42.52              8.47   \n",
       "15     16          5            75.146         38.07              8.30   \n",
       "16     17          6            75.182         39.89              8.70   \n",
       "\n",
       "     Enthalpy, h (kJ/kg)   x (g/kg)  \n",
       "0                  42.38       7.17  \n",
       "1                  42.05       7.04  \n",
       "2                  42.99       7.40  \n",
       "3                  42.52       2.22  \n",
       "4                  42.45       7.19  \n",
       "5                  42.50       7.19  \n",
       "6                  41.93       7.03  \n",
       "7                  42.04       7.08  \n",
       "8                  42.11       7.59  \n",
       "9                  42.73       7.28  \n",
       "10                 42.48       7.17  \n",
       "11                 41.76       7.12  \n",
       "12                 42.28       7.11  \n",
       "13                 42.67       7.26  \n",
       "14                 42.52       7.21  \n",
       "15                 42.19       7.06  \n",
       "16                 43.09       7.41  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load exit data\n",
    "ori_data_exit = pd.read_csv('/Users/hsiaopingni/Desktop/Hsiao-Ping PhD/Data/MAU_paper/AI_model_MAU_Exit.csv', encoding='unicode_escape')\n",
    "#ori_data_exit=pd.read_csv(r'C:\\Users\\Hsiao-ping.ni\\ASU Dropbox\\Hsiao-Ping Ni\\PhD\\Data\\3rd paper- MAU\\AI_model_MAU_Exit.csv', encoding='unicode_escape')\n",
    "#ori_data_exit=pd.read_csv(r'C:\\Users\\nick8\\ASU Dropbox\\Hsiao-Ping Ni\\PhD\\Data\\3rd paper- MAU\\AI_model_MAU_Exit.csv', encoding='unicode_escape')\n",
    "ori_data_exit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3afbdc1e",
   "metadata": {},
   "source": [
    "### Original test datasets for MAU exit (3 counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3c5ef1a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "      <th>Which MAU</th>\n",
       "      <th>Temperature (°F)</th>\n",
       "      <th>Humidity (%)</th>\n",
       "      <th>Density (g/m^3)</th>\n",
       "      <th>Enthalpy, h (kJ/kg)</th>\n",
       "      <th>x (g/kg)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>75.110</td>\n",
       "      <td>38.80</td>\n",
       "      <td>8.45</td>\n",
       "      <td>42.50</td>\n",
       "      <td>7.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>75.074</td>\n",
       "      <td>38.43</td>\n",
       "      <td>8.36</td>\n",
       "      <td>42.28</td>\n",
       "      <td>7.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>75.146</td>\n",
       "      <td>38.07</td>\n",
       "      <td>8.30</td>\n",
       "      <td>42.19</td>\n",
       "      <td>7.06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Count  Which MAU  Temperature (°F)  Humidity (%)   Density (g/m^3)  \\\n",
       "5       6          9            75.110         38.80              8.45   \n",
       "12     13          2            75.074         38.43              8.36   \n",
       "15     16          5            75.146         38.07              8.30   \n",
       "\n",
       "     Enthalpy, h (kJ/kg)   x (g/kg)  \n",
       "5                  42.50       7.19  \n",
       "12                 42.28       7.11  \n",
       "15                 42.19       7.06  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ori_test_exit = ori_data_exit.iloc[[5, 12, 15]]\n",
    "ori_test_exit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a918516",
   "metadata": {},
   "source": [
    "### Train and test features, and train and test labels for MAU entrance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ed65d195",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_entrance = train_dataset_entrance.copy()\n",
    "test_features_entrance = test_dataset_entrance.copy()\n",
    "train_labels_entrance = train_features_entrance.pop('Temperature (Â°F)')\n",
    "test_labels_entrance = test_features_entrance.pop('Temperature (Â°F)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aa663570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original\n",
    "ori_test_features_entrance = ori_test_entrance.copy()\n",
    "ori_test_labels_entrance = ori_test_features_entrance.pop('Temperature (°F)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e2479641",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Humidity (%)</th>\n",
       "      <th>Density (g/m^3)</th>\n",
       "      <th>Enthalpy, h (kJ/kg)</th>\n",
       "      <th>x (g/kg)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>20.63</td>\n",
       "      <td>6.618528</td>\n",
       "      <td>45.665051</td>\n",
       "      <td>5.661910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>7.95</td>\n",
       "      <td>2.391320</td>\n",
       "      <td>36.279681</td>\n",
       "      <td>2.227304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>31.99</td>\n",
       "      <td>6.753991</td>\n",
       "      <td>38.115914</td>\n",
       "      <td>5.658066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>20.05</td>\n",
       "      <td>6.582001</td>\n",
       "      <td>46.277658</td>\n",
       "      <td>5.752278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>13.32</td>\n",
       "      <td>4.397792</td>\n",
       "      <td>41.572672</td>\n",
       "      <td>3.736026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>12.46</td>\n",
       "      <td>3.984378</td>\n",
       "      <td>40.290405</td>\n",
       "      <td>3.480314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>13.32</td>\n",
       "      <td>4.393553</td>\n",
       "      <td>41.531900</td>\n",
       "      <td>3.807427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>7.00</td>\n",
       "      <td>2.420199</td>\n",
       "      <td>38.353314</td>\n",
       "      <td>2.127184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>7.57</td>\n",
       "      <td>2.741618</td>\n",
       "      <td>38.748406</td>\n",
       "      <td>2.348994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>7.64</td>\n",
       "      <td>2.786365</td>\n",
       "      <td>38.712086</td>\n",
       "      <td>2.349042</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>272 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Humidity (%)  Density (g/m^3)  Enthalpy, h (kJ/kg)  x (g/kg)\n",
       "225         20.63         6.618528            45.665051  5.661910\n",
       "271          7.95         2.391320            36.279681  2.227304\n",
       "204         31.99         6.753991            38.115914  5.658066\n",
       "274         20.05         6.582001            46.277658  5.752278\n",
       "299         13.32         4.397792            41.572672  3.736026\n",
       "..            ...              ...                  ...       ...\n",
       "143         12.46         3.984378            40.290405  3.480314\n",
       "180         13.32         4.393553            41.531900  3.807427\n",
       "131          7.00         2.420199            38.353314  2.127184\n",
       "302          7.57         2.741618            38.748406  2.348994\n",
       "338          7.64         2.786365            38.712086  2.349042\n",
       "\n",
       "[272 rows x 4 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features_entrance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c1a40da4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Humidity (%)</th>\n",
       "      <th>Density (g/m^3)</th>\n",
       "      <th>Enthalpy, h (kJ/kg)</th>\n",
       "      <th>x (g/kg)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>13.09</td>\n",
       "      <td>4.401632</td>\n",
       "      <td>42.274344</td>\n",
       "      <td>3.860325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>14.32</td>\n",
       "      <td>4.370370</td>\n",
       "      <td>39.863345</td>\n",
       "      <td>3.698648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>26.62</td>\n",
       "      <td>6.381562</td>\n",
       "      <td>40.238158</td>\n",
       "      <td>3.941589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>7.97</td>\n",
       "      <td>2.692270</td>\n",
       "      <td>38.022185</td>\n",
       "      <td>2.276832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>7.64</td>\n",
       "      <td>2.736127</td>\n",
       "      <td>38.803568</td>\n",
       "      <td>2.363204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>13.09</td>\n",
       "      <td>4.376609</td>\n",
       "      <td>42.282407</td>\n",
       "      <td>3.763491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>31.99</td>\n",
       "      <td>6.773940</td>\n",
       "      <td>38.008877</td>\n",
       "      <td>5.750958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>20.05</td>\n",
       "      <td>6.670464</td>\n",
       "      <td>46.247404</td>\n",
       "      <td>5.737961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>20.63</td>\n",
       "      <td>6.495229</td>\n",
       "      <td>45.571644</td>\n",
       "      <td>5.664049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>29.08</td>\n",
       "      <td>6.345534</td>\n",
       "      <td>38.280127</td>\n",
       "      <td>5.458094</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Humidity (%)  Density (g/m^3)  Enthalpy, h (kJ/kg)  x (g/kg)\n",
       "9           13.09         4.401632            42.274344  3.860325\n",
       "25          14.32         4.370370            39.863345  3.698648\n",
       "28          26.62         6.381562            40.238158  3.941589\n",
       "31           7.97         2.692270            38.022185  2.276832\n",
       "32           7.64         2.736127            38.803568  2.363204\n",
       "..            ...              ...                  ...       ...\n",
       "315         13.09         4.376609            42.282407  3.763491\n",
       "323         31.99         6.773940            38.008877  5.750958\n",
       "325         20.05         6.670464            46.247404  5.737961\n",
       "327         20.63         6.495229            45.571644  5.664049\n",
       "328         29.08         6.345534            38.280127  5.458094\n",
       "\n",
       "[68 rows x 4 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_features_entrance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f6eba111",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Humidity (%)</th>\n",
       "      <th>Density (g/m^3)</th>\n",
       "      <th>Enthalpy, h (kJ/kg)</th>\n",
       "      <th>x (g/kg)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>29.08</td>\n",
       "      <td>6.44</td>\n",
       "      <td>38.33</td>\n",
       "      <td>5.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7.00</td>\n",
       "      <td>2.42</td>\n",
       "      <td>38.36</td>\n",
       "      <td>2.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7.64</td>\n",
       "      <td>2.76</td>\n",
       "      <td>38.77</td>\n",
       "      <td>2.32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Humidity (%)  Density (g/m^3)  Enthalpy, h (kJ/kg)  x (g/kg)\n",
       "5          29.08             6.44                38.33      5.46\n",
       "12          7.00             2.42                38.36      2.10\n",
       "15          7.64             2.76                38.77      2.32"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ori_test_features_entrance = ori_test_features_entrance.drop(['Count','Which MAU'], axis=1)\n",
    "ori_test_features_entrance \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "04f9d966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "225    87.330\n",
       "271    86.720\n",
       "204    73.990\n",
       "274    88.410\n",
       "299    88.720\n",
       "        ...  \n",
       "143    87.760\n",
       "180    88.720\n",
       "131    90.770\n",
       "302    90.734\n",
       "338    90.194\n",
       "Name: Temperature (Â°F), Length: 272, dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels_entrance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fd346d9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9      89.650\n",
       "25     85.660\n",
       "28     78.570\n",
       "31     88.988\n",
       "32     90.194\n",
       "        ...  \n",
       "315    89.650\n",
       "323    73.990\n",
       "325    88.410\n",
       "327    87.330\n",
       "328    75.540\n",
       "Name: Temperature (Â°F), Length: 68, dtype: float64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels_entrance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd02152",
   "metadata": {},
   "source": [
    "### Train and test features, and train and test labels for MAU exit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a99eca75",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_exit = train_dataset_exit.copy()\n",
    "test_features_exit = test_dataset_exit.copy()\n",
    "train_labels_exit = train_features_exit.pop('Temperature (Â°F)')\n",
    "test_labels_exit = test_features_exit.pop('Temperature (Â°F)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "093d6925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original\n",
    "ori_test_features_exit = ori_test_exit.copy()\n",
    "ori_test_labels_exit = ori_test_features_exit.pop('Temperature (°F)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0ba7c11c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Humidity (%)</th>\n",
       "      <th>Density (g/m^3)</th>\n",
       "      <th>Enthalpy, h (kJ/kg)</th>\n",
       "      <th>x (g/kg)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>38.89</td>\n",
       "      <td>8.476378</td>\n",
       "      <td>42.396510</td>\n",
       "      <td>7.205999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>39.89</td>\n",
       "      <td>8.665360</td>\n",
       "      <td>42.979357</td>\n",
       "      <td>7.455157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>38.79</td>\n",
       "      <td>8.446582</td>\n",
       "      <td>42.355040</td>\n",
       "      <td>7.187971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>39.94</td>\n",
       "      <td>8.619342</td>\n",
       "      <td>42.970125</td>\n",
       "      <td>7.338046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>38.67</td>\n",
       "      <td>8.442880</td>\n",
       "      <td>42.501051</td>\n",
       "      <td>7.175249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>38.61</td>\n",
       "      <td>8.352576</td>\n",
       "      <td>42.012780</td>\n",
       "      <td>7.118046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>38.67</td>\n",
       "      <td>8.446570</td>\n",
       "      <td>42.555351</td>\n",
       "      <td>7.167860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>38.43</td>\n",
       "      <td>8.421875</td>\n",
       "      <td>42.249949</td>\n",
       "      <td>7.108325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>39.14</td>\n",
       "      <td>8.512689</td>\n",
       "      <td>42.774177</td>\n",
       "      <td>7.149740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>38.07</td>\n",
       "      <td>8.328769</td>\n",
       "      <td>42.158082</td>\n",
       "      <td>6.980890</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>272 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Humidity (%)  Density (g/m^3)  Enthalpy, h (kJ/kg)  x (g/kg)\n",
       "225         38.89         8.476378            42.396510  7.205999\n",
       "271         39.89         8.665360            42.979357  7.455157\n",
       "204         38.79         8.446582            42.355040  7.187971\n",
       "274         39.94         8.619342            42.970125  7.338046\n",
       "299         38.67         8.442880            42.501051  7.175249\n",
       "..            ...              ...                  ...       ...\n",
       "143         38.61         8.352576            42.012780  7.118046\n",
       "180         38.67         8.446570            42.555351  7.167860\n",
       "131         38.43         8.421875            42.249949  7.108325\n",
       "302         39.14         8.512689            42.774177  7.149740\n",
       "338         38.07         8.328769            42.158082  6.980890\n",
       "\n",
       "[272 rows x 4 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features_exit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "57ab8ada",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Humidity (%)</th>\n",
       "      <th>Density (g/m^3)</th>\n",
       "      <th>Enthalpy, h (kJ/kg)</th>\n",
       "      <th>x (g/kg)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>39.34</td>\n",
       "      <td>8.556251</td>\n",
       "      <td>42.768485</td>\n",
       "      <td>7.364775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>38.55</td>\n",
       "      <td>8.809186</td>\n",
       "      <td>42.199336</td>\n",
       "      <td>7.506645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>38.64</td>\n",
       "      <td>8.158391</td>\n",
       "      <td>41.736814</td>\n",
       "      <td>7.083349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>42.52</td>\n",
       "      <td>8.433321</td>\n",
       "      <td>42.531764</td>\n",
       "      <td>7.190104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>38.07</td>\n",
       "      <td>8.268372</td>\n",
       "      <td>42.181495</td>\n",
       "      <td>7.027293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>39.34</td>\n",
       "      <td>8.617384</td>\n",
       "      <td>42.765265</td>\n",
       "      <td>7.186293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>38.79</td>\n",
       "      <td>8.337885</td>\n",
       "      <td>42.368529</td>\n",
       "      <td>7.248409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>39.94</td>\n",
       "      <td>8.669885</td>\n",
       "      <td>42.921554</td>\n",
       "      <td>7.434315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>38.89</td>\n",
       "      <td>8.463199</td>\n",
       "      <td>42.462564</td>\n",
       "      <td>7.199611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>38.80</td>\n",
       "      <td>8.423292</td>\n",
       "      <td>42.530855</td>\n",
       "      <td>7.111604</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Humidity (%)  Density (g/m^3)  Enthalpy, h (kJ/kg)  x (g/kg)\n",
       "9           39.34         8.556251            42.768485  7.364775\n",
       "25          38.55         8.809186            42.199336  7.506645\n",
       "28          38.64         8.158391            41.736814  7.083349\n",
       "31          42.52         8.433321            42.531764  7.190104\n",
       "32          38.07         8.268372            42.181495  7.027293\n",
       "..            ...              ...                  ...       ...\n",
       "315         39.34         8.617384            42.765265  7.186293\n",
       "323         38.79         8.337885            42.368529  7.248409\n",
       "325         39.94         8.669885            42.921554  7.434315\n",
       "327         38.89         8.463199            42.462564  7.199611\n",
       "328         38.80         8.423292            42.530855  7.111604\n",
       "\n",
       "[68 rows x 4 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_features_exit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "50ca2e30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Humidity (%)</th>\n",
       "      <th>Density (g/m^3)</th>\n",
       "      <th>Enthalpy, h (kJ/kg)</th>\n",
       "      <th>x (g/kg)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>38.80</td>\n",
       "      <td>8.45</td>\n",
       "      <td>42.50</td>\n",
       "      <td>7.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>38.43</td>\n",
       "      <td>8.36</td>\n",
       "      <td>42.28</td>\n",
       "      <td>7.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>38.07</td>\n",
       "      <td>8.30</td>\n",
       "      <td>42.19</td>\n",
       "      <td>7.06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Humidity (%)   Density (g/m^3)   Enthalpy, h (kJ/kg)   x (g/kg)\n",
       "5          38.80              8.45                 42.50       7.19\n",
       "12         38.43              8.36                 42.28       7.11\n",
       "15         38.07              8.30                 42.19       7.06"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ori_test_features_exit = ori_test_features_exit.drop(['Count','Which MAU'], axis=1)\n",
    "ori_test_features_exit  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0ad33b2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "225    75.038\n",
       "271    75.182\n",
       "204    75.038\n",
       "274    75.092\n",
       "299    75.110\n",
       "        ...  \n",
       "143    74.804\n",
       "180    75.110\n",
       "131    75.074\n",
       "302    75.146\n",
       "338    75.146\n",
       "Name: Temperature (Â°F), Length: 272, dtype: float64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels_exit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7da236b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9      75.074\n",
       "25     74.894\n",
       "28     74.516\n",
       "31     75.074\n",
       "32     75.146\n",
       "        ...  \n",
       "315    75.074\n",
       "323    75.038\n",
       "325    75.092\n",
       "327    75.038\n",
       "328    75.110\n",
       "Name: Temperature (Â°F), Length: 68, dtype: float64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels_exit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3b1ae874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5     75.110\n",
       "12    75.074\n",
       "15    75.146\n",
       "Name: Temperature (°F), dtype: float64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ori_test_labels_exit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e07e6e9",
   "metadata": {},
   "source": [
    "## Regression with a deep neural network (DNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db869e0a",
   "metadata": {},
   "source": [
    "Here, you will implement a multiple-input DNN model.\n",
    "\n",
    "The name \"hidden\" here just means not directly connected to the inputs or outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a282793",
   "metadata": {},
   "source": [
    "This model will contain a few layers.\n",
    "\n",
    "* The dense input layer.\n",
    "* Two hidden, non-linear, `Dense` layers with the ReLU (`relu`) activation function nonlinearity.\n",
    "* A linear `Dense` single-output layer.\n",
    "\n",
    "The `compile` method is included in the `build_and_compile_model` function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f8e0518d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_and_compile_model():\n",
    "  model = keras.Sequential([\n",
    "      layers.Dense(4,  kernel_initializer='normal', input_dim = train_features_entrance.shape[1], activation='relu'),\n",
    "      layers.Dense(64,  kernel_initializer='normal', activation='relu'),\n",
    "      layers.Dense(64,  kernel_initializer='normal', activation='relu'),\n",
    "      layers.Dense(1)])\n",
    "\n",
    "  model.compile(loss='mean_absolute_error',\n",
    "                optimizer=tf.keras.optimizers.Adam(0.001))\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a2a043ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment with different configurations\n",
    "#configs = [\n",
    " #   {\"layers\": 2, \"neurons_per_layer\": [32, 16]},\n",
    " #   {\"layers\": 3, \"neurons_per_layer\": [64, 32, 16]},\n",
    " #   {\"layers\": 4, \"neurons_per_layer\": [128, 64, 32, 16]},\n",
    " #   {\"layers\": 2, \"neurons_per_layer\": [64, 64]},\n",
    " #   {\"layers\": 3, \"neurons_per_layer\": [128, 64, 32]}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1449909e",
   "metadata": {},
   "source": [
    "### Regression using a DNN and multiple inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0d03c2cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 4)                 20        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                320       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,565\n",
      "Trainable params: 4,565\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x16b9a5ed0>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_model = build_and_compile_model()\n",
    "dnn_model.summary()\n",
    "dnn_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a155532",
   "metadata": {},
   "source": [
    "This table summarizes the architecture of the neural network model. The table is divided into several columns detailing the layers in the model, their types, output shapes, and the number of parameters (weights and biases) each layer has. Here's a breakdown of the table:\n",
    "\n",
    "Layer: Indicates the name and type of each layer in the model. The model consists of a normalization layer followed by three dense (fully connected) layers.\n",
    "\n",
    "Output Shape: The shape of the output for each layer. The notation (None, x) indicates that the batch size is variable (denoted by None), and x is the dimensionality of the output from that layer.\n",
    "\n",
    "The normalization layer takes an input with 9 features ((None, 9)).\n",
    "The first dense layer outputs 64 units ((None, 64)).\n",
    "The second dense layer, identical to the first, also outputs 64 units.\n",
    "The final dense layer outputs a single unit ((None, 1)), corresponding to the model's prediction.\n",
    "\n",
    "Param #: Lists the number of parameters in each layer, which are learned during the training process.\n",
    "\n",
    "The normalization layer has 19 parameters, which are not trainable. These parameters might include statistics like mean and variance for each input feature used for data normalization.\n",
    "The first dense layer has 640 parameters, calculated as (9 input features * 64 output units) + 64 bias terms.\n",
    "The second dense layer has 4160 parameters, derived from (64 input units * 64 output units) + 64 bias terms.\n",
    "The final dense layer has 65 parameters, from (64 input units * 1 output unit) + 1 bias term.\n",
    "\n",
    "Total params: The total number of parameters in the model, summing to 4,884. This includes both trainable and non-trainable parameters.\n",
    "\n",
    "Trainable params: The number of parameters that will be updated during training, totaling 4,865. This excludes the normalization layer's statistics.\n",
    "\n",
    "Non-trainable params: Parameters that do not get updated during the training process, in this case, 19, likely related to the normalization layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3793b510",
   "metadata": {},
   "source": [
    "\n",
    "Train the model with Keras `Model.fit`.\n",
    "\n",
    "The validation_split=0.2 argument in the fit method of the Keras API indicates that 20% of the training data should be set aside for validation. The model will train on 80% of the data and evaluate its performance on the remaining 20% to monitor for issues like overfitting. This validation set is not used to update the model's weights; it's only for evaluation purposes to give an estimate of the model's performance on unseen data.\n",
    "\n",
    "The verbose parameter controls how much information the training process outputs to the console. Setting verbose=0 means that you won’t see any logging output during training, which can be useful if you don't need to track the training process in detail and want to avoid cluttering your console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "66eccda2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-24 19:38:17.493676: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.3 s, sys: 388 ms, total: 1.69 s\n",
      "Wall time: 1.28 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history_entrance = dnn_model.fit(\n",
    "    train_features_entrance,\n",
    "    train_labels_entrance,\n",
    "    validation_split=0.2,\n",
    "    verbose=0, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "73ea7bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.02 s, sys: 298 ms, total: 1.32 s\n",
      "Wall time: 960 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history_exit = dnn_model.fit(\n",
    "    train_features_exit,\n",
    "    train_labels_exit,\n",
    "    validation_split=0.2,\n",
    "    verbose=0, epochs=100) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d46c66",
   "metadata": {},
   "source": [
    "### Visualize the model's training progress in DNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d182f5f",
   "metadata": {},
   "source": [
    "Visualize the model's training progress using the stats stored in the `history` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "39113f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(history_entrance):\n",
    "  plt.plot(history_entrance.history['loss'], label='Training loss')\n",
    "  plt.plot(history_entrance.history['val_loss'], label='Validation loss')\n",
    "  plt.ylim([0, 100])\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('Error [Temperature (°F)]')\n",
    "  plt.title('Training progress in DNN model for MAU entrance')\n",
    "  plt.legend()\n",
    "  plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b62084fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss(history_entrance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4657bd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(history_exit):\n",
    "  plt.plot(history_exit.history['loss'], label='Training loss')\n",
    "  plt.plot(history_exit.history['val_loss'], label='Validation loss')\n",
    "  plt.ylim([0, 4])\n",
    "  plt.xlim([0, 100])\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('Error [Temperature (°F)]')\n",
    "  plt.title('Training progress in DNN model for MAU exit')\n",
    "  plt.legend()\n",
    "  plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "89c506f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plot_loss(history_exit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298aa32c",
   "metadata": {},
   "source": [
    "### Collect the results on the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b205b1",
   "metadata": {},
   "source": [
    "#### MAU entrance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f4dbd181",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68, 4)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_features_entrance = np.asarray(test_features_entrance).astype(np.float32)\n",
    "test_features_entrance.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "fa2521ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dnn_model': 2.8926711082458496}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results_entrance = {}\n",
    "test_results_entrance['dnn_model'] = dnn_model.evaluate(test_features_entrance, test_labels_entrance, verbose=0)\n",
    "test_results_entrance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f602ce39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 4)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#original\n",
    "ori_test_features_entrance = np.asarray(ori_test_features_entrance).astype(np.float32)\n",
    "ori_test_features_entrance.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "cedef9fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dnn_model': 3.8797504901885986}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ori_test_results_entrance = {}\n",
    "ori_test_results_entrance['dnn_model'] = dnn_model.evaluate(ori_test_features_entrance, ori_test_labels_entrance, verbose=0)\n",
    "ori_test_results_entrance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e20fa7",
   "metadata": {},
   "source": [
    "#### MAU exit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c1d5a3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features_exit = np.asarray(test_features_exit).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1d5d13e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dnn_model': 0.3804032802581787}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results_exit = {}\n",
    "test_results_exit['dnn_model'] = dnn_model.evaluate(test_features_exit, test_labels_exit, verbose=0)\n",
    "test_results_exit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0f318eca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 4)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#original\n",
    "ori_test_features_exit = np.asarray(ori_test_features_exit).astype(np.float32)\n",
    "ori_test_features_exit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9ebc99ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dnn_model': 0.2677103579044342}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ori_test_results_exit = {}\n",
    "ori_test_results_exit['dnn_model'] = dnn_model.evaluate(ori_test_features_exit, ori_test_labels_exit, verbose=0)\n",
    "ori_test_results_exit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09606ee2",
   "metadata": {},
   "source": [
    "## Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "35c1fff3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean absolute error [Temperature]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dnn_model</th>\n",
       "      <td>2.892671</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Mean absolute error [Temperature]\n",
       "dnn_model                           2.892671"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(test_results_entrance, index=['Mean absolute error [Temperature]']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "899a334a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean absolute error [Temperature]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dnn_model</th>\n",
       "      <td>3.87975</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Mean absolute error [Temperature]\n",
       "dnn_model                            3.87975"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# original\n",
    "pd.DataFrame(ori_test_results_entrance, index=['Mean absolute error [Temperature]']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4ad1c10f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean absolute error [Temperature]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dnn_model</th>\n",
       "      <td>0.380403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Mean absolute error [Temperature]\n",
       "dnn_model                           0.380403"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(test_results_exit, index=['Mean absolute error [Temperature]']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ed39b514",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean absolute error [Temperature]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dnn_model</th>\n",
       "      <td>0.26771</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Mean absolute error [Temperature]\n",
       "dnn_model                            0.26771"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#original\n",
    "pd.DataFrame(ori_test_results_exit, index=['Mean absolute error [Temperature]']).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5853fab4",
   "metadata": {},
   "source": [
    "### Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "39d7f904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 515us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([89.162, 83.98 , 77.864, 84.459, 86.081, 90.614, 73.121, 84.001,\n",
       "       86.198, 92.047, 80.114, 92.093, 90.873, 84.333, 80.882, 92.117,\n",
       "       90.421, 79.807, 84.5  , 90.446, 86.09 , 85.903, 71.503, 92.308,\n",
       "       84.264, 89.109, 78.009, 86.009, 87.407, 85.808, 92.224, 90.597,\n",
       "       85.95 , 86.137, 86.055, 73.172, 79.849, 83.923, 87.545, 85.933,\n",
       "       81.076, 85.942, 90.871, 73.141, 79.822, 86.26 , 92.345, 86.147,\n",
       "       87.853, 85.663, 90.526, 73.086, 86.125, 80.949, 90.78 , 90.546,\n",
       "       90.702, 89.001, 77.846, 90.586, 73.233, 85.832, 83.986, 89.197,\n",
       "       71.004, 92.076, 90.673, 73.105], dtype=float32)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions_entrance = dnn_model.predict(test_features_entrance).flatten()\n",
    "test_predictions_entrance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2f5f193f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 6ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([73.119, 85.753, 85.993], dtype=float32)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# original\n",
    "ori_test_predictions_entrance = dnn_model.predict(ori_test_features_entrance).flatten()\n",
    "ori_test_predictions_entrance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8f24baf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 475us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([75.713, 74.71 , 74.336, 74.043, 75.339, 75.306, 75.626, 74.495,\n",
       "       75.495, 75.765, 74.798, 75.729, 75.417, 73.923, 75.87 , 75.784,\n",
       "       75.316, 74.942, 74.136, 75.26 , 75.789, 75.223, 75.355, 75.741,\n",
       "       74.547, 75.448, 74.279, 75.175, 75.519, 75.289, 75.846, 75.325,\n",
       "       74.821, 75.662, 75.336, 75.489, 74.703, 74.59 , 75.569, 75.253,\n",
       "       75.852, 74.707, 75.291, 75.618, 74.743, 75.665, 76.029, 74.69 ,\n",
       "       75.388, 75.124, 74.856, 75.504, 75.533, 75.863, 75.098, 75.267,\n",
       "       75.335, 75.695, 74.349, 74.934, 75.419, 74.655, 74.486, 75.648,\n",
       "       75.35 , 75.665, 75.38 , 75.583], dtype=float32)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions_exit = dnn_model.predict(test_features_exit).flatten()\n",
    "test_predictions_exit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6f34069f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 6ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([75.502, 75.303, 75.328], dtype=float32)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# original\n",
    "ori_test_predictions_exit = dnn_model.predict(ori_test_features_exit).flatten()\n",
    "ori_test_predictions_exit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "27f0962c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9     -0.487814\n",
       "25    -1.679867\n",
       "28    -0.706238\n",
       "31    -4.529428\n",
       "32    -4.113189\n",
       "         ...   \n",
       "315   -0.452544\n",
       "323   -2.985567\n",
       "325    3.666057\n",
       "327    3.342821\n",
       "328   -2.435248\n",
       "Name: Temperature (Â°F), Length: 68, dtype: float64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_entrance = test_predictions_entrance - test_labels_entrance\n",
    "error_entrance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "eb91e834",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    -2.421454\n",
       "12   -5.016979\n",
       "15   -4.200821\n",
       "Name: Temperature (°F), dtype: float64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# original\n",
    "ori_error_entrance = ori_test_predictions_entrance - ori_test_labels_entrance\n",
    "ori_error_entrance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c6df03d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(error_entrance, bins=25)\n",
    "plt.xlabel('Prediction Error [Temperature]')\n",
    "_ = plt.ylabel('Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "458ce87c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# original\n",
    "plt.hist(ori_error_entrance, bins=25)\n",
    "plt.xlabel('Prediction Error [Temperature]')\n",
    "_ = plt.ylabel('Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "61995131",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9      0.638753\n",
       "25    -0.183856\n",
       "28    -0.180459\n",
       "31    -1.030970\n",
       "32     0.192638\n",
       "         ...   \n",
       "315    0.573820\n",
       "323    0.312288\n",
       "325    0.572810\n",
       "327    0.342264\n",
       "328    0.473450\n",
       "Name: Temperature (Â°F), Length: 68, dtype: float64"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_exit = test_predictions_exit - test_labels_exit\n",
    "error_exit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f708ba6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5     0.391770\n",
       "12    0.229230\n",
       "15    0.182133\n",
       "Name: Temperature (°F), dtype: float64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# original\n",
    "ori_error_exit = ori_test_predictions_exit - ori_test_labels_exit\n",
    "ori_error_exit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6066fedc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(error_exit, bins=25)\n",
    "plt.xlabel('Prediction Error [Temperature]')\n",
    "_ = plt.ylabel('Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "10adf226",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# original\n",
    "plt.hist(ori_error_exit, bins=25)\n",
    "plt.xlabel('Prediction Error [Temperature]')\n",
    "_ = plt.ylabel('Count')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fa24a0",
   "metadata": {},
   "source": [
    "#### Average error (AE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8c90bb",
   "metadata": {},
   "source": [
    "AE: Provide a measure of bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d98de95a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average error: -0.9607871793859146\n"
     ]
    }
   ],
   "source": [
    "average_error_entrance = np.mean(error_entrance)\n",
    "print(\"Average error:\", average_error_entrance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "37a5044d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average error: -3.879751302083335\n"
     ]
    }
   ],
   "source": [
    "# original\n",
    "ori_average_error_entrance = np.mean(ori_error_entrance)\n",
    "print(\"Average error:\", ori_average_error_entrance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f3634dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average error: 0.1960481845631319\n"
     ]
    }
   ],
   "source": [
    "average_error_exit = np.mean(error_exit)\n",
    "print(\"Average error:\", average_error_exit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "41a7c39d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average error: 0.26771097819010475\n"
     ]
    }
   ],
   "source": [
    "# original\n",
    "ori_average_error_exit = np.mean(ori_error_exit)\n",
    "print(\"Average error:\", ori_average_error_exit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58aee21",
   "metadata": {},
   "source": [
    "#### Mean squared error (MSE) and mean absolute error (MAE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef604f2d",
   "metadata": {},
   "source": [
    "MSE: Penalize significant errors more heavily \\\n",
    "MAE: Provide a measure of the average magnitude of errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "33b9d2af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 10.570412913778632\n",
      "Mean Absolute Error: 2.8926718283260575\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mse = mean_squared_error(test_labels_entrance, test_predictions_entrance)\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "mae = mean_absolute_error(test_labels_entrance, test_predictions_entrance)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Mean Absolute Error:\", mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e947392e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 16.22680399670827\n",
      "Mean Absolute Error: 3.879751302083335\n"
     ]
    }
   ],
   "source": [
    "# original\n",
    "ori_mse = mean_squared_error(ori_test_labels_entrance, ori_test_predictions_entrance)\n",
    "ori_mae = mean_absolute_error(ori_test_labels_entrance, ori_test_predictions_entrance)\n",
    "print(\"Mean Squared Error:\", ori_mse)\n",
    "print(\"Mean Absolute Error:\", ori_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "aa516341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.20891283522648949\n",
      "Mean Absolute Error: 0.38040327094583093\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mse = mean_squared_error(test_labels_exit, test_predictions_exit)\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "mae = mean_absolute_error(test_labels_exit, test_predictions_exit)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Mean Absolute Error:\", mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "aeb42a9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.07973418891678537\n",
      "Mean Absolute Error: 0.26771097819010475\n"
     ]
    }
   ],
   "source": [
    "# original\n",
    "ori_mse = mean_squared_error(ori_test_labels_exit, ori_test_predictions_exit)\n",
    "ori_mae = mean_absolute_error(ori_test_labels_exit, ori_test_predictions_exit)\n",
    "print(\"Mean Squared Error:\", ori_mse)\n",
    "print(\"Mean Absolute Error:\", ori_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "a8fb7913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE: 3.34%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def mean_absolute_percentage_error(y_actual, y_pred):\n",
    "    y_actual, y_pred = np.array(y_actual), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_actual - y_pred) / y_actual)) * 100\n",
    "\n",
    "mape = mean_absolute_percentage_error(test_labels_entrance, test_predictions_entrance)\n",
    "print(f'MAPE: {mape:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "8f7472ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE: 4.46%\n"
     ]
    }
   ],
   "source": [
    "# original\n",
    "mape = mean_absolute_percentage_error(ori_test_labels_entrance, ori_test_predictions_entrance)\n",
    "print(f'MAPE: {mape:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "93f5dac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE: 0.51%\n"
     ]
    }
   ],
   "source": [
    "mape = mean_absolute_percentage_error(test_labels_exit, test_predictions_exit)\n",
    "print(f'MAPE: {mape:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b5fe37e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE: 0.36%\n"
     ]
    }
   ],
   "source": [
    "# original\n",
    "mape = mean_absolute_percentage_error(ori_test_labels_exit, ori_test_predictions_exit)\n",
    "print(f'MAPE: {mape:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9fc0352",
   "metadata": {},
   "source": [
    "# Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e412faf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-24 19:38:20,807] A new study created in memory with name: no-name-06697ccd-73dc-4680-b240-7d3b6fb6b20c\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_4119/3630070542.py:42: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:38:23,224] Trial 0 finished with value: 20.393013954162598 and parameters: {'num_layers': 3, 'num_neurons_layer_0': 28, 'num_neurons_layer_1': 20, 'num_neurons_layer_2': 104, 'learning_rate': 0.0005998149387650946, 'activation': 'tanh'}. Best is trial 0 with value: 20.393013954162598.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_4119/3630070542.py:42: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:38:25,664] Trial 1 finished with value: 0.8846242129802704 and parameters: {'num_layers': 4, 'num_neurons_layer_0': 48, 'num_neurons_layer_1': 100, 'num_neurons_layer_2': 40, 'num_neurons_layer_3': 104, 'learning_rate': 0.0009402117506956998, 'activation': 'relu'}. Best is trial 1 with value: 0.8846242129802704.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_4119/3630070542.py:42: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:38:27,933] Trial 2 finished with value: 6.349931418895721 and parameters: {'num_layers': 3, 'num_neurons_layer_0': 16, 'num_neurons_layer_1': 28, 'num_neurons_layer_2': 92, 'learning_rate': 0.0008972565924529848, 'activation': 'tanh'}. Best is trial 1 with value: 0.8846242129802704.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_4119/3630070542.py:42: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:38:30,578] Trial 3 finished with value: 1.041165679693222 and parameters: {'num_layers': 5, 'num_neurons_layer_0': 80, 'num_neurons_layer_1': 76, 'num_neurons_layer_2': 88, 'num_neurons_layer_3': 68, 'num_neurons_layer_4': 24, 'learning_rate': 0.0013940155799191886, 'activation': 'relu'}. Best is trial 1 with value: 0.8846242129802704.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_4119/3630070542.py:42: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:38:32,690] Trial 4 finished with value: 1.3741911053657532 and parameters: {'num_layers': 1, 'num_neurons_layer_0': 108, 'learning_rate': 0.0005970436959403736, 'activation': 'relu'}. Best is trial 1 with value: 0.8846242129802704.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_4119/3630070542.py:42: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:38:35,147] Trial 5 finished with value: 0.7633539140224457 and parameters: {'num_layers': 4, 'num_neurons_layer_0': 20, 'num_neurons_layer_1': 96, 'num_neurons_layer_2': 92, 'num_neurons_layer_3': 76, 'learning_rate': 0.0019698800307703106, 'activation': 'relu'}. Best is trial 5 with value: 0.7633539140224457.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_4119/3630070542.py:42: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:38:37,533] Trial 6 finished with value: 52.60276222229004 and parameters: {'num_layers': 3, 'num_neurons_layer_0': 96, 'num_neurons_layer_1': 100, 'num_neurons_layer_2': 40, 'learning_rate': 0.0007147472296169172, 'activation': 'tanh'}. Best is trial 5 with value: 0.7633539140224457.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_4119/3630070542.py:42: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:38:39,595] Trial 7 finished with value: 3.9390420019626617 and parameters: {'num_layers': 1, 'num_neurons_layer_0': 40, 'learning_rate': 0.00043190437545647097, 'activation': 'relu'}. Best is trial 5 with value: 0.7633539140224457.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_4119/3630070542.py:42: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:38:41,666] Trial 8 finished with value: 55.32628059387207 and parameters: {'num_layers': 1, 'num_neurons_layer_0': 88, 'learning_rate': 0.00026295679299226333, 'activation': 'tanh'}. Best is trial 5 with value: 0.7633539140224457.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_4119/3630070542.py:42: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:38:43,962] Trial 9 finished with value: 35.13973140716553 and parameters: {'num_layers': 2, 'num_neurons_layer_0': 16, 'num_neurons_layer_1': 64, 'learning_rate': 0.000719975484711098, 'activation': 'tanh'}. Best is trial 5 with value: 0.7633539140224457.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_4119/3630070542.py:42: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:38:46,694] Trial 10 finished with value: 2.012504458427429 and parameters: {'num_layers': 5, 'num_neurons_layer_0': 128, 'num_neurons_layer_1': 128, 'num_neurons_layer_2': 124, 'num_neurons_layer_3': 20, 'num_neurons_layer_4': 120, 'learning_rate': 0.004934959141546655, 'activation': 'relu'}. Best is trial 5 with value: 0.7633539140224457.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_4119/3630070542.py:42: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:38:49,137] Trial 11 finished with value: 1.2917988300323486 and parameters: {'num_layers': 4, 'num_neurons_layer_0': 52, 'num_neurons_layer_1': 100, 'num_neurons_layer_2': 44, 'num_neurons_layer_3': 112, 'learning_rate': 0.0023917741024202365, 'activation': 'relu'}. Best is trial 5 with value: 0.7633539140224457.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_4119/3630070542.py:42: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:38:51,559] Trial 12 finished with value: 1.597553163766861 and parameters: {'num_layers': 4, 'num_neurons_layer_0': 60, 'num_neurons_layer_1': 100, 'num_neurons_layer_2': 16, 'num_neurons_layer_3': 104, 'learning_rate': 0.0001135120187739009, 'activation': 'relu'}. Best is trial 5 with value: 0.7633539140224457.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_4119/3630070542.py:42: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:38:54,057] Trial 13 finished with value: 2.211782991886139 and parameters: {'num_layers': 4, 'num_neurons_layer_0': 40, 'num_neurons_layer_1': 128, 'num_neurons_layer_2': 60, 'num_neurons_layer_3': 76, 'learning_rate': 0.008131544367182301, 'activation': 'relu'}. Best is trial 5 with value: 0.7633539140224457.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_4119/3630070542.py:42: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:38:56,559] Trial 14 finished with value: 1.049449861049652 and parameters: {'num_layers': 4, 'num_neurons_layer_0': 64, 'num_neurons_layer_1': 68, 'num_neurons_layer_2': 68, 'num_neurons_layer_3': 76, 'learning_rate': 0.0020757763211361195, 'activation': 'relu'}. Best is trial 5 with value: 0.7633539140224457.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_4119/3630070542.py:42: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:38:59,128] Trial 15 finished with value: 1.5876287817955017 and parameters: {'num_layers': 5, 'num_neurons_layer_0': 40, 'num_neurons_layer_1': 88, 'num_neurons_layer_2': 16, 'num_neurons_layer_3': 128, 'num_neurons_layer_4': 76, 'learning_rate': 0.003705018076956989, 'activation': 'relu'}. Best is trial 5 with value: 0.7633539140224457.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_4119/3630070542.py:42: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:39:01,548] Trial 16 finished with value: 0.5625100433826447 and parameters: {'num_layers': 4, 'num_neurons_layer_0': 28, 'num_neurons_layer_1': 44, 'num_neurons_layer_2': 48, 'num_neurons_layer_3': 88, 'learning_rate': 0.001449090906190974, 'activation': 'relu'}. Best is trial 16 with value: 0.5625100433826447.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_4119/3630070542.py:42: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:39:03,710] Trial 17 finished with value: 0.7661831974983215 and parameters: {'num_layers': 2, 'num_neurons_layer_0': 28, 'num_neurons_layer_1': 44, 'learning_rate': 0.0015994470034274, 'activation': 'relu'}. Best is trial 16 with value: 0.5625100433826447.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_4119/3630070542.py:42: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:39:05,869] Trial 18 finished with value: 1.0716294050216675 and parameters: {'num_layers': 2, 'num_neurons_layer_0': 28, 'num_neurons_layer_1': 48, 'learning_rate': 0.003446866243500057, 'activation': 'relu'}. Best is trial 16 with value: 0.5625100433826447.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_4119/3630070542.py:42: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:39:08,793] Trial 19 finished with value: 0.7539654672145844 and parameters: {'num_layers': 5, 'num_neurons_layer_0': 72, 'num_neurons_layer_1': 44, 'num_neurons_layer_2': 80, 'num_neurons_layer_3': 48, 'num_neurons_layer_4': 16, 'learning_rate': 0.0002742679759942787, 'activation': 'relu'}. Best is trial 16 with value: 0.5625100433826447.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_4119/3630070542.py:42: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:39:11,546] Trial 20 finished with value: 0.7505942583084106 and parameters: {'num_layers': 5, 'num_neurons_layer_0': 72, 'num_neurons_layer_1': 40, 'num_neurons_layer_2': 56, 'num_neurons_layer_3': 40, 'num_neurons_layer_4': 16, 'learning_rate': 0.00020758276636398385, 'activation': 'relu'}. Best is trial 16 with value: 0.5625100433826447.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_4119/3630070542.py:42: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:39:14,188] Trial 21 finished with value: 0.8040673434734344 and parameters: {'num_layers': 5, 'num_neurons_layer_0': 76, 'num_neurons_layer_1': 40, 'num_neurons_layer_2': 56, 'num_neurons_layer_3': 36, 'num_neurons_layer_4': 16, 'learning_rate': 0.00017338257642831329, 'activation': 'relu'}. Best is trial 16 with value: 0.5625100433826447.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_4119/3630070542.py:42: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:39:16,989] Trial 22 finished with value: 0.7802556753158569 and parameters: {'num_layers': 5, 'num_neurons_layer_0': 68, 'num_neurons_layer_1': 56, 'num_neurons_layer_2': 68, 'num_neurons_layer_3': 48, 'num_neurons_layer_4': 44, 'learning_rate': 0.0002887086954991985, 'activation': 'relu'}. Best is trial 16 with value: 0.5625100433826447.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_4119/3630070542.py:42: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:39:19,693] Trial 23 finished with value: 0.8131701946258545 and parameters: {'num_layers': 5, 'num_neurons_layer_0': 104, 'num_neurons_layer_1': 32, 'num_neurons_layer_2': 80, 'num_neurons_layer_3': 48, 'num_neurons_layer_4': 56, 'learning_rate': 0.00013353445213228047, 'activation': 'relu'}. Best is trial 16 with value: 0.5625100433826447.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_4119/3630070542.py:42: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:39:22,290] Trial 24 finished with value: 0.7259791195392609 and parameters: {'num_layers': 5, 'num_neurons_layer_0': 84, 'num_neurons_layer_1': 16, 'num_neurons_layer_2': 52, 'num_neurons_layer_3': 56, 'num_neurons_layer_4': 16, 'learning_rate': 0.00026320493729990144, 'activation': 'relu'}. Best is trial 16 with value: 0.5625100433826447.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_4119/3630070542.py:42: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:39:24,772] Trial 25 finished with value: 0.7979927659034729 and parameters: {'num_layers': 4, 'num_neurons_layer_0': 120, 'num_neurons_layer_1': 16, 'num_neurons_layer_2': 48, 'num_neurons_layer_3': 60, 'learning_rate': 0.0001976374055372746, 'activation': 'relu'}. Best is trial 16 with value: 0.5625100433826447.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_4119/3630070542.py:42: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:39:27,449] Trial 26 finished with value: 41.85505485534668 and parameters: {'num_layers': 5, 'num_neurons_layer_0': 88, 'num_neurons_layer_1': 28, 'num_neurons_layer_2': 28, 'num_neurons_layer_3': 92, 'num_neurons_layer_4': 84, 'learning_rate': 0.0004294552354252258, 'activation': 'tanh'}. Best is trial 16 with value: 0.5625100433826447.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_4119/3630070542.py:42: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:39:29,817] Trial 27 finished with value: 0.6781105995178223 and parameters: {'num_layers': 3, 'num_neurons_layer_0': 84, 'num_neurons_layer_1': 56, 'num_neurons_layer_2': 52, 'learning_rate': 0.0003687648886392949, 'activation': 'relu'}. Best is trial 16 with value: 0.5625100433826447.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_4119/3630070542.py:42: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:39:32,207] Trial 28 finished with value: 0.7329423427581787 and parameters: {'num_layers': 3, 'num_neurons_layer_0': 84, 'num_neurons_layer_1': 56, 'num_neurons_layer_2': 32, 'learning_rate': 0.0004450494505130042, 'activation': 'relu'}. Best is trial 16 with value: 0.5625100433826447.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_4119/3630070542.py:42: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:39:34,751] Trial 29 finished with value: 22.95008945465088 and parameters: {'num_layers': 3, 'num_neurons_layer_0': 96, 'num_neurons_layer_1': 80, 'num_neurons_layer_2': 52, 'learning_rate': 0.001305911101000612, 'activation': 'tanh'}. Best is trial 16 with value: 0.5625100433826447.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_4119/3630070542.py:42: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:39:37,019] Trial 30 finished with value: 0.6940211653709412 and parameters: {'num_layers': 3, 'num_neurons_layer_0': 56, 'num_neurons_layer_1': 56, 'num_neurons_layer_2': 28, 'learning_rate': 0.0003638536906587787, 'activation': 'relu'}. Best is trial 16 with value: 0.5625100433826447.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_4119/3630070542.py:42: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:39:39,310] Trial 31 finished with value: 0.6004887670278549 and parameters: {'num_layers': 3, 'num_neurons_layer_0': 56, 'num_neurons_layer_1': 56, 'num_neurons_layer_2': 28, 'learning_rate': 0.0003384143808174873, 'activation': 'relu'}. Best is trial 16 with value: 0.5625100433826447.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_4119/3630070542.py:42: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:39:41,589] Trial 32 finished with value: 1.1110619902610779 and parameters: {'num_layers': 3, 'num_neurons_layer_0': 56, 'num_neurons_layer_1': 56, 'num_neurons_layer_2': 28, 'learning_rate': 0.00038144946335661665, 'activation': 'relu'}. Best is trial 16 with value: 0.5625100433826447.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_4119/3630070542.py:42: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:39:43,813] Trial 33 finished with value: 1.1572476625442505 and parameters: {'num_layers': 2, 'num_neurons_layer_0': 48, 'num_neurons_layer_1': 64, 'learning_rate': 0.0005825123433595332, 'activation': 'relu'}. Best is trial 16 with value: 0.5625100433826447.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_4119/3630070542.py:42: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:39:46,105] Trial 34 finished with value: 0.7308538258075714 and parameters: {'num_layers': 3, 'num_neurons_layer_0': 48, 'num_neurons_layer_1': 52, 'num_neurons_layer_2': 32, 'learning_rate': 0.0010370083293166552, 'activation': 'relu'}. Best is trial 16 with value: 0.5625100433826447.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_4119/3630070542.py:42: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:39:48,392] Trial 35 finished with value: 0.8779771327972412 and parameters: {'num_layers': 3, 'num_neurons_layer_0': 36, 'num_neurons_layer_1': 36, 'num_neurons_layer_2': 24, 'learning_rate': 0.0009662991881141729, 'activation': 'relu'}. Best is trial 16 with value: 0.5625100433826447.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_4119/3630070542.py:42: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:39:50,679] Trial 36 finished with value: 0.6212256550788879 and parameters: {'num_layers': 3, 'num_neurons_layer_0': 64, 'num_neurons_layer_1': 64, 'num_neurons_layer_2': 36, 'learning_rate': 0.00037296239536256393, 'activation': 'relu'}. Best is trial 16 with value: 0.5625100433826447.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_4119/3630070542.py:42: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:39:52,911] Trial 37 finished with value: 39.936201095581055 and parameters: {'num_layers': 2, 'num_neurons_layer_0': 68, 'num_neurons_layer_1': 72, 'learning_rate': 0.0005701171778588413, 'activation': 'tanh'}. Best is trial 16 with value: 0.5625100433826447.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_4119/3630070542.py:42: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:39:55,218] Trial 38 finished with value: 0.7414824962615967 and parameters: {'num_layers': 3, 'num_neurons_layer_0': 32, 'num_neurons_layer_1': 80, 'num_neurons_layer_2': 40, 'learning_rate': 0.0007553107658716489, 'activation': 'relu'}. Best is trial 16 with value: 0.5625100433826447.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_4119/3630070542.py:42: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:39:57,717] Trial 39 finished with value: 1.0261983573436737 and parameters: {'num_layers': 3, 'num_neurons_layer_0': 96, 'num_neurons_layer_1': 68, 'num_neurons_layer_2': 64, 'learning_rate': 0.001114670070868114, 'activation': 'relu'}. Best is trial 16 with value: 0.5625100433826447.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_4119/3630070542.py:42: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:40:00,591] Trial 40 finished with value: 57.279184341430664 and parameters: {'num_layers': 4, 'num_neurons_layer_0': 80, 'num_neurons_layer_1': 24, 'num_neurons_layer_2': 36, 'num_neurons_layer_3': 88, 'learning_rate': 0.00016662309387934488, 'activation': 'tanh'}. Best is trial 16 with value: 0.5625100433826447.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_4119/3630070542.py:42: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:40:02,973] Trial 41 finished with value: 0.8126037418842316 and parameters: {'num_layers': 3, 'num_neurons_layer_0': 60, 'num_neurons_layer_1': 60, 'num_neurons_layer_2': 24, 'learning_rate': 0.00035669381987259364, 'activation': 'relu'}. Best is trial 16 with value: 0.5625100433826447.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_4119/3630070542.py:42: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:40:05,362] Trial 42 finished with value: 0.7102407515048981 and parameters: {'num_layers': 3, 'num_neurons_layer_0': 52, 'num_neurons_layer_1': 48, 'num_neurons_layer_2': 44, 'learning_rate': 0.00032957907403544903, 'activation': 'relu'}. Best is trial 16 with value: 0.5625100433826447.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_4119/3630070542.py:42: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:40:07,590] Trial 43 finished with value: 0.7987150847911835 and parameters: {'num_layers': 2, 'num_neurons_layer_0': 20, 'num_neurons_layer_1': 52, 'learning_rate': 0.00047762234807624873, 'activation': 'relu'}. Best is trial 16 with value: 0.5625100433826447.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_4119/3630070542.py:42: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:40:09,949] Trial 44 finished with value: 0.7580009400844574 and parameters: {'num_layers': 3, 'num_neurons_layer_0': 60, 'num_neurons_layer_1': 64, 'num_neurons_layer_2': 36, 'learning_rate': 0.0005710348846568331, 'activation': 'relu'}. Best is trial 16 with value: 0.5625100433826447.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_4119/3630070542.py:42: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:40:12,415] Trial 45 finished with value: 0.8102715313434601 and parameters: {'num_layers': 4, 'num_neurons_layer_0': 44, 'num_neurons_layer_1': 76, 'num_neurons_layer_2': 20, 'num_neurons_layer_3': 128, 'learning_rate': 0.0008391150893981466, 'activation': 'relu'}. Best is trial 16 with value: 0.5625100433826447.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_4119/3630070542.py:42: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:40:14,777] Trial 46 finished with value: 0.9749234318733215 and parameters: {'num_layers': 3, 'num_neurons_layer_0': 64, 'num_neurons_layer_1': 60, 'num_neurons_layer_2': 48, 'learning_rate': 0.00021944664845807417, 'activation': 'relu'}. Best is trial 16 with value: 0.5625100433826447.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_4119/3630070542.py:42: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:40:17,244] Trial 47 finished with value: 0.7857323586940765 and parameters: {'num_layers': 4, 'num_neurons_layer_0': 52, 'num_neurons_layer_1': 48, 'num_neurons_layer_2': 104, 'num_neurons_layer_3': 20, 'learning_rate': 0.0003176113669421351, 'activation': 'relu'}. Best is trial 16 with value: 0.5625100433826447.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_4119/3630070542.py:42: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:40:19,505] Trial 48 finished with value: 58.79370880126953 and parameters: {'num_layers': 2, 'num_neurons_layer_0': 76, 'num_neurons_layer_1': 92, 'learning_rate': 0.0001388468307792703, 'activation': 'tanh'}. Best is trial 16 with value: 0.5625100433826447.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_4119/3630070542.py:42: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:40:21,964] Trial 49 finished with value: 0.6483251452445984 and parameters: {'num_layers': 4, 'num_neurons_layer_0': 20, 'num_neurons_layer_1': 72, 'num_neurons_layer_2': 36, 'num_neurons_layer_3': 92, 'learning_rate': 0.0016336440229785126, 'activation': 'relu'}. Best is trial 16 with value: 0.5625100433826447.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_4119/3630070542.py:42: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:40:24,429] Trial 50 finished with value: 0.6677360534667969 and parameters: {'num_layers': 4, 'num_neurons_layer_0': 20, 'num_neurons_layer_1': 120, 'num_neurons_layer_2': 40, 'num_neurons_layer_3': 88, 'learning_rate': 0.0016775951641271047, 'activation': 'relu'}. Best is trial 16 with value: 0.5625100433826447.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_4119/3630070542.py:42: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:40:27,022] Trial 51 finished with value: 0.6878957450389862 and parameters: {'num_layers': 4, 'num_neurons_layer_0': 20, 'num_neurons_layer_1': 112, 'num_neurons_layer_2': 40, 'num_neurons_layer_3': 88, 'learning_rate': 0.0017107057287155064, 'activation': 'relu'}. Best is trial 16 with value: 0.5625100433826447.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_4119/3630070542.py:42: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:40:29,598] Trial 52 finished with value: 0.7902318835258484 and parameters: {'num_layers': 4, 'num_neurons_layer_0': 24, 'num_neurons_layer_1': 108, 'num_neurons_layer_2': 44, 'num_neurons_layer_3': 96, 'learning_rate': 0.0024193614572181193, 'activation': 'relu'}. Best is trial 16 with value: 0.5625100433826447.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_4119/3630070542.py:42: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:40:32,182] Trial 53 finished with value: 0.5855598300695419 and parameters: {'num_layers': 4, 'num_neurons_layer_0': 32, 'num_neurons_layer_1': 120, 'num_neurons_layer_2': 36, 'num_neurons_layer_3': 112, 'learning_rate': 0.002768930764295742, 'activation': 'relu'}. Best is trial 16 with value: 0.5625100433826447.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_4119/3630070542.py:42: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:40:34,678] Trial 54 finished with value: 1.1188874244689941 and parameters: {'num_layers': 4, 'num_neurons_layer_0': 32, 'num_neurons_layer_1': 88, 'num_neurons_layer_2': 36, 'num_neurons_layer_3': 116, 'learning_rate': 0.003266678938368572, 'activation': 'relu'}. Best is trial 16 with value: 0.5625100433826447.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_4119/3630070542.py:42: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:40:37,115] Trial 55 finished with value: 0.700616180896759 and parameters: {'num_layers': 4, 'num_neurons_layer_0': 16, 'num_neurons_layer_1': 120, 'num_neurons_layer_2': 20, 'num_neurons_layer_3': 100, 'learning_rate': 0.002727891264146621, 'activation': 'relu'}. Best is trial 16 with value: 0.5625100433826447.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_4119/3630070542.py:42: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:40:39,607] Trial 56 finished with value: 1.562762439250946 and parameters: {'num_layers': 4, 'num_neurons_layer_0': 24, 'num_neurons_layer_1': 120, 'num_neurons_layer_2': 36, 'num_neurons_layer_3': 84, 'learning_rate': 0.004323829651792289, 'activation': 'relu'}. Best is trial 16 with value: 0.5625100433826447.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_4119/3630070542.py:42: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:40:42,122] Trial 57 finished with value: 0.585047647356987 and parameters: {'num_layers': 4, 'num_neurons_layer_0': 32, 'num_neurons_layer_1': 124, 'num_neurons_layer_2': 32, 'num_neurons_layer_3': 116, 'learning_rate': 0.0014069973865065725, 'activation': 'relu'}. Best is trial 16 with value: 0.5625100433826447.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_4119/3630070542.py:42: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:40:44,599] Trial 58 finished with value: 0.9726312756538391 and parameters: {'num_layers': 4, 'num_neurons_layer_0': 36, 'num_neurons_layer_1': 128, 'num_neurons_layer_2': 32, 'num_neurons_layer_3': 108, 'learning_rate': 0.0013179317109877802, 'activation': 'relu'}. Best is trial 16 with value: 0.5625100433826447.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_4119/3630070542.py:42: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:40:47,184] Trial 59 finished with value: 1.868028074502945 and parameters: {'num_layers': 4, 'num_neurons_layer_0': 32, 'num_neurons_layer_1': 112, 'num_neurons_layer_2': 24, 'num_neurons_layer_3': 120, 'learning_rate': 0.006415152123613463, 'activation': 'relu'}. Best is trial 16 with value: 0.5625100433826447.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_4119/3630070542.py:42: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:40:49,974] Trial 60 finished with value: 0.7921716868877411 and parameters: {'num_layers': 4, 'num_neurons_layer_0': 44, 'num_neurons_layer_1': 80, 'num_neurons_layer_2': 16, 'num_neurons_layer_3': 100, 'learning_rate': 0.0018287945410194024, 'activation': 'relu'}. Best is trial 16 with value: 0.5625100433826447.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_4119/3630070542.py:42: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:40:52,639] Trial 61 finished with value: 0.8111113607883453 and parameters: {'num_layers': 4, 'num_neurons_layer_0': 24, 'num_neurons_layer_1': 124, 'num_neurons_layer_2': 44, 'num_neurons_layer_3': 120, 'learning_rate': 0.0015023004052158076, 'activation': 'relu'}. Best is trial 16 with value: 0.5625100433826447.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_4119/3630070542.py:42: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:40:55,101] Trial 62 finished with value: 0.873173177242279 and parameters: {'num_layers': 4, 'num_neurons_layer_0': 16, 'num_neurons_layer_1': 120, 'num_neurons_layer_2': 40, 'num_neurons_layer_3': 84, 'learning_rate': 0.0022998221824838917, 'activation': 'relu'}. Best is trial 16 with value: 0.5625100433826447.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_4119/3630070542.py:42: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:40:57,582] Trial 63 finished with value: 0.7814703285694122 and parameters: {'num_layers': 4, 'num_neurons_layer_0': 28, 'num_neurons_layer_1': 108, 'num_neurons_layer_2': 32, 'num_neurons_layer_3': 108, 'learning_rate': 0.0012100491298735927, 'activation': 'relu'}. Best is trial 16 with value: 0.5625100433826447.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_4119/3630070542.py:42: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:41:00,142] Trial 64 finished with value: 2.6881298422813416 and parameters: {'num_layers': 4, 'num_neurons_layer_0': 20, 'num_neurons_layer_1': 116, 'num_neurons_layer_2': 128, 'num_neurons_layer_3': 68, 'learning_rate': 0.0027171808880827176, 'activation': 'relu'}. Best is trial 16 with value: 0.5625100433826447.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_4119/3630070542.py:42: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:41:02,988] Trial 65 finished with value: 0.5570501685142517 and parameters: {'num_layers': 4, 'num_neurons_layer_0': 36, 'num_neurons_layer_1': 104, 'num_neurons_layer_2': 48, 'num_neurons_layer_3': 96, 'learning_rate': 0.002004988311475371, 'activation': 'relu'}. Best is trial 65 with value: 0.5570501685142517.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_4119/3630070542.py:42: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:41:05,867] Trial 66 finished with value: 1.9402182772755623 and parameters: {'num_layers': 5, 'num_neurons_layer_0': 36, 'num_neurons_layer_1': 104, 'num_neurons_layer_2': 48, 'num_neurons_layer_3': 112, 'num_neurons_layer_4': 128, 'learning_rate': 0.002032693826109519, 'activation': 'tanh'}. Best is trial 65 with value: 0.5570501685142517.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_4119/3630070542.py:42: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:41:08,548] Trial 67 finished with value: 0.759847491979599 and parameters: {'num_layers': 4, 'num_neurons_layer_0': 44, 'num_neurons_layer_1': 68, 'num_neurons_layer_2': 60, 'num_neurons_layer_3': 100, 'learning_rate': 0.0014571033958279886, 'activation': 'relu'}. Best is trial 65 with value: 0.5570501685142517.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_4119/3630070542.py:42: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:41:11,126] Trial 68 finished with value: 0.779484748840332 and parameters: {'num_layers': 4, 'num_neurons_layer_0': 40, 'num_neurons_layer_1': 128, 'num_neurons_layer_2': 76, 'num_neurons_layer_3': 80, 'learning_rate': 0.003058070878901763, 'activation': 'relu'}. Best is trial 65 with value: 0.5570501685142517.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_4119/3630070542.py:42: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:41:13,479] Trial 69 finished with value: 0.9114914238452911 and parameters: {'num_layers': 3, 'num_neurons_layer_0': 28, 'num_neurons_layer_1': 40, 'num_neurons_layer_2': 56, 'learning_rate': 0.0046208750104236515, 'activation': 'relu'}. Best is trial 65 with value: 0.5570501685142517.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_4119/3630070542.py:42: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:41:16,100] Trial 70 finished with value: 0.9975232183933258 and parameters: {'num_layers': 5, 'num_neurons_layer_0': 32, 'num_neurons_layer_1': 96, 'num_neurons_layer_2': 28, 'num_neurons_layer_3': 104, 'num_neurons_layer_4': 100, 'learning_rate': 0.0008672776679609258, 'activation': 'relu'}. Best is trial 65 with value: 0.5570501685142517.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_4119/3630070542.py:42: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:41:18,869] Trial 71 finished with value: 0.6760039031505585 and parameters: {'num_layers': 4, 'num_neurons_layer_0': 24, 'num_neurons_layer_1': 124, 'num_neurons_layer_2': 36, 'num_neurons_layer_3': 92, 'learning_rate': 0.0017003470766839982, 'activation': 'relu'}. Best is trial 65 with value: 0.5570501685142517.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_4119/3630070542.py:42: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:41:21,352] Trial 72 finished with value: 0.7183680683374405 and parameters: {'num_layers': 4, 'num_neurons_layer_0': 16, 'num_neurons_layer_1': 116, 'num_neurons_layer_2': 48, 'num_neurons_layer_3': 92, 'learning_rate': 0.0020810442999074637, 'activation': 'relu'}. Best is trial 65 with value: 0.5570501685142517.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_4119/3630070542.py:42: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:41:23,786] Trial 73 finished with value: 0.7225893139839172 and parameters: {'num_layers': 4, 'num_neurons_layer_0': 36, 'num_neurons_layer_1': 124, 'num_neurons_layer_2': 40, 'num_neurons_layer_3': 72, 'learning_rate': 0.001155463910798384, 'activation': 'relu'}. Best is trial 65 with value: 0.5570501685142517.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_4119/3630070542.py:42: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:41:26,189] Trial 74 finished with value: 0.9641363322734833 and parameters: {'num_layers': 4, 'num_neurons_layer_0': 28, 'num_neurons_layer_1': 72, 'num_neurons_layer_2': 32, 'num_neurons_layer_3': 112, 'learning_rate': 0.003907157479850775, 'activation': 'relu'}. Best is trial 65 with value: 0.5570501685142517.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_4119/3630070542.py:42: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:41:28,461] Trial 75 finished with value: 0.6169871687889099 and parameters: {'num_layers': 3, 'num_neurons_layer_0': 24, 'num_neurons_layer_1': 116, 'num_neurons_layer_2': 24, 'learning_rate': 0.0023084538903366428, 'activation': 'relu'}. Best is trial 65 with value: 0.5570501685142517.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_4119/3630070542.py:42: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:41:30,748] Trial 76 finished with value: 0.8506523668766022 and parameters: {'num_layers': 3, 'num_neurons_layer_0': 40, 'num_neurons_layer_1': 112, 'num_neurons_layer_2': 20, 'learning_rate': 0.002698363674853738, 'activation': 'relu'}. Best is trial 65 with value: 0.5570501685142517.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_4119/3630070542.py:42: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:41:33,073] Trial 77 finished with value: 35.372355461120605 and parameters: {'num_layers': 3, 'num_neurons_layer_0': 32, 'num_neurons_layer_1': 84, 'num_neurons_layer_2': 24, 'learning_rate': 0.0022319741640122966, 'activation': 'tanh'}. Best is trial 65 with value: 0.5570501685142517.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_4119/3630070542.py:42: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:41:35,531] Trial 78 finished with value: 0.7353311777114868 and parameters: {'num_layers': 3, 'num_neurons_layer_0': 28, 'num_neurons_layer_1': 104, 'num_neurons_layer_2': 28, 'learning_rate': 0.0019225897865411353, 'activation': 'relu'}. Best is trial 65 with value: 0.5570501685142517.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_4119/3630070542.py:42: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:41:37,810] Trial 79 finished with value: 0.720747709274292 and parameters: {'num_layers': 3, 'num_neurons_layer_0': 48, 'num_neurons_layer_1': 60, 'num_neurons_layer_2': 16, 'learning_rate': 0.0014279433498904286, 'activation': 'relu'}. Best is trial 65 with value: 0.5570501685142517.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_4119/3630070542.py:42: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:41:40,225] Trial 80 finished with value: 0.7157372832298279 and parameters: {'num_layers': 3, 'num_neurons_layer_0': 68, 'num_neurons_layer_1': 72, 'num_neurons_layer_2': 116, 'learning_rate': 0.0025795216388660065, 'activation': 'relu'}. Best is trial 65 with value: 0.5570501685142517.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_4119/3630070542.py:42: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:41:42,692] Trial 81 finished with value: 1.0360132157802582 and parameters: {'num_layers': 4, 'num_neurons_layer_0': 24, 'num_neurons_layer_1': 116, 'num_neurons_layer_2': 44, 'num_neurons_layer_3': 120, 'learning_rate': 0.0012352855818120437, 'activation': 'relu'}. Best is trial 65 with value: 0.5570501685142517.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_4119/3630070542.py:42: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:41:45,214] Trial 82 finished with value: 0.6300010085105896 and parameters: {'num_layers': 3, 'num_neurons_layer_0': 20, 'num_neurons_layer_1': 124, 'num_neurons_layer_2': 40, 'learning_rate': 0.0016953546844243113, 'activation': 'relu'}. Best is trial 65 with value: 0.5570501685142517.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_4119/3630070542.py:42: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:41:47,543] Trial 83 finished with value: 0.7856374979019165 and parameters: {'num_layers': 3, 'num_neurons_layer_0': 20, 'num_neurons_layer_1': 128, 'num_neurons_layer_2': 32, 'learning_rate': 0.0030071547971271353, 'activation': 'relu'}. Best is trial 65 with value: 0.5570501685142517.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_4119/3630070542.py:42: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:41:49,940] Trial 84 finished with value: 0.7339179217815399 and parameters: {'num_layers': 3, 'num_neurons_layer_0': 36, 'num_neurons_layer_1': 124, 'num_neurons_layer_2': 52, 'learning_rate': 0.0010916102430556759, 'activation': 'relu'}. Best is trial 65 with value: 0.5570501685142517.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_4119/3630070542.py:42: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:41:52,046] Trial 85 finished with value: 2.3661988973617554 and parameters: {'num_layers': 1, 'num_neurons_layer_0': 56, 'learning_rate': 0.0006564791322509466, 'activation': 'relu'}. Best is trial 65 with value: 0.5570501685142517.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_4119/3630070542.py:42: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:41:54,355] Trial 86 finished with value: 0.6911300718784332 and parameters: {'num_layers': 3, 'num_neurons_layer_0': 28, 'num_neurons_layer_1': 52, 'num_neurons_layer_2': 36, 'learning_rate': 0.001612454698680174, 'activation': 'relu'}. Best is trial 65 with value: 0.5570501685142517.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_4119/3630070542.py:42: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:41:56,657] Trial 87 finished with value: 0.8371849954128265 and parameters: {'num_layers': 3, 'num_neurons_layer_0': 20, 'num_neurons_layer_1': 44, 'num_neurons_layer_2': 28, 'learning_rate': 0.0009334192671467187, 'activation': 'relu'}. Best is trial 65 with value: 0.5570501685142517.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_4119/3630070542.py:42: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:41:59,011] Trial 88 finished with value: 0.7934439182281494 and parameters: {'num_layers': 3, 'num_neurons_layer_0': 64, 'num_neurons_layer_1': 64, 'num_neurons_layer_2': 48, 'learning_rate': 0.0018482636485261364, 'activation': 'relu'}. Best is trial 65 with value: 0.5570501685142517.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_4119/3630070542.py:42: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:42:01,156] Trial 89 finished with value: 1.931679580360651 and parameters: {'num_layers': 2, 'num_neurons_layer_0': 24, 'num_neurons_layer_1': 68, 'learning_rate': 0.0057200947336303485, 'activation': 'tanh'}. Best is trial 65 with value: 0.5570501685142517.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_4119/3630070542.py:42: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:42:03,501] Trial 90 finished with value: 0.707400768995285 and parameters: {'num_layers': 3, 'num_neurons_layer_0': 16, 'num_neurons_layer_1': 76, 'num_neurons_layer_2': 24, 'learning_rate': 0.0022058209569986447, 'activation': 'relu'}. Best is trial 65 with value: 0.5570501685142517.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_4119/3630070542.py:42: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:42:06,069] Trial 91 finished with value: 0.8920473158359528 and parameters: {'num_layers': 4, 'num_neurons_layer_0': 20, 'num_neurons_layer_1': 120, 'num_neurons_layer_2': 40, 'num_neurons_layer_3': 96, 'learning_rate': 0.0015795663178449478, 'activation': 'relu'}. Best is trial 65 with value: 0.5570501685142517.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_4119/3630070542.py:42: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:42:08,611] Trial 92 finished with value: 0.7204986065626144 and parameters: {'num_layers': 4, 'num_neurons_layer_0': 32, 'num_neurons_layer_1': 116, 'num_neurons_layer_2': 44, 'num_neurons_layer_3': 84, 'learning_rate': 0.0013561998675551826, 'activation': 'relu'}. Best is trial 65 with value: 0.5570501685142517.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_4119/3630070542.py:42: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:42:11,161] Trial 93 finished with value: 0.7102984189987183 and parameters: {'num_layers': 4, 'num_neurons_layer_0': 24, 'num_neurons_layer_1': 108, 'num_neurons_layer_2': 36, 'num_neurons_layer_3': 76, 'learning_rate': 0.001647070399251116, 'activation': 'relu'}. Best is trial 65 with value: 0.5570501685142517.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_4119/3630070542.py:42: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:42:13,559] Trial 94 finished with value: 0.6215191185474396 and parameters: {'num_layers': 4, 'num_neurons_layer_0': 20, 'num_neurons_layer_1': 120, 'num_neurons_layer_2': 32, 'num_neurons_layer_3': 108, 'learning_rate': 0.00022923454382573453, 'activation': 'relu'}. Best is trial 65 with value: 0.5570501685142517.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_4119/3630070542.py:42: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:42:15,823] Trial 95 finished with value: 1.7196272313594818 and parameters: {'num_layers': 3, 'num_neurons_layer_0': 16, 'num_neurons_layer_1': 124, 'num_neurons_layer_2': 20, 'learning_rate': 0.00023600488704080252, 'activation': 'relu'}. Best is trial 65 with value: 0.5570501685142517.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_4119/3630070542.py:42: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:42:18,302] Trial 96 finished with value: 0.7107625007629395 and parameters: {'num_layers': 4, 'num_neurons_layer_0': 32, 'num_neurons_layer_1': 32, 'num_neurons_layer_2': 32, 'num_neurons_layer_3': 108, 'learning_rate': 0.0001594617762798746, 'activation': 'relu'}. Best is trial 65 with value: 0.5570501685142517.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_4119/3630070542.py:42: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:42:20,802] Trial 97 finished with value: 0.7473300099372864 and parameters: {'num_layers': 3, 'num_neurons_layer_0': 28, 'num_neurons_layer_1': 112, 'num_neurons_layer_2': 28, 'learning_rate': 0.0002961324287220088, 'activation': 'relu'}. Best is trial 65 with value: 0.5570501685142517.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_4119/3630070542.py:42: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:42:23,473] Trial 98 finished with value: 0.7504443228244781 and parameters: {'num_layers': 5, 'num_neurons_layer_0': 44, 'num_neurons_layer_1': 128, 'num_neurons_layer_2': 36, 'num_neurons_layer_3': 116, 'num_neurons_layer_4': 104, 'learning_rate': 0.00024125698779543437, 'activation': 'relu'}. Best is trial 65 with value: 0.5570501685142517.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_4119/3630070542.py:42: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:42:25,977] Trial 99 finished with value: 0.9535350203514099 and parameters: {'num_layers': 4, 'num_neurons_layer_0': 40, 'num_neurons_layer_1': 120, 'num_neurons_layer_2': 24, 'num_neurons_layer_3': 128, 'learning_rate': 0.003619912917230598, 'activation': 'relu'}. Best is trial 65 with value: 0.5570501685142517.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:  {'num_layers': 4, 'num_neurons_layer_0': 36, 'num_neurons_layer_1': 104, 'num_neurons_layer_2': 48, 'num_neurons_layer_3': 96, 'learning_rate': 0.002004988311475371, 'activation': 'relu'}\n",
      "Best trial loss:  0.5570501685142517\n",
      "Epoch 1/50\n",
      "9/9 [==============================] - 0s 587us/step - loss: 69.3829\n",
      "Epoch 2/50\n",
      "9/9 [==============================] - 0s 522us/step - loss: 22.5302\n",
      "Epoch 3/50\n",
      "9/9 [==============================] - 0s 517us/step - loss: 14.3603\n",
      "Epoch 4/50\n",
      "9/9 [==============================] - 0s 544us/step - loss: 11.0119\n",
      "Epoch 5/50\n",
      "9/9 [==============================] - 0s 500us/step - loss: 9.1087\n",
      "Epoch 6/50\n",
      "9/9 [==============================] - 0s 490us/step - loss: 5.5413\n",
      "Epoch 7/50\n",
      "9/9 [==============================] - 0s 472us/step - loss: 3.8366\n",
      "Epoch 8/50\n",
      "9/9 [==============================] - 0s 447us/step - loss: 3.8065\n",
      "Epoch 9/50\n",
      "9/9 [==============================] - 0s 465us/step - loss: 2.6931\n",
      "Epoch 10/50\n",
      "9/9 [==============================] - 0s 491us/step - loss: 2.0978\n",
      "Epoch 11/50\n",
      "9/9 [==============================] - 0s 496us/step - loss: 1.4343\n",
      "Epoch 12/50\n",
      "9/9 [==============================] - 0s 499us/step - loss: 1.3179\n",
      "Epoch 13/50\n",
      "9/9 [==============================] - 0s 474us/step - loss: 1.3349\n",
      "Epoch 14/50\n",
      "9/9 [==============================] - 0s 492us/step - loss: 1.5620\n",
      "Epoch 15/50\n",
      "9/9 [==============================] - 0s 479us/step - loss: 1.6635\n",
      "Epoch 16/50\n",
      "9/9 [==============================] - 0s 510us/step - loss: 1.6479\n",
      "Epoch 17/50\n",
      "9/9 [==============================] - 0s 498us/step - loss: 2.2565\n",
      "Epoch 18/50\n",
      "9/9 [==============================] - 0s 494us/step - loss: 3.0618\n",
      "Epoch 19/50\n",
      "9/9 [==============================] - 0s 504us/step - loss: 1.4685\n",
      "Epoch 20/50\n",
      "9/9 [==============================] - 0s 490us/step - loss: 1.5309\n",
      "Epoch 21/50\n",
      "9/9 [==============================] - 0s 568us/step - loss: 1.1453\n",
      "Epoch 22/50\n",
      "9/9 [==============================] - 0s 563us/step - loss: 1.1864\n",
      "Epoch 23/50\n",
      "9/9 [==============================] - 0s 543us/step - loss: 1.5149\n",
      "Epoch 24/50\n",
      "9/9 [==============================] - 0s 497us/step - loss: 1.2319\n",
      "Epoch 25/50\n",
      "9/9 [==============================] - 0s 535us/step - loss: 1.3350\n",
      "Epoch 26/50\n",
      "9/9 [==============================] - 0s 505us/step - loss: 1.8882\n",
      "Epoch 27/50\n",
      "9/9 [==============================] - 0s 530us/step - loss: 2.0737\n",
      "Epoch 28/50\n",
      "9/9 [==============================] - 0s 550us/step - loss: 1.7324\n",
      "Epoch 29/50\n",
      "9/9 [==============================] - 0s 552us/step - loss: 1.1312\n",
      "Epoch 30/50\n",
      "9/9 [==============================] - 0s 543us/step - loss: 1.1023\n",
      "Epoch 31/50\n",
      "9/9 [==============================] - 0s 529us/step - loss: 1.2534\n",
      "Epoch 32/50\n",
      "9/9 [==============================] - 0s 544us/step - loss: 1.0670\n",
      "Epoch 33/50\n",
      "9/9 [==============================] - 0s 518us/step - loss: 1.0771\n",
      "Epoch 34/50\n",
      "9/9 [==============================] - 0s 532us/step - loss: 1.5207\n",
      "Epoch 35/50\n",
      "9/9 [==============================] - 0s 526us/step - loss: 1.0772\n",
      "Epoch 36/50\n",
      "9/9 [==============================] - 0s 517us/step - loss: 1.4017\n",
      "Epoch 37/50\n",
      "9/9 [==============================] - 0s 517us/step - loss: 1.0828\n",
      "Epoch 38/50\n",
      "9/9 [==============================] - 0s 498us/step - loss: 1.2206\n",
      "Epoch 39/50\n",
      "9/9 [==============================] - 0s 527us/step - loss: 1.3703\n",
      "Epoch 40/50\n",
      "9/9 [==============================] - 0s 525us/step - loss: 1.2994\n",
      "Epoch 41/50\n",
      "9/9 [==============================] - 0s 565us/step - loss: 1.6317\n",
      "Epoch 42/50\n",
      "9/9 [==============================] - 0s 533us/step - loss: 2.1116\n",
      "Epoch 43/50\n",
      "9/9 [==============================] - 0s 546us/step - loss: 2.1658\n",
      "Epoch 44/50\n",
      "9/9 [==============================] - 0s 493us/step - loss: 1.5291\n",
      "Epoch 45/50\n",
      "9/9 [==============================] - 0s 530us/step - loss: 1.0642\n",
      "Epoch 46/50\n",
      "9/9 [==============================] - 0s 500us/step - loss: 1.0106\n",
      "Epoch 47/50\n",
      "9/9 [==============================] - 0s 509us/step - loss: 1.1832\n",
      "Epoch 48/50\n",
      "9/9 [==============================] - 0s 529us/step - loss: 1.4171\n",
      "Epoch 49/50\n",
      "9/9 [==============================] - 0s 544us/step - loss: 1.0995\n",
      "Epoch 50/50\n",
      "9/9 [==============================] - 0s 517us/step - loss: 1.0273\n",
      "Epoch 1/50\n",
      "9/9 [==============================] - 0s 591us/step - loss: 56.2975\n",
      "Epoch 2/50\n",
      "9/9 [==============================] - 0s 514us/step - loss: 16.1574\n",
      "Epoch 3/50\n",
      "9/9 [==============================] - 0s 479us/step - loss: 9.3869\n",
      "Epoch 4/50\n",
      "9/9 [==============================] - 0s 487us/step - loss: 4.2856\n",
      "Epoch 5/50\n",
      "9/9 [==============================] - 0s 486us/step - loss: 2.7604\n",
      "Epoch 6/50\n",
      "9/9 [==============================] - 0s 490us/step - loss: 1.8005\n",
      "Epoch 7/50\n",
      "9/9 [==============================] - 0s 463us/step - loss: 1.2227\n",
      "Epoch 8/50\n",
      "9/9 [==============================] - 0s 476us/step - loss: 1.0894\n",
      "Epoch 9/50\n",
      "9/9 [==============================] - 0s 454us/step - loss: 0.9197\n",
      "Epoch 10/50\n",
      "9/9 [==============================] - 0s 472us/step - loss: 0.8540\n",
      "Epoch 11/50\n",
      "9/9 [==============================] - 0s 496us/step - loss: 0.8515\n",
      "Epoch 12/50\n",
      "9/9 [==============================] - 0s 501us/step - loss: 0.8609\n",
      "Epoch 13/50\n",
      "9/9 [==============================] - 0s 542us/step - loss: 0.7864\n",
      "Epoch 14/50\n",
      "9/9 [==============================] - 0s 514us/step - loss: 0.8443\n",
      "Epoch 15/50\n",
      "9/9 [==============================] - 0s 481us/step - loss: 0.7948\n",
      "Epoch 16/50\n",
      "9/9 [==============================] - 0s 481us/step - loss: 0.8165\n",
      "Epoch 17/50\n",
      "9/9 [==============================] - 0s 499us/step - loss: 0.8313\n",
      "Epoch 18/50\n",
      "9/9 [==============================] - 0s 524us/step - loss: 0.9910\n",
      "Epoch 19/50\n",
      "9/9 [==============================] - 0s 529us/step - loss: 0.9360\n",
      "Epoch 20/50\n",
      "9/9 [==============================] - 0s 521us/step - loss: 0.9321\n",
      "Epoch 21/50\n",
      "9/9 [==============================] - 0s 491us/step - loss: 0.8962\n",
      "Epoch 22/50\n",
      "9/9 [==============================] - 0s 473us/step - loss: 1.0629\n",
      "Epoch 23/50\n",
      "9/9 [==============================] - 0s 537us/step - loss: 0.8260\n",
      "Epoch 24/50\n",
      "9/9 [==============================] - 0s 546us/step - loss: 1.0067\n",
      "Epoch 25/50\n",
      "9/9 [==============================] - 0s 499us/step - loss: 0.9666\n",
      "Epoch 26/50\n",
      "9/9 [==============================] - 0s 526us/step - loss: 0.8863\n",
      "Epoch 27/50\n",
      "9/9 [==============================] - 0s 524us/step - loss: 1.0208\n",
      "Epoch 28/50\n",
      "9/9 [==============================] - 0s 484us/step - loss: 1.2014\n",
      "Epoch 29/50\n",
      "9/9 [==============================] - 0s 497us/step - loss: 1.1262\n",
      "Epoch 30/50\n",
      "9/9 [==============================] - 0s 507us/step - loss: 0.9495\n",
      "Epoch 31/50\n",
      "9/9 [==============================] - 0s 508us/step - loss: 0.7997\n",
      "Epoch 32/50\n",
      "9/9 [==============================] - 0s 524us/step - loss: 1.1877\n",
      "Epoch 33/50\n",
      "9/9 [==============================] - 0s 516us/step - loss: 0.8693\n",
      "Epoch 34/50\n",
      "9/9 [==============================] - 0s 529us/step - loss: 0.9679\n",
      "Epoch 35/50\n",
      "9/9 [==============================] - 0s 490us/step - loss: 0.9480\n",
      "Epoch 36/50\n",
      "9/9 [==============================] - 0s 512us/step - loss: 0.9237\n",
      "Epoch 37/50\n",
      "9/9 [==============================] - 0s 487us/step - loss: 0.7940\n",
      "Epoch 38/50\n",
      "9/9 [==============================] - 0s 512us/step - loss: 0.8223\n",
      "Epoch 39/50\n",
      "9/9 [==============================] - 0s 508us/step - loss: 1.1576\n",
      "Epoch 40/50\n",
      "9/9 [==============================] - 0s 492us/step - loss: 0.9690\n",
      "Epoch 41/50\n",
      "9/9 [==============================] - 0s 531us/step - loss: 0.8479\n",
      "Epoch 42/50\n",
      "9/9 [==============================] - 0s 494us/step - loss: 0.9864\n",
      "Epoch 43/50\n",
      "9/9 [==============================] - 0s 511us/step - loss: 0.8310\n",
      "Epoch 44/50\n",
      "9/9 [==============================] - 0s 519us/step - loss: 0.8188\n"
     ]
    }
   ],
   "source": [
    "# import optuna\n",
    "import optuna\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "trial_losses = []\n",
    "\n",
    "# Function to create a model with the given hyperparameters\n",
    "# Function to create a model with a specific number of neurons in each layer\n",
    "def create_model(input_shape, neurons_per_layer, activation, learning_rate):\n",
    "    model = tf.keras.Sequential()\n",
    "    \n",
    "    # Add the first layer with input shape\n",
    "    model.add(layers.Dense(neurons_per_layer[0], activation=activation, input_shape=(input_shape,)))\n",
    "    \n",
    "    # Add subsequent layers with specified number of neurons\n",
    "    for neurons in neurons_per_layer[1:]:\n",
    "        model.add(layers.Dense(neurons, activation=activation))\n",
    "    \n",
    "    model.add(layers.Dense(1))  # Output layer\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate),\n",
    "                  loss='mean_absolute_error')\n",
    "    return model\n",
    "\n",
    "# Objective function to optimize both entrance and exit models\n",
    "def objective(trial):\n",
    "    # Suggest number of layers\n",
    "    num_layers = trial.suggest_int('num_layers', 1, 5)\n",
    "    \n",
    "    # Suggest a different number of neurons for each layer\n",
    "    neurons_per_layer = []\n",
    "    for i in range(num_layers):\n",
    "        neurons = trial.suggest_int(f'num_neurons_layer_{i}', 16, 128, step=4)  # Each layer can have 16 to 128 neurons\n",
    "        neurons_per_layer.append(neurons)\n",
    "    \n",
    "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
    "    activation = trial.suggest_categorical('activation', ['relu', 'tanh'])\n",
    "\n",
    "    # Create models for both entrance and exit\n",
    "    model_entrance = create_model(train_features_entrance.shape[1], neurons_per_layer, activation, learning_rate)\n",
    "    model_exit = create_model(train_features_exit.shape[1], neurons_per_layer, activation, learning_rate)\n",
    "\n",
    "    # Split data into training and validation for both entrance and exit\n",
    "    x_train_entrance, x_val_entrance, y_train_entrance, y_val_entrance = train_test_split(train_features_entrance, train_labels_entrance, test_size=0.2, random_state=42)\n",
    "    x_train_exit, x_val_exit, y_train_exit, y_val_exit = train_test_split(train_features_exit, train_labels_exit, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Train both models\n",
    "    model_entrance.fit(x_train_entrance, y_train_entrance, validation_data=(x_val_entrance, y_val_entrance), \n",
    "                       epochs=100, batch_size=32, verbose=0)\n",
    "    model_exit.fit(x_train_exit, y_train_exit, validation_data=(x_val_exit, y_val_exit), \n",
    "                   epochs=100, batch_size=32, verbose=0)\n",
    "\n",
    "    # Evaluate both models on validation data\n",
    "    val_loss_entrance = model_entrance.evaluate(x_val_entrance, y_val_entrance, verbose=0)\n",
    "    val_loss_exit = model_exit.evaluate(x_val_exit, y_val_exit, verbose=0)\n",
    "\n",
    "    # Combine the two objectives by returning a weighted sum\n",
    "    combined_loss = 0.5 * val_loss_entrance + 0.5 * val_loss_exit\n",
    "    trial_losses.append(combined_loss)  # Append the loss to the list\n",
    "    \n",
    "    return combined_loss\n",
    "\n",
    "# Create a study and optimize both models simultaneously\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "# Plot the losses\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(trial_losses, label='Loss per Trial', marker='o', color='blue')\n",
    "plt.title('Optimization Progress: Loss per Trial')\n",
    "plt.xlabel('Trial')\n",
    "plt.ylabel('Objective Value (Loss)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Print best hyperparameters\n",
    "print(\"Best hyperparameters: \", study.best_params)\n",
    "print(\"Best trial loss: \", study.best_value)\n",
    "\n",
    "# Build the final optimized models\n",
    "def build_best_model(best_params, input_shape):\n",
    "    num_layers = best_params['num_layers']\n",
    "    \n",
    "    # Reconstruct neurons per layer using the best parameters\n",
    "    neurons_per_layer = [best_params[f'num_neurons_layer_{i}'] for i in range(num_layers)]\n",
    "    activation = best_params['activation']\n",
    "    learning_rate = best_params['learning_rate']\n",
    "\n",
    "    model = create_model(input_shape, neurons_per_layer, activation, learning_rate)\n",
    "    return model\n",
    "\n",
    "# Create the final models using the best hyperparameters\n",
    "final_model_entrance = build_best_model(study.best_params, train_features_entrance.shape[1])\n",
    "final_model_exit = build_best_model(study.best_params, train_features_exit.shape[1])\n",
    "\n",
    "\n",
    "# Train the final models on the full datasets\n",
    "final_model_entrance.fit(train_features_entrance, train_labels_entrance, epochs=50, batch_size=32, verbose=1)\n",
    "final_model_exit.fit(train_features_exit, train_labels_exit, epochs=50, batch_size=32, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "682ac3be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 2ms/step - loss: 1.1224\n",
      "Test set loss for entrance: 1.1223833560943604\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 1.2042\n",
      "Test set loss for exit: 1.204248309135437\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.0412\n",
      "v2. Test set loss for entrance: 1.0412216186523438\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.5720\n",
      "v2. Test set loss for exit: 0.5720087885856628\n",
      "Test features Entrance: [[13.09   4.402 42.274  3.86 ]\n",
      " [14.32   4.37  39.863  3.699]\n",
      " [26.62   6.382 40.238  3.942]\n",
      " [ 7.97   2.692 38.022  2.277]\n",
      " [ 7.64   2.736 38.804  2.363]\n",
      " [20.63   6.577 45.579  5.597]\n",
      " [29.08   6.42  38.323  5.389]\n",
      " [14.32   4.34  39.86   3.699]\n",
      " [ 7.57   2.603 38.789  2.34 ]\n",
      " [20.05   6.657 46.226  5.752]\n",
      " [22.35   5.708 40.169  4.998]\n",
      " [20.05   6.616 46.23   5.817]\n",
      " [20.63   6.429 45.644  5.667]\n",
      " [ 7.97   2.68  37.952  2.306]\n",
      " [ 7.95   2.472 36.084  2.14 ]\n",
      " [20.05   6.622 46.246  5.795]\n",
      " [20.35   6.452 45.364  5.656]\n",
      " [22.35   5.829 40.068  4.924]\n",
      " [ 7.97   2.716 38.054  2.329]\n",
      " [20.35   6.421 45.363  5.616]\n",
      " [ 7.57   2.665 38.763  2.231]\n",
      " [ 7.64   2.801 38.742  2.319]\n",
      " [31.99   6.702 38.233  5.708]\n",
      " [20.05   6.612 46.341  5.686]\n",
      " [14.32   4.442 40.041  3.707]\n",
      " [13.09   4.333 42.217  3.768]\n",
      " [26.62   6.46  40.348  3.977]\n",
      " [ 7.64   2.74  38.769  2.323]\n",
      " [13.32   4.332 41.392  3.757]\n",
      " [ 7.     2.433 38.394  2.096]\n",
      " [20.05   6.62  46.3    5.759]\n",
      " [20.63   6.573 45.569  5.631]\n",
      " [12.46   4.048 40.338  3.433]\n",
      " [ 7.57   2.673 38.789  2.35 ]\n",
      " [ 7.64   2.752 38.798  2.352]\n",
      " [29.08   6.452 38.364  5.385]\n",
      " [22.35   5.76  40.057  4.975]\n",
      " [14.32   4.423 39.857  3.754]\n",
      " [13.32   4.414 41.5    3.757]\n",
      " [ 7.64   2.815 38.764  2.257]\n",
      " [ 7.95   2.518 36.204  2.188]\n",
      " [12.46   3.921 40.276  3.416]\n",
      " [20.63   6.477 45.665  5.639]\n",
      " [29.08   6.453 38.348  5.438]\n",
      " [22.35   5.84  40.079  4.995]\n",
      " [ 7.57   2.585 38.815  2.193]\n",
      " [20.05   6.511 46.312  5.815]\n",
      " [12.46   3.974 40.406  3.412]\n",
      " [13.32   4.349 41.629  3.747]\n",
      " [ 7.     2.405 38.307  2.104]\n",
      " [20.51   6.516 45.479  5.764]\n",
      " [29.08   6.459 38.322  5.452]\n",
      " [ 7.57   2.605 38.753  2.274]\n",
      " [ 7.95   2.522 36.142  2.09 ]\n",
      " [20.51   6.465 45.588  5.629]\n",
      " [20.35   6.481 45.442  5.592]\n",
      " [20.63   6.498 45.588  5.664]\n",
      " [13.09   4.417 42.198  3.884]\n",
      " [26.62   6.428 40.251  3.898]\n",
      " [20.51   6.582 45.542  5.6  ]\n",
      " [29.08   6.387 38.365  5.465]\n",
      " [12.46   4.144 40.32   3.503]\n",
      " [14.32   4.418 39.889  3.656]\n",
      " [13.09   4.377 42.282  3.763]\n",
      " [31.99   6.774 38.009  5.751]\n",
      " [20.05   6.67  46.247  5.738]\n",
      " [20.63   6.495 45.572  5.664]\n",
      " [29.08   6.346 38.28   5.458]]\n",
      "\n",
      "v2. Test features Entrance: [[29.08  6.44 38.33  5.46]\n",
      " [ 7.    2.42 38.36  2.1 ]\n",
      " [ 7.64  2.76 38.77  2.32]]\n",
      "\n",
      "Test result Entrance: {'dnn_model': 1.1223833560943604}\n",
      "\n",
      "v2. Test result Entrance: {'dnn_model': 1.0412216186523438}\n",
      "\n",
      "Test features Exit: [[39.34   8.556 42.768  7.365]\n",
      " [38.55   8.809 42.199  7.507]\n",
      " [38.64   8.158 41.737  7.083]\n",
      " [42.52   8.433 42.532  7.19 ]\n",
      " [38.07   8.268 42.181  7.027]\n",
      " [38.89   8.512 42.447  7.156]\n",
      " [38.8    8.334 42.511  7.212]\n",
      " [38.55   8.856 42.109  7.588]\n",
      " [39.14   8.573 42.624  7.239]\n",
      " [39.94   8.712 42.992  7.433]\n",
      " [38.19   8.326 41.954  7.168]\n",
      " [39.94   8.767 42.999  7.447]\n",
      " [38.89   8.466 42.484  7.075]\n",
      " [42.52   8.53  42.515  7.149]\n",
      " [39.89   8.707 43.034  7.359]\n",
      " [39.94   8.689 42.991  7.503]\n",
      " [39.08   8.457 42.533  2.286]\n",
      " [38.19   8.21  41.976  7.115]\n",
      " [42.52   8.415 42.571  7.215]\n",
      " [39.08   8.541 42.543  2.247]\n",
      " [39.14   8.427 42.708  7.273]\n",
      " [38.07   8.296 42.133  7.12 ]\n",
      " [38.79   8.43  42.414  7.178]\n",
      " [39.94   8.627 42.941  7.396]\n",
      " [38.55   8.778 42.101  7.57 ]\n",
      " [39.34   8.618 42.662  7.281]\n",
      " [38.64   8.264 41.755  7.14 ]\n",
      " [38.07   8.351 42.135  7.039]\n",
      " [38.67   8.406 42.462  7.186]\n",
      " [38.43   8.352 42.267  7.232]\n",
      " [39.94   8.68  43.019  7.469]\n",
      " [38.89   8.461 42.433  7.239]\n",
      " [38.61   8.339 42.062  7.052]\n",
      " [39.14   8.467 42.661  7.26 ]\n",
      " [38.07   8.342 42.213  7.087]\n",
      " [38.8    8.534 42.531  7.204]\n",
      " [38.19   8.213 41.856  7.003]\n",
      " [38.55   8.79  42.128  7.589]\n",
      " [38.67   8.413 42.491  7.114]\n",
      " [38.07   8.321 42.16   7.118]\n",
      " [39.89   8.848 43.089  7.374]\n",
      " [38.61   8.312 41.991  7.095]\n",
      " [38.89   8.426 42.4    7.187]\n",
      " [38.8    8.382 42.529  7.197]\n",
      " [38.19   8.334 41.93   7.088]\n",
      " [39.14   8.491 42.674  7.229]\n",
      " [39.94   8.69  43.118  7.381]\n",
      " [38.61   8.348 41.998  7.092]\n",
      " [38.67   8.476 42.426  7.151]\n",
      " [38.43   8.445 42.228  7.006]\n",
      " [38.16   8.225 41.933  7.058]\n",
      " [38.8    8.374 42.465  7.282]\n",
      " [39.14   8.547 42.631  7.241]\n",
      " [39.89   8.787 43.067  7.357]\n",
      " [38.16   8.299 42.091  7.055]\n",
      " [39.08   8.368 42.467  2.34 ]\n",
      " [38.89   8.422 42.421  7.207]\n",
      " [39.34   8.487 42.727  7.421]\n",
      " [38.64   8.29  41.803  7.154]\n",
      " [38.16   8.259 41.989  7.022]\n",
      " [38.8    8.457 42.461  7.161]\n",
      " [38.61   8.298 41.957  7.119]\n",
      " [38.55   8.762 42.062  7.583]\n",
      " [39.34   8.617 42.765  7.186]\n",
      " [38.79   8.338 42.369  7.248]\n",
      " [39.94   8.67  42.922  7.434]\n",
      " [38.89   8.463 42.463  7.2  ]\n",
      " [38.8    8.423 42.531  7.112]]\n",
      "\n",
      "v2. Test features Exit: [[38.8   8.45 42.5   7.19]\n",
      " [38.43  8.36 42.28  7.11]\n",
      " [38.07  8.3  42.19  7.06]]\n",
      "Test result Exit: {'dnn_model': 1.204248309135437}\n",
      "\n",
      "v2. Test result Exit: {'dnn_model': 0.5720087885856628}\n",
      "\n",
      "3/3 [==============================] - 0s 818us/step\n",
      "Test Predictions Entrance: [91.586 84.01  78.561 89.538 91.824 88.156 75.855 84.044 92.059 89.656\n",
      " 78.59  89.658 88.292 89.338 84.815 89.713 87.731 78.39  89.54  87.736\n",
      " 92.012 91.615 76.081 90.094 84.378 91.619 78.786 91.766 89.18  92.065\n",
      " 89.898 88.137 87.982 91.956 91.797 75.933 78.379 83.863 89.355 91.715\n",
      " 85.027 88.01  88.325 75.924 78.411 92.294 90.026 88.285 89.8   91.862\n",
      " 87.962 75.883 92.026 84.951 88.167 87.873 88.18  91.337 78.578 88.067\n",
      " 75.949 87.731 84.055 91.739 75.713 89.708 88.151 75.787]\n",
      "\n",
      "3/3 [==============================] - 0s 658us/step\n",
      "Test Predictions Exit: [76.861 75.703 75.176 78.902 75.247 76.165 76.156 75.616 76.55  77.56\n",
      " 75.104 77.574 76.195 78.89  77.564 77.562 76.027 75.114 78.944 76.043\n",
      " 76.63  75.204 76.05  77.495 75.599 76.745 75.21  75.205 76.012 75.626\n",
      " 77.589 76.151 75.521 76.582 75.292 76.196 74.975 75.63  76.04  75.235\n",
      " 77.636 75.444 76.109 76.179 75.074 76.596 77.691 75.455 75.978 75.575\n",
      " 75.042 76.116 76.556 77.606 75.22  75.952 76.132 76.814 75.265 75.103\n",
      " 76.11  75.409 75.557 76.85  75.998 77.48  76.181 76.178]\n",
      "\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "v2. Test Predictions Entrance: [75.897 91.987 91.744]\n",
      "\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "v2. Test Predictions Exit: [76.153 75.631 75.262]\n",
      "\n",
      "Error entrance: 9      1.936159\n",
      "25    -1.650456\n",
      "28    -0.009056\n",
      "31     0.549636\n",
      "32     1.630120\n",
      "         ...   \n",
      "315    2.088510\n",
      "323    1.722822\n",
      "325    1.297954\n",
      "327    0.821146\n",
      "328    0.246842\n",
      "Name: Temperature (Â°F), Length: 68, dtype: float64\n",
      "\n",
      "Error exit: 9      1.936159\n",
      "25    -1.650456\n",
      "28    -0.009056\n",
      "31     0.549636\n",
      "32     1.630120\n",
      "         ...   \n",
      "315    2.088510\n",
      "323    1.722822\n",
      "325    1.297954\n",
      "327    0.821146\n",
      "328    0.246842\n",
      "Name: Temperature (Â°F), Length: 68, dtype: float64\n",
      "\n",
      "v2. Error entrance: 5     0.357186\n",
      "12    1.216687\n",
      "15    1.549759\n",
      "Name: Temperature (°F), dtype: float64\n",
      "\n",
      "v2. Error exit: 5     0.357186\n",
      "12    1.216687\n",
      "15    1.549759\n",
      "Name: Temperature (°F), dtype: float64\n",
      "\n",
      "Average error for entrance: 0.4545341707117417\n",
      "\n",
      "Average error for exit: 1.2042477641386145\n",
      "\n",
      "v2. Average error for entrance: 1.0412107137044255\n",
      "\n",
      "v2. Average error for exit: 1.0412107137044255\n",
      "\n",
      "Mean Squared Error for entrance: 1.6870544851225495\n",
      "Mean Squared Error for exit: 2.2813620069150073\n",
      "\n",
      "v2. Mean Squared Error for entrance: 1.3365540064500523\n",
      "v2. Mean Squared Error for exit: 0.4707817803444376\n",
      "\n",
      "Mean Absolute Error for entrance: 1.1223834354176234\n",
      "Mean Absolute Error for exit: 1.2042477641386145\n",
      "\n",
      "v2. Mean Absolute Error for entrance: 1.0412107137044255\n",
      "v2. Mean Absolute Error for exit: 0.5720068359375006\n",
      "\n",
      "MAPE for entrance: 1.30%\n",
      "MAPE for exit: 1.60%\n",
      "v2. MAPE for entrance: 1.18%\n",
      "v2. MAPE for exit: 0.76%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Optionally, evaluate on a test set (if you have one)\n",
    "test_loss_entrance = final_model_entrance.evaluate(test_features_entrance, test_labels_entrance, verbose=1)\n",
    "print(f\"Test set loss for entrance: {test_loss_entrance}\")\n",
    "test_loss_exit = final_model_exit.evaluate(test_features_exit, test_labels_exit, verbose=1)\n",
    "print(f\"Test set loss for exit: {test_loss_exit}\")\n",
    "\n",
    "ori_test_loss_entrance = final_model_entrance.evaluate(ori_test_features_entrance, ori_test_labels_entrance, verbose=1)\n",
    "print(f\"v2. Test set loss for entrance: {ori_test_loss_entrance}\")\n",
    "ori_test_loss_exit = final_model_exit.evaluate(ori_test_features_exit, ori_test_labels_exit, verbose=1)\n",
    "print(f\"v2. Test set loss for exit: {ori_test_loss_exit}\")\n",
    "\n",
    "#----------------------\n",
    "test_features_entrance = np.asarray(test_features_entrance).astype(np.float32)\n",
    "print(\"Test features Entrance:\", test_features_entrance)\n",
    "print()\n",
    "\n",
    "ori_test_features_entrance = np.asarray(ori_test_features_entrance).astype(np.float32)\n",
    "print(\"v2. Test features Entrance:\", ori_test_features_entrance)\n",
    "print()\n",
    "\n",
    "#----------------------\n",
    "test_results_entrance = {}\n",
    "test_results_entrance['dnn_model'] = final_model_entrance.evaluate(test_features_entrance, test_labels_entrance, verbose=0)\n",
    "print(\"Test result Entrance:\", test_results_entrance)\n",
    "print()\n",
    "\n",
    "ori_test_results_entrance = {}\n",
    "ori_test_results_entrance['dnn_model'] = final_model_entrance.evaluate(ori_test_features_entrance, ori_test_labels_entrance, verbose=0)\n",
    "print(\"v2. Test result Entrance:\", ori_test_results_entrance)\n",
    "print()\n",
    "\n",
    "#----------------------\n",
    "test_features_exit = np.asarray(test_features_exit).astype(np.float32)\n",
    "print(\"Test features Exit:\", test_features_exit)\n",
    "print()\n",
    "\n",
    "ori_test_features_exit = np.asarray(ori_test_features_exit).astype(np.float32)\n",
    "print(\"v2. Test features Exit:\", ori_test_features_exit)\n",
    "\n",
    "#----------------------\n",
    "test_results_exit = {}\n",
    "test_results_exit['dnn_model'] = final_model_exit.evaluate(test_features_exit, test_labels_exit, verbose=0)\n",
    "print(\"Test result Exit:\", test_results_exit)\n",
    "print()\n",
    "\n",
    "ori_test_results_exit = {}\n",
    "ori_test_results_exit['dnn_model'] = final_model_exit.evaluate(ori_test_features_exit, ori_test_labels_exit, verbose=0)\n",
    "print(\"v2. Test result Exit:\", ori_test_results_exit)\n",
    "print()\n",
    "\n",
    "#----------------------\n",
    "pd.DataFrame(test_results_entrance, index=['Mean absolute error [Temperature]']).T\n",
    "\n",
    "pd.DataFrame(test_results_exit, index=['Mean absolute error [Temperature]']).T\n",
    "\n",
    "pd.DataFrame(ori_test_results_entrance, index=['Mean absolute error [Temperature]']).T\n",
    "\n",
    "pd.DataFrame(ori_test_results_exit, index=['Mean absolute error [Temperature]']).T\n",
    "\n",
    "#----------------------\n",
    "test_predictions_entrance = final_model_entrance.predict(test_features_entrance).flatten()\n",
    "print(\"Test Predictions Entrance:\", test_predictions_entrance)\n",
    "print()\n",
    "\n",
    "test_predictions_exit = final_model_exit.predict(test_features_exit).flatten()\n",
    "print(\"Test Predictions Exit:\", test_predictions_exit)\n",
    "print()\n",
    "\n",
    "ori_test_predictions_entrance = final_model_entrance.predict(ori_test_features_entrance).flatten()\n",
    "print(\"v2. Test Predictions Entrance:\", ori_test_predictions_entrance)\n",
    "print()\n",
    "\n",
    "ori_test_predictions_exit = final_model_exit.predict(ori_test_features_exit).flatten()\n",
    "print(\"v2. Test Predictions Exit:\", ori_test_predictions_exit)\n",
    "print()\n",
    "\n",
    "#----------------------\n",
    "error_entrance = test_predictions_entrance - test_labels_entrance\n",
    "print(\"Error entrance:\", error_entrance)\n",
    "print()\n",
    "\n",
    "error_exit = test_predictions_entrance - test_labels_entrance\n",
    "print(\"Error exit:\", error_exit)\n",
    "print()\n",
    "\n",
    "ori_error_entrance = ori_test_predictions_entrance - ori_test_labels_entrance\n",
    "print(\"v2. Error entrance:\", ori_error_entrance)\n",
    "print()\n",
    "\n",
    "ori_error_exit = ori_test_predictions_entrance - ori_test_labels_entrance\n",
    "print(\"v2. Error exit:\", ori_error_exit)\n",
    "print()\n",
    "\n",
    "#----------------------\n",
    "plt.hist(error_entrance, bins=25, color='lightblue')\n",
    "plt.xlabel('Prediction Error [Temperature]')\n",
    "_ = plt.ylabel('Count')\n",
    "\n",
    "error_exit = test_predictions_exit - test_labels_exit\n",
    "error_exit\n",
    "\n",
    "plt.hist(error_exit, bins=25, color='lightblue')\n",
    "plt.xlabel('Prediction Error [Temperature]')\n",
    "_ = plt.ylabel('Count')\n",
    "\n",
    "# average error\n",
    "average_error_entrance = np.mean(error_entrance)\n",
    "print(\"Average error for entrance:\", average_error_entrance)\n",
    "print()\n",
    "\n",
    "average_error_exit = np.mean(error_exit)\n",
    "print(\"Average error for exit:\", average_error_exit)\n",
    "print()\n",
    "\n",
    "ori_average_error_entrance = np.mean(ori_error_entrance)\n",
    "print(\"v2. Average error for entrance:\", ori_average_error_entrance)\n",
    "print()\n",
    "\n",
    "ori_average_error_exit = np.mean(ori_error_exit)\n",
    "print(\"v2. Average error for exit:\", ori_average_error_exit)\n",
    "print()\n",
    "\n",
    "# mean squared error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse_entrance = mean_squared_error(test_labels_entrance, test_predictions_entrance)\n",
    "mse_exit = mean_squared_error(test_labels_exit, test_predictions_exit)\n",
    "print(\"Mean Squared Error for entrance:\", mse_entrance)\n",
    "print(\"Mean Squared Error for exit:\", mse_exit)\n",
    "print()\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "ori_mse_entrance = mean_squared_error(ori_test_labels_entrance, ori_test_predictions_entrance)\n",
    "ori_mse_exit = mean_squared_error(ori_test_labels_exit, ori_test_predictions_exit)\n",
    "print(\"v2. Mean Squared Error for entrance:\", ori_mse_entrance)\n",
    "print(\"v2. Mean Squared Error for exit:\", ori_mse_exit)\n",
    "print()\n",
    "\n",
    "# mean absolute error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "mae_entrance = mean_absolute_error(test_labels_entrance, test_predictions_entrance)\n",
    "mae_exit = mean_absolute_error(test_labels_exit, test_predictions_exit)\n",
    "print(\"Mean Absolute Error for entrance:\", mae_entrance)\n",
    "print(\"Mean Absolute Error for exit:\", mae_exit)\n",
    "print()\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "ori_mae_entrance = mean_absolute_error(ori_test_labels_entrance, ori_test_predictions_entrance)\n",
    "ori_mae_exit = mean_absolute_error(ori_test_labels_exit, ori_test_predictions_exit)\n",
    "print(\"v2. Mean Absolute Error for entrance:\", ori_mae_entrance)\n",
    "print(\"v2. Mean Absolute Error for exit:\", ori_mae_exit)\n",
    "print()\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def mean_absolute_percentage_error(y_actual, y_pred):\n",
    "    y_actual, y_pred = np.array(y_actual), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_actual - y_pred) / y_actual)) * 100\n",
    "\n",
    "mape_entrance = mean_absolute_percentage_error(test_labels_entrance, test_predictions_entrance)\n",
    "print(f'MAPE for entrance: {mape_entrance:.2f}%')\n",
    "\n",
    "mape_exit = mean_absolute_percentage_error(test_labels_exit, test_predictions_exit)\n",
    "print(f'MAPE for exit: {mape_exit:.2f}%')\n",
    "\n",
    "ori_mape_entrance = mean_absolute_percentage_error(ori_test_labels_entrance, ori_test_predictions_entrance)\n",
    "print(f'v2. MAPE for entrance: {ori_mape_entrance:.2f}%')\n",
    "\n",
    "ori_mape_exit = mean_absolute_percentage_error(ori_test_labels_exit, ori_test_predictions_exit)\n",
    "print(f'v2. MAPE for exit: {ori_mape_exit:.2f}%')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "7c19bc6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial Losses (Objective Values) as a Column:\n",
      "1|20.393013954162598\n",
      "2|0.8846242129802704\n",
      "3|6.349931418895721\n",
      "4|1.041165679693222\n",
      "5|1.3741911053657532\n",
      "6|0.7633539140224457\n",
      "7|52.60276222229004\n",
      "8|3.9390420019626617\n",
      "9|55.32628059387207\n",
      "10|35.13973140716553\n",
      "11|2.012504458427429\n",
      "12|1.2917988300323486\n",
      "13|1.597553163766861\n",
      "14|2.211782991886139\n",
      "15|1.049449861049652\n",
      "16|1.5876287817955017\n",
      "17|0.5625100433826447\n",
      "18|0.7661831974983215\n",
      "19|1.0716294050216675\n",
      "20|0.7539654672145844\n",
      "21|0.7505942583084106\n",
      "22|0.8040673434734344\n",
      "23|0.7802556753158569\n",
      "24|0.8131701946258545\n",
      "25|0.7259791195392609\n",
      "26|0.7979927659034729\n",
      "27|41.85505485534668\n",
      "28|0.6781105995178223\n",
      "29|0.7329423427581787\n",
      "30|22.95008945465088\n",
      "31|0.6940211653709412\n",
      "32|0.6004887670278549\n",
      "33|1.1110619902610779\n",
      "34|1.1572476625442505\n",
      "35|0.7308538258075714\n",
      "36|0.8779771327972412\n",
      "37|0.6212256550788879\n",
      "38|39.936201095581055\n",
      "39|0.7414824962615967\n",
      "40|1.0261983573436737\n",
      "41|57.279184341430664\n",
      "42|0.8126037418842316\n",
      "43|0.7102407515048981\n",
      "44|0.7987150847911835\n",
      "45|0.7580009400844574\n",
      "46|0.8102715313434601\n",
      "47|0.9749234318733215\n",
      "48|0.7857323586940765\n",
      "49|58.79370880126953\n",
      "50|0.6483251452445984\n",
      "51|0.6677360534667969\n",
      "52|0.6878957450389862\n",
      "53|0.7902318835258484\n",
      "54|0.5855598300695419\n",
      "55|1.1188874244689941\n",
      "56|0.700616180896759\n",
      "57|1.562762439250946\n",
      "58|0.585047647356987\n",
      "59|0.9726312756538391\n",
      "60|1.868028074502945\n",
      "61|0.7921716868877411\n",
      "62|0.8111113607883453\n",
      "63|0.873173177242279\n",
      "64|0.7814703285694122\n",
      "65|2.6881298422813416\n",
      "66|0.5570501685142517\n",
      "67|1.9402182772755623\n",
      "68|0.759847491979599\n",
      "69|0.779484748840332\n",
      "70|0.9114914238452911\n",
      "71|0.9975232183933258\n",
      "72|0.6760039031505585\n",
      "73|0.7183680683374405\n",
      "74|0.7225893139839172\n",
      "75|0.9641363322734833\n",
      "76|0.6169871687889099\n",
      "77|0.8506523668766022\n",
      "78|35.372355461120605\n",
      "79|0.7353311777114868\n",
      "80|0.720747709274292\n",
      "81|0.7157372832298279\n",
      "82|1.0360132157802582\n",
      "83|0.6300010085105896\n",
      "84|0.7856374979019165\n",
      "85|0.7339179217815399\n",
      "86|2.3661988973617554\n",
      "87|0.6911300718784332\n",
      "88|0.8371849954128265\n",
      "89|0.7934439182281494\n",
      "90|1.931679580360651\n",
      "91|0.707400768995285\n",
      "92|0.8920473158359528\n",
      "93|0.7204986065626144\n",
      "94|0.7102984189987183\n",
      "95|0.6215191185474396\n",
      "96|1.7196272313594818\n",
      "97|0.7107625007629395\n",
      "98|0.7473300099372864\n",
      "99|0.7504443228244781\n",
      "100|0.9535350203514099\n"
     ]
    }
   ],
   "source": [
    "print(\"Trial Losses (Objective Values) as a Column:\")\n",
    "for i, loss in enumerate(trial_losses):\n",
    "    print(f\"{i + 1}|{loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038538d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
