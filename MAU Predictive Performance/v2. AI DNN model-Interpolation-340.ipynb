{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2449187",
   "metadata": {},
   "source": [
    "# Regression with Deep Neural Network (DNN)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf46af2",
   "metadata": {},
   "source": [
    "In a regression problem, the aim is to predict the output of a continuous value, like a energy consumption, a temperature value or a probability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b62a5c",
   "metadata": {},
   "source": [
    "This file demonstrates how to build models to predict the energy efficiency of the MAU system. To do this, you will provide the models with a description of many MAUs from that a certain period. This description includes attributes like temperature, humidity, airflow, and enthalpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "757b6769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use seaborn for pairplot.\n",
    "!pip install -q seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bcc84e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Make NumPy printouts easier to read.\n",
    "np.set_printoptions(precision=3, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04780b27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.12.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58eaa09e",
   "metadata": {},
   "source": [
    "## Load all MAU entrance data (340 counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd298cf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ï»¿Date</th>\n",
       "      <th>Temperature (Â°F)</th>\n",
       "      <th>Humidity (%)</th>\n",
       "      <th>Density (g/m3)</th>\n",
       "      <th>Enthalpy, h (kJ/kg)</th>\n",
       "      <th>x (g/kg)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22-Feb-24</td>\n",
       "      <td>73.990000</td>\n",
       "      <td>31.990000</td>\n",
       "      <td>6.730000</td>\n",
       "      <td>38.080000</td>\n",
       "      <td>5.680000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22-Feb-24</td>\n",
       "      <td>74.622920</td>\n",
       "      <td>31.448171</td>\n",
       "      <td>6.719617</td>\n",
       "      <td>38.432566</td>\n",
       "      <td>5.679056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22-Feb-24</td>\n",
       "      <td>75.255841</td>\n",
       "      <td>30.906342</td>\n",
       "      <td>6.709233</td>\n",
       "      <td>38.785133</td>\n",
       "      <td>5.678112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22-Feb-24</td>\n",
       "      <td>75.888761</td>\n",
       "      <td>30.364513</td>\n",
       "      <td>6.698850</td>\n",
       "      <td>39.137699</td>\n",
       "      <td>5.677168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22-Feb-24</td>\n",
       "      <td>76.521681</td>\n",
       "      <td>29.822684</td>\n",
       "      <td>6.688466</td>\n",
       "      <td>39.490265</td>\n",
       "      <td>5.676224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>4-Apr-24</td>\n",
       "      <td>87.375858</td>\n",
       "      <td>7.891475</td>\n",
       "      <td>2.500413</td>\n",
       "      <td>36.644631</td>\n",
       "      <td>2.157758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>4-Apr-24</td>\n",
       "      <td>87.211894</td>\n",
       "      <td>7.906106</td>\n",
       "      <td>2.485310</td>\n",
       "      <td>36.520973</td>\n",
       "      <td>2.148319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>4-Apr-24</td>\n",
       "      <td>87.047929</td>\n",
       "      <td>7.920737</td>\n",
       "      <td>2.470206</td>\n",
       "      <td>36.397316</td>\n",
       "      <td>2.138879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>4-Apr-24</td>\n",
       "      <td>86.883965</td>\n",
       "      <td>7.935369</td>\n",
       "      <td>2.455103</td>\n",
       "      <td>36.273658</td>\n",
       "      <td>2.129440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>4-Apr-24</td>\n",
       "      <td>86.720000</td>\n",
       "      <td>7.950000</td>\n",
       "      <td>2.440000</td>\n",
       "      <td>36.150000</td>\n",
       "      <td>2.120000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>340 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ï»¿Date  Temperature (Â°F)  Humidity (%)  Density (g/m3)  \\\n",
       "0    22-Feb-24          73.990000     31.990000        6.730000   \n",
       "1    22-Feb-24          74.622920     31.448171        6.719617   \n",
       "2    22-Feb-24          75.255841     30.906342        6.709233   \n",
       "3    22-Feb-24          75.888761     30.364513        6.698850   \n",
       "4    22-Feb-24          76.521681     29.822684        6.688466   \n",
       "..         ...                ...           ...             ...   \n",
       "335   4-Apr-24          87.375858      7.891475        2.500413   \n",
       "336   4-Apr-24          87.211894      7.906106        2.485310   \n",
       "337   4-Apr-24          87.047929      7.920737        2.470206   \n",
       "338   4-Apr-24          86.883965      7.935369        2.455103   \n",
       "339   4-Apr-24          86.720000      7.950000        2.440000   \n",
       "\n",
       "     Enthalpy, h (kJ/kg)  x (g/kg)  \n",
       "0              38.080000  5.680000  \n",
       "1              38.432566  5.679056  \n",
       "2              38.785133  5.678112  \n",
       "3              39.137699  5.677168  \n",
       "4              39.490265  5.676224  \n",
       "..                   ...       ...  \n",
       "335            36.644631  2.157758  \n",
       "336            36.520973  2.148319  \n",
       "337            36.397316  2.138879  \n",
       "338            36.273658  2.129440  \n",
       "339            36.150000  2.120000  \n",
       "\n",
       "[340 rows x 6 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load entrance data\n",
    "data_entrance = pd.read_csv('/Users/hsiaopingni/Desktop/Hsiao-Ping PhD/Data/MAU_paper/interpolated_data_entrance_340.csv', encoding='unicode_escape')\n",
    "#data_entrance=pd.read_csv(r'C:\\Users\\Hsiao-ping.ni\\ASU Dropbox\\Hsiao-Ping Ni\\PhD\\Data\\3rd paper- MAU\\interpolated_data_entrance_340.csv', encoding='unicode_escape')\n",
    "#data_entrance=pd.read_csv(r'C:\\Users\\nick8\\ASU Dropbox\\Hsiao-Ping Ni\\PhD\\Data\\3rd paper- MAU\\interpolated_data_entrance_340.csv', encoding='unicode_escape')\n",
    "data_entrance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80c1e7b",
   "metadata": {},
   "source": [
    "## Load all MAU exit data (340 counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6f18855",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ï»¿Date</th>\n",
       "      <th>Temperature (Â°F)</th>\n",
       "      <th>Humidity (%)</th>\n",
       "      <th>Density (g/m3)</th>\n",
       "      <th>Enthalpy, h (kJ/kg)</th>\n",
       "      <th>x (g/kg)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22-Feb-24</td>\n",
       "      <td>75.038000</td>\n",
       "      <td>38.790000</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>42.380000</td>\n",
       "      <td>7.170000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22-Feb-24</td>\n",
       "      <td>75.035451</td>\n",
       "      <td>38.760265</td>\n",
       "      <td>8.394336</td>\n",
       "      <td>42.364425</td>\n",
       "      <td>7.163864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22-Feb-24</td>\n",
       "      <td>75.032903</td>\n",
       "      <td>38.730531</td>\n",
       "      <td>8.388673</td>\n",
       "      <td>42.348850</td>\n",
       "      <td>7.157729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22-Feb-24</td>\n",
       "      <td>75.030354</td>\n",
       "      <td>38.700796</td>\n",
       "      <td>8.383009</td>\n",
       "      <td>42.333274</td>\n",
       "      <td>7.151593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22-Feb-24</td>\n",
       "      <td>75.027805</td>\n",
       "      <td>38.671062</td>\n",
       "      <td>8.377345</td>\n",
       "      <td>42.317699</td>\n",
       "      <td>7.145457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>4-Apr-24</td>\n",
       "      <td>75.175204</td>\n",
       "      <td>39.546401</td>\n",
       "      <td>8.624484</td>\n",
       "      <td>42.920088</td>\n",
       "      <td>7.343923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>4-Apr-24</td>\n",
       "      <td>75.176903</td>\n",
       "      <td>39.632301</td>\n",
       "      <td>8.643363</td>\n",
       "      <td>42.962566</td>\n",
       "      <td>7.360442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>4-Apr-24</td>\n",
       "      <td>75.178602</td>\n",
       "      <td>39.718201</td>\n",
       "      <td>8.662242</td>\n",
       "      <td>43.005044</td>\n",
       "      <td>7.376962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>4-Apr-24</td>\n",
       "      <td>75.180301</td>\n",
       "      <td>39.804100</td>\n",
       "      <td>8.681121</td>\n",
       "      <td>43.047522</td>\n",
       "      <td>7.393481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>4-Apr-24</td>\n",
       "      <td>75.182000</td>\n",
       "      <td>39.890000</td>\n",
       "      <td>8.700000</td>\n",
       "      <td>43.090000</td>\n",
       "      <td>7.410000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>340 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ï»¿Date  Temperature (Â°F)  Humidity (%)  Density (g/m3)  \\\n",
       "0    22-Feb-24          75.038000     38.790000        8.400000   \n",
       "1    22-Feb-24          75.035451     38.760265        8.394336   \n",
       "2    22-Feb-24          75.032903     38.730531        8.388673   \n",
       "3    22-Feb-24          75.030354     38.700796        8.383009   \n",
       "4    22-Feb-24          75.027805     38.671062        8.377345   \n",
       "..         ...                ...           ...             ...   \n",
       "335   4-Apr-24          75.175204     39.546401        8.624484   \n",
       "336   4-Apr-24          75.176903     39.632301        8.643363   \n",
       "337   4-Apr-24          75.178602     39.718201        8.662242   \n",
       "338   4-Apr-24          75.180301     39.804100        8.681121   \n",
       "339   4-Apr-24          75.182000     39.890000        8.700000   \n",
       "\n",
       "     Enthalpy, h (kJ/kg)  x (g/kg)  \n",
       "0              42.380000  7.170000  \n",
       "1              42.364425  7.163864  \n",
       "2              42.348850  7.157729  \n",
       "3              42.333274  7.151593  \n",
       "4              42.317699  7.145457  \n",
       "..                   ...       ...  \n",
       "335            42.920088  7.343923  \n",
       "336            42.962566  7.360442  \n",
       "337            43.005044  7.376962  \n",
       "338            43.047522  7.393481  \n",
       "339            43.090000  7.410000  \n",
       "\n",
       "[340 rows x 6 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load exit data\n",
    "data_exit = pd.read_csv('/Users/hsiaopingni/Desktop/Hsiao-Ping PhD/Data/MAU_paper/interpolated_data_exit_340.csv', encoding='unicode_escape')\n",
    "#data_exit=pd.read_csv(r'C:\\Users\\Hsiao-ping.ni\\ASU Dropbox\\Hsiao-Ping Ni\\PhD\\Data\\3rd paper- MAU\\interpolated_data_exit_340.csv', encoding='unicode_escape')\n",
    "#data_exit=pd.read_csv(r'C:\\Users\\nick8\\ASU Dropbox\\Hsiao-Ping Ni\\PhD\\Data\\3rd paper- MAU\\interpolated_data_exit_340.csv', encoding='unicode_escape')\n",
    "data_exit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4941ff",
   "metadata": {},
   "source": [
    "## Split the data into training and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926f127a",
   "metadata": {},
   "source": [
    "Now, split the dataset into a training set and a test set. You will use the test set in the final evaluation of your model.\n",
    "\n",
    "The line of code \"train_dataset = dataset.sample(frac=0.8, random_state=0)\" creates a training dataset by randomly selecting 80% of the rows from the dataset, ensuring that the selection is reproducible by setting a random state. The frac=0.8 parameter specifies that 80% of the data should be sampled, and random_state=0 ensures that the random selection of rows is consistent every time the code is run, facilitating reproducible results in experiments or analyses.\n",
    "\n",
    "The line \"test_dataset = dataset.drop(train_dataset.index)\" removes all rows from dataset that are already included in train_dataset, effectively creating a test dataset. This is achieved by dropping rows indexed in train_dataset.index from the original dataset. The result is a dataset containing 20% of the original data, not selected for training, used for testing model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0899dde3",
   "metadata": {},
   "source": [
    "### Train datasets for MAU entrance (272 counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909af274",
   "metadata": {},
   "source": [
    "Drop 'Count' and 'Which MAU' columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3ae9f3e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature (Â°F)</th>\n",
       "      <th>Humidity (%)</th>\n",
       "      <th>Density (g/m3)</th>\n",
       "      <th>Enthalpy, h (kJ/kg)</th>\n",
       "      <th>x (g/kg)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>82.432389</td>\n",
       "      <td>21.558938</td>\n",
       "      <td>5.652301</td>\n",
       "      <td>40.698496</td>\n",
       "      <td>3.853363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>90.741540</td>\n",
       "      <td>7.450619</td>\n",
       "      <td>2.586018</td>\n",
       "      <td>38.676224</td>\n",
       "      <td>2.266018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>89.065664</td>\n",
       "      <td>13.234513</td>\n",
       "      <td>4.388584</td>\n",
       "      <td>41.770177</td>\n",
       "      <td>3.828584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>90.736442</td>\n",
       "      <td>7.531327</td>\n",
       "      <td>2.615752</td>\n",
       "      <td>38.732861</td>\n",
       "      <td>2.295752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>89.123186</td>\n",
       "      <td>7.933009</td>\n",
       "      <td>2.715605</td>\n",
       "      <td>38.121829</td>\n",
       "      <td>2.302242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>86.009853</td>\n",
       "      <td>14.939794</td>\n",
       "      <td>4.431357</td>\n",
       "      <td>40.262330</td>\n",
       "      <td>3.841121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>87.637345</td>\n",
       "      <td>13.710442</td>\n",
       "      <td>4.404867</td>\n",
       "      <td>41.029646</td>\n",
       "      <td>3.789381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>82.056578</td>\n",
       "      <td>20.541209</td>\n",
       "      <td>5.473481</td>\n",
       "      <td>40.132065</td>\n",
       "      <td>4.702006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>89.293947</td>\n",
       "      <td>7.886283</td>\n",
       "      <td>2.722684</td>\n",
       "      <td>38.225192</td>\n",
       "      <td>2.305074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>86.883965</td>\n",
       "      <td>7.935369</td>\n",
       "      <td>2.455103</td>\n",
       "      <td>36.273658</td>\n",
       "      <td>2.129440</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>272 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Temperature (Â°F)  Humidity (%)  Density (g/m3)  Enthalpy, h (kJ/kg)  \\\n",
       "225          82.432389     21.558938        5.652301            40.698496   \n",
       "271          90.741540      7.450619        2.586018            38.676224   \n",
       "204          89.065664     13.234513        4.388584            41.770177   \n",
       "274          90.736442      7.531327        2.615752            38.732861   \n",
       "299          89.123186      7.933009        2.715605            38.121829   \n",
       "..                 ...           ...             ...                  ...   \n",
       "143          86.009853     14.939794        4.431357            40.262330   \n",
       "180          87.637345     13.710442        4.404867            41.029646   \n",
       "131          82.056578     20.541209        5.473481            40.132065   \n",
       "302          89.293947      7.886283        2.722684            38.225192   \n",
       "338          86.883965      7.935369        2.455103            36.273658   \n",
       "\n",
       "     x (g/kg)  \n",
       "225  3.853363  \n",
       "271  2.266018  \n",
       "204  3.828584  \n",
       "274  2.295752  \n",
       "299  2.302242  \n",
       "..        ...  \n",
       "143  3.841121  \n",
       "180  3.789381  \n",
       "131  4.702006  \n",
       "302  2.305074  \n",
       "338  2.129440  \n",
       "\n",
       "[272 rows x 5 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_entrance = data_entrance.drop(['ï»¿Date'], axis=1)\n",
    "train_dataset_entrance = data_entrance.sample(frac=0.8, random_state=0)\n",
    "test_dataset_entrance = data_entrance.drop(train_dataset_entrance.index)\n",
    "train_dataset_entrance\n",
    "\n",
    "# Spliting data into Feature \n",
    "#X=data[['Humidity (%)','Airflow (g/m^3)','Enthalpy, h (kJ/kg)','x (g/kg)']]\n",
    "#y=data['Temperature (°F)']\n",
    "\n",
    "# Import train_test_split function\n",
    "#from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split dataset into training set and test (validation) set\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)  # 80% training and 20% test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f4ed3e",
   "metadata": {},
   "source": [
    "### Test datasets for MAU entrance (68 counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "360ce48e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature (Â°F)</th>\n",
       "      <th>Humidity (%)</th>\n",
       "      <th>Density (g/m3)</th>\n",
       "      <th>Enthalpy, h (kJ/kg)</th>\n",
       "      <th>x (g/kg)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>79.686283</td>\n",
       "      <td>27.113540</td>\n",
       "      <td>6.636549</td>\n",
       "      <td>41.253097</td>\n",
       "      <td>5.671504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>87.581740</td>\n",
       "      <td>20.427227</td>\n",
       "      <td>6.524395</td>\n",
       "      <td>45.683156</td>\n",
       "      <td>5.674395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>87.724749</td>\n",
       "      <td>20.362094</td>\n",
       "      <td>6.535723</td>\n",
       "      <td>45.787935</td>\n",
       "      <td>5.685723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>87.867758</td>\n",
       "      <td>20.296962</td>\n",
       "      <td>6.547050</td>\n",
       "      <td>45.892714</td>\n",
       "      <td>5.697050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>87.915428</td>\n",
       "      <td>20.275251</td>\n",
       "      <td>6.550826</td>\n",
       "      <td>45.927640</td>\n",
       "      <td>5.700826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>90.033912</td>\n",
       "      <td>7.683805</td>\n",
       "      <td>2.753363</td>\n",
       "      <td>38.673097</td>\n",
       "      <td>2.317345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>89.343434</td>\n",
       "      <td>7.715900</td>\n",
       "      <td>2.681652</td>\n",
       "      <td>38.128525</td>\n",
       "      <td>2.271032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>89.015504</td>\n",
       "      <td>7.745162</td>\n",
       "      <td>2.651445</td>\n",
       "      <td>37.881209</td>\n",
       "      <td>2.252153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>88.687575</td>\n",
       "      <td>7.774425</td>\n",
       "      <td>2.621239</td>\n",
       "      <td>37.633894</td>\n",
       "      <td>2.233274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>88.523611</td>\n",
       "      <td>7.789056</td>\n",
       "      <td>2.606136</td>\n",
       "      <td>37.510236</td>\n",
       "      <td>2.223835</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Temperature (Â°F)  Humidity (%)  Density (g/m3)  Enthalpy, h (kJ/kg)  \\\n",
       "9            79.686283     27.113540        6.636549            41.253097   \n",
       "25           87.581740     20.427227        6.524395            45.683156   \n",
       "28           87.724749     20.362094        6.535723            45.787935   \n",
       "31           87.867758     20.296962        6.547050            45.892714   \n",
       "32           87.915428     20.275251        6.550826            45.927640   \n",
       "..                 ...           ...             ...                  ...   \n",
       "315          90.033912      7.683805        2.753363            38.673097   \n",
       "323          89.343434      7.715900        2.681652            38.128525   \n",
       "325          89.015504      7.745162        2.651445            37.881209   \n",
       "327          88.687575      7.774425        2.621239            37.633894   \n",
       "328          88.523611      7.789056        2.606136            37.510236   \n",
       "\n",
       "     x (g/kg)  \n",
       "9    5.671504  \n",
       "25   5.674395  \n",
       "28   5.685723  \n",
       "31   5.697050  \n",
       "32   5.700826  \n",
       "..        ...  \n",
       "315  2.317345  \n",
       "323  2.271032  \n",
       "325  2.252153  \n",
       "327  2.233274  \n",
       "328  2.223835  \n",
       "\n",
       "[68 rows x 5 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset_entrance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b3aa9a",
   "metadata": {},
   "source": [
    "### Load original entrance data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b451be4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "      <th>Which MAU</th>\n",
       "      <th>Temperature (°F)</th>\n",
       "      <th>Humidity (%)</th>\n",
       "      <th>Density (g/m^3)</th>\n",
       "      <th>Enthalpy, h (kJ/kg)</th>\n",
       "      <th>x (g/kg)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>73.990</td>\n",
       "      <td>31.99</td>\n",
       "      <td>6.73</td>\n",
       "      <td>38.08</td>\n",
       "      <td>5.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>87.400</td>\n",
       "      <td>20.51</td>\n",
       "      <td>6.51</td>\n",
       "      <td>45.55</td>\n",
       "      <td>5.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>88.410</td>\n",
       "      <td>20.05</td>\n",
       "      <td>6.59</td>\n",
       "      <td>46.29</td>\n",
       "      <td>5.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>87.370</td>\n",
       "      <td>20.35</td>\n",
       "      <td>6.45</td>\n",
       "      <td>45.39</td>\n",
       "      <td>5.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>87.330</td>\n",
       "      <td>20.63</td>\n",
       "      <td>6.51</td>\n",
       "      <td>45.59</td>\n",
       "      <td>5.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>75.540</td>\n",
       "      <td>29.08</td>\n",
       "      <td>6.44</td>\n",
       "      <td>38.33</td>\n",
       "      <td>5.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>80.780</td>\n",
       "      <td>22.35</td>\n",
       "      <td>5.81</td>\n",
       "      <td>40.09</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>87.760</td>\n",
       "      <td>12.46</td>\n",
       "      <td>3.97</td>\n",
       "      <td>40.32</td>\n",
       "      <td>3.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>85.660</td>\n",
       "      <td>14.32</td>\n",
       "      <td>4.39</td>\n",
       "      <td>39.87</td>\n",
       "      <td>3.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>89.650</td>\n",
       "      <td>13.09</td>\n",
       "      <td>4.42</td>\n",
       "      <td>42.21</td>\n",
       "      <td>3.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>88.720</td>\n",
       "      <td>13.32</td>\n",
       "      <td>4.37</td>\n",
       "      <td>41.51</td>\n",
       "      <td>3.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>78.570</td>\n",
       "      <td>26.62</td>\n",
       "      <td>6.44</td>\n",
       "      <td>40.20</td>\n",
       "      <td>3.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>90.770</td>\n",
       "      <td>7.00</td>\n",
       "      <td>2.42</td>\n",
       "      <td>38.36</td>\n",
       "      <td>2.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>90.734</td>\n",
       "      <td>7.57</td>\n",
       "      <td>2.63</td>\n",
       "      <td>38.76</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>88.988</td>\n",
       "      <td>7.97</td>\n",
       "      <td>2.71</td>\n",
       "      <td>38.04</td>\n",
       "      <td>2.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>90.194</td>\n",
       "      <td>7.64</td>\n",
       "      <td>2.76</td>\n",
       "      <td>38.77</td>\n",
       "      <td>2.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>86.720</td>\n",
       "      <td>7.95</td>\n",
       "      <td>2.44</td>\n",
       "      <td>36.15</td>\n",
       "      <td>2.12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Count  Which MAU  Temperature (°F)  Humidity (%)  Density (g/m^3)  \\\n",
       "0       1          1            73.990         31.99             6.73   \n",
       "1       2          2            87.400         20.51             6.51   \n",
       "2       3          3            88.410         20.05             6.59   \n",
       "3       4          4            87.370         20.35             6.45   \n",
       "4       5          5            87.330         20.63             6.51   \n",
       "5       6          9            75.540         29.08             6.44   \n",
       "6       7          1            80.780         22.35             5.81   \n",
       "7       8          1            87.760         12.46             3.97   \n",
       "8       9          1            85.660         14.32             4.39   \n",
       "9      10          3            89.650         13.09             4.42   \n",
       "10     11          4            88.720         13.32             4.37   \n",
       "11     12          1            78.570         26.62             6.44   \n",
       "12     13          2            90.770          7.00             2.42   \n",
       "13     14          3            90.734          7.57             2.63   \n",
       "14     15          4            88.988          7.97             2.71   \n",
       "15     16          5            90.194          7.64             2.76   \n",
       "16     17          6            86.720          7.95             2.44   \n",
       "\n",
       "    Enthalpy, h (kJ/kg)  x (g/kg)  \n",
       "0                 38.08      5.68  \n",
       "1                 45.55      5.66  \n",
       "2                 46.29      5.74  \n",
       "3                 45.39      5.60  \n",
       "4                 45.59      5.66  \n",
       "5                 38.33      5.46  \n",
       "6                 40.09      4.98  \n",
       "7                 40.32      3.46  \n",
       "8                 39.87      3.72  \n",
       "9                 42.21      3.86  \n",
       "10                41.51      3.81  \n",
       "11                40.20      3.88  \n",
       "12                38.36      2.10  \n",
       "13                38.76      2.31  \n",
       "14                38.04      2.30  \n",
       "15                38.77      2.32  \n",
       "16                36.15      2.12  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load entrance data\n",
    "ori_data_entrance = pd.read_csv('/Users/hsiaopingni/Desktop/Hsiao-Ping PhD/Data/MAU_paper/AI_model_MAU_Entrance.csv', encoding='unicode_escape')\n",
    "#ori_data_entrance=pd.read_csv(r'C:\\Users\\Hsiao-ping.ni\\ASU Dropbox\\Hsiao-Ping Ni\\PhD\\Data\\3rd paper- MAU\\AI_model_MAU_Entrance.csv', encoding='unicode_escape')\n",
    "#ori_data_entrance=pd.read_csv(r'C:\\Users\\nick8\\ASU Dropbox\\Hsiao-Ping Ni\\PhD\\Data\\3rd paper- MAU\\AI_model_MAU_Entrance.csv', encoding='unicode_escape')\n",
    "ori_data_entrance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f180f46",
   "metadata": {},
   "source": [
    "### Original test datasets for MAU entrance (3 counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2d2233bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "      <th>Which MAU</th>\n",
       "      <th>Temperature (°F)</th>\n",
       "      <th>Humidity (%)</th>\n",
       "      <th>Density (g/m^3)</th>\n",
       "      <th>Enthalpy, h (kJ/kg)</th>\n",
       "      <th>x (g/kg)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>75.540</td>\n",
       "      <td>29.08</td>\n",
       "      <td>6.44</td>\n",
       "      <td>38.33</td>\n",
       "      <td>5.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>90.770</td>\n",
       "      <td>7.00</td>\n",
       "      <td>2.42</td>\n",
       "      <td>38.36</td>\n",
       "      <td>2.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>90.194</td>\n",
       "      <td>7.64</td>\n",
       "      <td>2.76</td>\n",
       "      <td>38.77</td>\n",
       "      <td>2.32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Count  Which MAU  Temperature (°F)  Humidity (%)  Density (g/m^3)  \\\n",
       "5       6          9            75.540         29.08             6.44   \n",
       "12     13          2            90.770          7.00             2.42   \n",
       "15     16          5            90.194          7.64             2.76   \n",
       "\n",
       "    Enthalpy, h (kJ/kg)  x (g/kg)  \n",
       "5                 38.33      5.46  \n",
       "12                38.36      2.10  \n",
       "15                38.77      2.32  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ori_test_entrance = ori_data_entrance.iloc[[5, 12, 15]]\n",
    "ori_test_entrance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe38de2f",
   "metadata": {},
   "source": [
    "### Train datasets for MAU exit (272 counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fcaa78ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature (Â°F)</th>\n",
       "      <th>Humidity (%)</th>\n",
       "      <th>Density (g/m3)</th>\n",
       "      <th>Enthalpy, h (kJ/kg)</th>\n",
       "      <th>x (g/kg)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>74.742035</td>\n",
       "      <td>38.651416</td>\n",
       "      <td>8.330885</td>\n",
       "      <td>42.033982</td>\n",
       "      <td>7.139027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>75.130920</td>\n",
       "      <td>38.991298</td>\n",
       "      <td>8.486490</td>\n",
       "      <td>42.588319</td>\n",
       "      <td>7.228584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>75.096619</td>\n",
       "      <td>38.919027</td>\n",
       "      <td>8.478319</td>\n",
       "      <td>42.572920</td>\n",
       "      <td>7.210885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>75.141115</td>\n",
       "      <td>39.091829</td>\n",
       "      <td>8.509145</td>\n",
       "      <td>42.643540</td>\n",
       "      <td>7.249823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>75.082071</td>\n",
       "      <td>42.021180</td>\n",
       "      <td>8.450944</td>\n",
       "      <td>42.483009</td>\n",
       "      <td>7.193186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>74.822053</td>\n",
       "      <td>38.504690</td>\n",
       "      <td>8.304956</td>\n",
       "      <td>42.012419</td>\n",
       "      <td>7.067463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>74.983204</td>\n",
       "      <td>38.941504</td>\n",
       "      <td>8.696195</td>\n",
       "      <td>42.417257</td>\n",
       "      <td>7.436372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>74.862832</td>\n",
       "      <td>38.266814</td>\n",
       "      <td>8.270973</td>\n",
       "      <td>41.950118</td>\n",
       "      <td>7.039145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>75.092265</td>\n",
       "      <td>41.391091</td>\n",
       "      <td>8.426873</td>\n",
       "      <td>42.436283</td>\n",
       "      <td>7.171947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>75.180301</td>\n",
       "      <td>39.804100</td>\n",
       "      <td>8.681121</td>\n",
       "      <td>43.047522</td>\n",
       "      <td>7.393481</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>272 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Temperature (Â°F)  Humidity (%)  Density (g/m3)  Enthalpy, h (kJ/kg)  \\\n",
       "225          74.742035     38.651416        8.330885            42.033982   \n",
       "271          75.130920     38.991298        8.486490            42.588319   \n",
       "204          75.096619     38.919027        8.478319            42.572920   \n",
       "274          75.141115     39.091829        8.509145            42.643540   \n",
       "299          75.082071     42.021180        8.450944            42.483009   \n",
       "..                 ...           ...             ...                  ...   \n",
       "143          74.822053     38.504690        8.304956            42.012419   \n",
       "180          74.983204     38.941504        8.696195            42.417257   \n",
       "131          74.862832     38.266814        8.270973            41.950118   \n",
       "302          75.092265     41.391091        8.426873            42.436283   \n",
       "338          75.180301     39.804100        8.681121            43.047522   \n",
       "\n",
       "     x (g/kg)  \n",
       "225  7.139027  \n",
       "271  7.228584  \n",
       "204  7.210885  \n",
       "274  7.249823  \n",
       "299  7.193186  \n",
       "..        ...  \n",
       "143  7.067463  \n",
       "180  7.436372  \n",
       "131  7.039145  \n",
       "302  7.171947  \n",
       "338  7.393481  \n",
       "\n",
       "[272 rows x 5 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_exit = data_exit.drop(['ï»¿Date'], axis=1)\n",
    "train_dataset_exit = data_exit.sample(frac=0.8, random_state=0)\n",
    "test_dataset_exit = data_exit.drop(train_dataset_exit.index)\n",
    "train_dataset_exit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67a3cca",
   "metadata": {},
   "source": [
    "### Test datasets for MAU exit (68 counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bb8dbaca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature (Â°F)</th>\n",
       "      <th>Humidity (%)</th>\n",
       "      <th>Density (g/m3)</th>\n",
       "      <th>Enthalpy, h (kJ/kg)</th>\n",
       "      <th>x (g/kg)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>75.015062</td>\n",
       "      <td>38.522389</td>\n",
       "      <td>8.349027</td>\n",
       "      <td>42.239823</td>\n",
       "      <td>7.114779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>75.003434</td>\n",
       "      <td>38.480295</td>\n",
       "      <td>8.351976</td>\n",
       "      <td>42.219145</td>\n",
       "      <td>7.104779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>75.018726</td>\n",
       "      <td>38.732330</td>\n",
       "      <td>8.408614</td>\n",
       "      <td>42.352242</td>\n",
       "      <td>7.155752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>75.034018</td>\n",
       "      <td>38.984366</td>\n",
       "      <td>8.465251</td>\n",
       "      <td>42.485339</td>\n",
       "      <td>7.206726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>75.039115</td>\n",
       "      <td>39.068378</td>\n",
       "      <td>8.484130</td>\n",
       "      <td>42.529705</td>\n",
       "      <td>7.223717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>75.136442</td>\n",
       "      <td>38.660708</td>\n",
       "      <td>8.322566</td>\n",
       "      <td>42.233805</td>\n",
       "      <td>7.079912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>75.154814</td>\n",
       "      <td>38.515605</td>\n",
       "      <td>8.397935</td>\n",
       "      <td>42.410354</td>\n",
       "      <td>7.145693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>75.158212</td>\n",
       "      <td>38.687404</td>\n",
       "      <td>8.435693</td>\n",
       "      <td>42.495310</td>\n",
       "      <td>7.178732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>75.161611</td>\n",
       "      <td>38.859204</td>\n",
       "      <td>8.473451</td>\n",
       "      <td>42.580265</td>\n",
       "      <td>7.211770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>75.163310</td>\n",
       "      <td>38.945103</td>\n",
       "      <td>8.492330</td>\n",
       "      <td>42.622743</td>\n",
       "      <td>7.228289</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Temperature (Â°F)  Humidity (%)  Density (g/m3)  Enthalpy, h (kJ/kg)  \\\n",
       "9            75.015062     38.522389        8.349027            42.239823   \n",
       "25           75.003434     38.480295        8.351976            42.219145   \n",
       "28           75.018726     38.732330        8.408614            42.352242   \n",
       "31           75.034018     38.984366        8.465251            42.485339   \n",
       "32           75.039115     39.068378        8.484130            42.529705   \n",
       "..                 ...           ...             ...                  ...   \n",
       "315          75.136442     38.660708        8.322566            42.233805   \n",
       "323          75.154814     38.515605        8.397935            42.410354   \n",
       "325          75.158212     38.687404        8.435693            42.495310   \n",
       "327          75.161611     38.859204        8.473451            42.580265   \n",
       "328          75.163310     38.945103        8.492330            42.622743   \n",
       "\n",
       "     x (g/kg)  \n",
       "9    7.114779  \n",
       "25   7.104779  \n",
       "28   7.155752  \n",
       "31   7.206726  \n",
       "32   7.223717  \n",
       "..        ...  \n",
       "315  7.079912  \n",
       "323  7.145693  \n",
       "325  7.178732  \n",
       "327  7.211770  \n",
       "328  7.228289  \n",
       "\n",
       "[68 rows x 5 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset_exit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46524ce4",
   "metadata": {},
   "source": [
    "### Load original exit data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8a66534a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "      <th>Which MAU</th>\n",
       "      <th>Temperature (°F)</th>\n",
       "      <th>Humidity (%)</th>\n",
       "      <th>Density (g/m^3)</th>\n",
       "      <th>Enthalpy, h (kJ/kg)</th>\n",
       "      <th>x (g/kg)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>75.038</td>\n",
       "      <td>38.79</td>\n",
       "      <td>8.40</td>\n",
       "      <td>42.38</td>\n",
       "      <td>7.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>74.984</td>\n",
       "      <td>38.16</td>\n",
       "      <td>8.28</td>\n",
       "      <td>42.05</td>\n",
       "      <td>7.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>75.092</td>\n",
       "      <td>39.94</td>\n",
       "      <td>8.68</td>\n",
       "      <td>42.99</td>\n",
       "      <td>7.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>75.020</td>\n",
       "      <td>39.08</td>\n",
       "      <td>8.48</td>\n",
       "      <td>42.52</td>\n",
       "      <td>2.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>75.038</td>\n",
       "      <td>38.89</td>\n",
       "      <td>8.45</td>\n",
       "      <td>42.45</td>\n",
       "      <td>7.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>75.110</td>\n",
       "      <td>38.80</td>\n",
       "      <td>8.45</td>\n",
       "      <td>42.50</td>\n",
       "      <td>7.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>74.876</td>\n",
       "      <td>38.19</td>\n",
       "      <td>8.26</td>\n",
       "      <td>41.93</td>\n",
       "      <td>7.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>74.804</td>\n",
       "      <td>38.61</td>\n",
       "      <td>8.32</td>\n",
       "      <td>42.04</td>\n",
       "      <td>7.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>74.894</td>\n",
       "      <td>38.55</td>\n",
       "      <td>8.83</td>\n",
       "      <td>42.11</td>\n",
       "      <td>7.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>75.074</td>\n",
       "      <td>39.34</td>\n",
       "      <td>8.56</td>\n",
       "      <td>42.73</td>\n",
       "      <td>7.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>75.110</td>\n",
       "      <td>38.67</td>\n",
       "      <td>8.43</td>\n",
       "      <td>42.48</td>\n",
       "      <td>7.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>74.516</td>\n",
       "      <td>38.64</td>\n",
       "      <td>8.27</td>\n",
       "      <td>41.76</td>\n",
       "      <td>7.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>75.074</td>\n",
       "      <td>38.43</td>\n",
       "      <td>8.36</td>\n",
       "      <td>42.28</td>\n",
       "      <td>7.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>75.146</td>\n",
       "      <td>39.14</td>\n",
       "      <td>8.52</td>\n",
       "      <td>42.67</td>\n",
       "      <td>7.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>75.074</td>\n",
       "      <td>42.52</td>\n",
       "      <td>8.47</td>\n",
       "      <td>42.52</td>\n",
       "      <td>7.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>75.146</td>\n",
       "      <td>38.07</td>\n",
       "      <td>8.30</td>\n",
       "      <td>42.19</td>\n",
       "      <td>7.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>75.182</td>\n",
       "      <td>39.89</td>\n",
       "      <td>8.70</td>\n",
       "      <td>43.09</td>\n",
       "      <td>7.41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Count  Which MAU  Temperature (°F)  Humidity (%)   Density (g/m^3)  \\\n",
       "0       1          1            75.038         38.79              8.40   \n",
       "1       2          2            74.984         38.16              8.28   \n",
       "2       3          3            75.092         39.94              8.68   \n",
       "3       4          4            75.020         39.08              8.48   \n",
       "4       5          5            75.038         38.89              8.45   \n",
       "5       6          9            75.110         38.80              8.45   \n",
       "6       7          1            74.876         38.19              8.26   \n",
       "7       8          1            74.804         38.61              8.32   \n",
       "8       9          1            74.894         38.55              8.83   \n",
       "9      10          3            75.074         39.34              8.56   \n",
       "10     11          4            75.110         38.67              8.43   \n",
       "11     12          1            74.516         38.64              8.27   \n",
       "12     13          2            75.074         38.43              8.36   \n",
       "13     14          3            75.146         39.14              8.52   \n",
       "14     15          4            75.074         42.52              8.47   \n",
       "15     16          5            75.146         38.07              8.30   \n",
       "16     17          6            75.182         39.89              8.70   \n",
       "\n",
       "     Enthalpy, h (kJ/kg)   x (g/kg)  \n",
       "0                  42.38       7.17  \n",
       "1                  42.05       7.04  \n",
       "2                  42.99       7.40  \n",
       "3                  42.52       2.22  \n",
       "4                  42.45       7.19  \n",
       "5                  42.50       7.19  \n",
       "6                  41.93       7.03  \n",
       "7                  42.04       7.08  \n",
       "8                  42.11       7.59  \n",
       "9                  42.73       7.28  \n",
       "10                 42.48       7.17  \n",
       "11                 41.76       7.12  \n",
       "12                 42.28       7.11  \n",
       "13                 42.67       7.26  \n",
       "14                 42.52       7.21  \n",
       "15                 42.19       7.06  \n",
       "16                 43.09       7.41  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load exit data\n",
    "ori_data_exit = pd.read_csv('/Users/hsiaopingni/Desktop/Hsiao-Ping PhD/Data/MAU_paper/AI_model_MAU_Exit.csv', encoding='unicode_escape')\n",
    "#ori_data_exit=pd.read_csv(r'C:\\Users\\Hsiao-ping.ni\\ASU Dropbox\\Hsiao-Ping Ni\\PhD\\Data\\3rd paper- MAU\\AI_model_MAU_Exit.csv', encoding='unicode_escape')\n",
    "#ori_data_exit=pd.read_csv(r'C:\\Users\\nick8\\ASU Dropbox\\Hsiao-Ping Ni\\PhD\\Data\\3rd paper- MAU\\AI_model_MAU_Exit.csv', encoding='unicode_escape')\n",
    "ori_data_exit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a61893",
   "metadata": {},
   "source": [
    "### Original test datasets for MAU exit (3 counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "81c592f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "      <th>Which MAU</th>\n",
       "      <th>Temperature (°F)</th>\n",
       "      <th>Humidity (%)</th>\n",
       "      <th>Density (g/m^3)</th>\n",
       "      <th>Enthalpy, h (kJ/kg)</th>\n",
       "      <th>x (g/kg)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>75.110</td>\n",
       "      <td>38.80</td>\n",
       "      <td>8.45</td>\n",
       "      <td>42.50</td>\n",
       "      <td>7.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>75.074</td>\n",
       "      <td>38.43</td>\n",
       "      <td>8.36</td>\n",
       "      <td>42.28</td>\n",
       "      <td>7.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>75.146</td>\n",
       "      <td>38.07</td>\n",
       "      <td>8.30</td>\n",
       "      <td>42.19</td>\n",
       "      <td>7.06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Count  Which MAU  Temperature (°F)  Humidity (%)   Density (g/m^3)  \\\n",
       "5       6          9            75.110         38.80              8.45   \n",
       "12     13          2            75.074         38.43              8.36   \n",
       "15     16          5            75.146         38.07              8.30   \n",
       "\n",
       "     Enthalpy, h (kJ/kg)   x (g/kg)  \n",
       "5                  42.50       7.19  \n",
       "12                 42.28       7.11  \n",
       "15                 42.19       7.06  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ori_test_exit = ori_data_exit.iloc[[5, 12, 15]]\n",
    "ori_test_exit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb1ad4a",
   "metadata": {},
   "source": [
    "## Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478de120",
   "metadata": {},
   "source": [
    "Let's check the overall statistics. Note how each feature covers a very different range.\n",
    "\n",
    ".describe(): This method generates descriptive statistics that summarize the central tendency, dispersion, and shape of the dataset's distribution, excluding NaN values. By default, it provides information such as count (number of non-missing values), mean, standard deviation (std), minimum, 25th percentile (25%), median (50th percentile), 75th percentile (75%), and maximum for numeric columns.\n",
    "\n",
    ".transpose() or .T: This method transposes the DataFrame, swapping its rows and columns. After calling .describe(), the resulting DataFrame has the descriptive statistics as rows and the features (or columns of the original dataset) as columns. Transposing flips this layout, so the features become rows and the descriptive statistics become columns. This often makes the output more readable and easier to analyze, especially if the dataset has many features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248e88be",
   "metadata": {},
   "source": [
    "### Train datasets for MAU entrance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9344f266",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Temperature (Â°F)</th>\n",
       "      <td>272.0</td>\n",
       "      <td>85.882523</td>\n",
       "      <td>4.104426</td>\n",
       "      <td>73.990000</td>\n",
       "      <td>83.386460</td>\n",
       "      <td>87.349351</td>\n",
       "      <td>88.939381</td>\n",
       "      <td>90.768726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Humidity (%)</th>\n",
       "      <td>272.0</td>\n",
       "      <td>16.789624</td>\n",
       "      <td>6.797241</td>\n",
       "      <td>7.020177</td>\n",
       "      <td>12.355664</td>\n",
       "      <td>17.219277</td>\n",
       "      <td>21.036438</td>\n",
       "      <td>31.990000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Density (g/m3)</th>\n",
       "      <td>272.0</td>\n",
       "      <td>4.872189</td>\n",
       "      <td>1.547741</td>\n",
       "      <td>2.427434</td>\n",
       "      <td>3.558407</td>\n",
       "      <td>4.902345</td>\n",
       "      <td>6.473009</td>\n",
       "      <td>6.730000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Enthalpy, h (kJ/kg)</th>\n",
       "      <td>272.0</td>\n",
       "      <td>41.007276</td>\n",
       "      <td>2.724847</td>\n",
       "      <td>36.150000</td>\n",
       "      <td>38.723702</td>\n",
       "      <td>40.219676</td>\n",
       "      <td>42.108938</td>\n",
       "      <td>46.263451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x (g/kg)</th>\n",
       "      <td>272.0</td>\n",
       "      <td>4.083345</td>\n",
       "      <td>1.332594</td>\n",
       "      <td>2.107434</td>\n",
       "      <td>2.604071</td>\n",
       "      <td>3.841681</td>\n",
       "      <td>5.610354</td>\n",
       "      <td>5.735870</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     count       mean       std        min        25%  \\\n",
       "Temperature (Â°F)    272.0  85.882523  4.104426  73.990000  83.386460   \n",
       "Humidity (%)         272.0  16.789624  6.797241   7.020177  12.355664   \n",
       "Density (g/m3)       272.0   4.872189  1.547741   2.427434   3.558407   \n",
       "Enthalpy, h (kJ/kg)  272.0  41.007276  2.724847  36.150000  38.723702   \n",
       "x (g/kg)             272.0   4.083345  1.332594   2.107434   2.604071   \n",
       "\n",
       "                           50%        75%        max  \n",
       "Temperature (Â°F)    87.349351  88.939381  90.768726  \n",
       "Humidity (%)         17.219277  21.036438  31.990000  \n",
       "Density (g/m3)        4.902345   6.473009   6.730000  \n",
       "Enthalpy, h (kJ/kg)  40.219676  42.108938  46.263451  \n",
       "x (g/kg)              3.841681   5.610354   5.735870  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset_entrance.describe().transpose()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6188981e",
   "metadata": {},
   "source": [
    "### Train datasets for MAU exit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e38f405b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Temperature (Â°F)</th>\n",
       "      <td>272.0</td>\n",
       "      <td>74.996852</td>\n",
       "      <td>0.137332</td>\n",
       "      <td>74.517752</td>\n",
       "      <td>74.910447</td>\n",
       "      <td>75.033540</td>\n",
       "      <td>75.090487</td>\n",
       "      <td>75.182000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Humidity (%)</th>\n",
       "      <td>272.0</td>\n",
       "      <td>38.986088</td>\n",
       "      <td>0.760959</td>\n",
       "      <td>38.086106</td>\n",
       "      <td>38.567301</td>\n",
       "      <td>38.758496</td>\n",
       "      <td>39.129860</td>\n",
       "      <td>42.441239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Density (g/m3)</th>\n",
       "      <td>272.0</td>\n",
       "      <td>8.446702</td>\n",
       "      <td>0.126381</td>\n",
       "      <td>8.265310</td>\n",
       "      <td>8.341696</td>\n",
       "      <td>8.449720</td>\n",
       "      <td>8.509167</td>\n",
       "      <td>8.823628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Enthalpy, h (kJ/kg)</th>\n",
       "      <td>272.0</td>\n",
       "      <td>42.361219</td>\n",
       "      <td>0.279928</td>\n",
       "      <td>41.762124</td>\n",
       "      <td>42.107522</td>\n",
       "      <td>42.390133</td>\n",
       "      <td>42.541268</td>\n",
       "      <td>43.090000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x (g/kg)</th>\n",
       "      <td>272.0</td>\n",
       "      <td>6.863280</td>\n",
       "      <td>1.010208</td>\n",
       "      <td>2.322625</td>\n",
       "      <td>7.077109</td>\n",
       "      <td>7.150767</td>\n",
       "      <td>7.228142</td>\n",
       "      <td>7.582684</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     count       mean       std        min        25%  \\\n",
       "Temperature (Â°F)    272.0  74.996852  0.137332  74.517752  74.910447   \n",
       "Humidity (%)         272.0  38.986088  0.760959  38.086106  38.567301   \n",
       "Density (g/m3)       272.0   8.446702  0.126381   8.265310   8.341696   \n",
       "Enthalpy, h (kJ/kg)  272.0  42.361219  0.279928  41.762124  42.107522   \n",
       "x (g/kg)             272.0   6.863280  1.010208   2.322625   7.077109   \n",
       "\n",
       "                           50%        75%        max  \n",
       "Temperature (Â°F)    75.033540  75.090487  75.182000  \n",
       "Humidity (%)         38.758496  39.129860  42.441239  \n",
       "Density (g/m3)        8.449720   8.509167   8.823628  \n",
       "Enthalpy, h (kJ/kg)  42.390133  42.541268  43.090000  \n",
       "x (g/kg)              7.150767   7.228142   7.582684  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset_exit.describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39af1dc6",
   "metadata": {},
   "source": [
    "## Split features from labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8512c35e",
   "metadata": {},
   "source": [
    "Separate the target value—the \"label\"—from the features. This label is the value that you will train the model to predict.\n",
    "\n",
    "train_features = train_dataset.copy(): This line creates a copy of the train_dataset DataFrame and assigns it to train_features. The .copy() method ensures that the original dataset remains unchanged when modifications are made to train_features. This dataset contains the features used to train the machine learning model.\n",
    "\n",
    "test_features = test_dataset.copy(): Similarly, this line duplicates the test_dataset DataFrame, storing the copy in test_features. This is done to preserve the original test_dataset while allowing modifications on test_features. This dataset is used to evaluate the model's performance after training.\n",
    "\n",
    "train_labels = train_features.pop('Temperature (°F)'): The .pop() method removes the column named 'Temperature (°F)' from train_features and returns it. This removed column is then stored in train_labels. In our machine learning context, 'Temperature (°F)' is considered the target variable (or label) that the model will be trained to predict. By doing this, train_features now only contains the input features (or independent variables) for the training data, while train_labels holds the corresponding target values.\n",
    "\n",
    "test_labels = test_features.pop('Temperature (°F)'): This line does the same operation as the previous one but for the testing dataset. It removes the 'Temperature (°F)' column from test_features and stores it in test_labels. Now, test_features only includes the input features for the testing data, and test_labels contains the corresponding target values that will be used to evaluate the model's predictive accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a918516",
   "metadata": {},
   "source": [
    "### Train and test features, and train and test labels for MAU entrance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ed65d195",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_entrance = train_dataset_entrance.copy()\n",
    "test_features_entrance = test_dataset_entrance.copy()\n",
    "train_labels_entrance = train_features_entrance.pop('Temperature (Â°F)')\n",
    "test_labels_entrance = test_features_entrance.pop('Temperature (Â°F)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0e1233d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original\n",
    "ori_test_features_entrance = ori_test_entrance.copy()\n",
    "ori_test_labels_entrance = ori_test_features_entrance.pop('Temperature (°F)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e2479641",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Humidity (%)</th>\n",
       "      <th>Density (g/m3)</th>\n",
       "      <th>Enthalpy, h (kJ/kg)</th>\n",
       "      <th>x (g/kg)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>21.558938</td>\n",
       "      <td>5.652301</td>\n",
       "      <td>40.698496</td>\n",
       "      <td>3.853363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>7.450619</td>\n",
       "      <td>2.586018</td>\n",
       "      <td>38.676224</td>\n",
       "      <td>2.266018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>13.234513</td>\n",
       "      <td>4.388584</td>\n",
       "      <td>41.770177</td>\n",
       "      <td>3.828584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>7.531327</td>\n",
       "      <td>2.615752</td>\n",
       "      <td>38.732861</td>\n",
       "      <td>2.295752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>7.933009</td>\n",
       "      <td>2.715605</td>\n",
       "      <td>38.121829</td>\n",
       "      <td>2.302242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>14.939794</td>\n",
       "      <td>4.431357</td>\n",
       "      <td>40.262330</td>\n",
       "      <td>3.841121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>13.710442</td>\n",
       "      <td>4.404867</td>\n",
       "      <td>41.029646</td>\n",
       "      <td>3.789381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>20.541209</td>\n",
       "      <td>5.473481</td>\n",
       "      <td>40.132065</td>\n",
       "      <td>4.702006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>7.886283</td>\n",
       "      <td>2.722684</td>\n",
       "      <td>38.225192</td>\n",
       "      <td>2.305074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>7.935369</td>\n",
       "      <td>2.455103</td>\n",
       "      <td>36.273658</td>\n",
       "      <td>2.129440</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>272 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Humidity (%)  Density (g/m3)  Enthalpy, h (kJ/kg)  x (g/kg)\n",
       "225     21.558938        5.652301            40.698496  3.853363\n",
       "271      7.450619        2.586018            38.676224  2.266018\n",
       "204     13.234513        4.388584            41.770177  3.828584\n",
       "274      7.531327        2.615752            38.732861  2.295752\n",
       "299      7.933009        2.715605            38.121829  2.302242\n",
       "..            ...             ...                  ...       ...\n",
       "143     14.939794        4.431357            40.262330  3.841121\n",
       "180     13.710442        4.404867            41.029646  3.789381\n",
       "131     20.541209        5.473481            40.132065  4.702006\n",
       "302      7.886283        2.722684            38.225192  2.305074\n",
       "338      7.935369        2.455103            36.273658  2.129440\n",
       "\n",
       "[272 rows x 4 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features_entrance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c1a40da4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Humidity (%)</th>\n",
       "      <th>Density (g/m3)</th>\n",
       "      <th>Enthalpy, h (kJ/kg)</th>\n",
       "      <th>x (g/kg)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>27.113540</td>\n",
       "      <td>6.636549</td>\n",
       "      <td>41.253097</td>\n",
       "      <td>5.671504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>20.427227</td>\n",
       "      <td>6.524395</td>\n",
       "      <td>45.683156</td>\n",
       "      <td>5.674395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>20.362094</td>\n",
       "      <td>6.535723</td>\n",
       "      <td>45.787935</td>\n",
       "      <td>5.685723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>20.296962</td>\n",
       "      <td>6.547050</td>\n",
       "      <td>45.892714</td>\n",
       "      <td>5.697050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>20.275251</td>\n",
       "      <td>6.550826</td>\n",
       "      <td>45.927640</td>\n",
       "      <td>5.700826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>7.683805</td>\n",
       "      <td>2.753363</td>\n",
       "      <td>38.673097</td>\n",
       "      <td>2.317345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>7.715900</td>\n",
       "      <td>2.681652</td>\n",
       "      <td>38.128525</td>\n",
       "      <td>2.271032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>7.745162</td>\n",
       "      <td>2.651445</td>\n",
       "      <td>37.881209</td>\n",
       "      <td>2.252153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>7.774425</td>\n",
       "      <td>2.621239</td>\n",
       "      <td>37.633894</td>\n",
       "      <td>2.233274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>7.789056</td>\n",
       "      <td>2.606136</td>\n",
       "      <td>37.510236</td>\n",
       "      <td>2.223835</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Humidity (%)  Density (g/m3)  Enthalpy, h (kJ/kg)  x (g/kg)\n",
       "9       27.113540        6.636549            41.253097  5.671504\n",
       "25      20.427227        6.524395            45.683156  5.674395\n",
       "28      20.362094        6.535723            45.787935  5.685723\n",
       "31      20.296962        6.547050            45.892714  5.697050\n",
       "32      20.275251        6.550826            45.927640  5.700826\n",
       "..            ...             ...                  ...       ...\n",
       "315      7.683805        2.753363            38.673097  2.317345\n",
       "323      7.715900        2.681652            38.128525  2.271032\n",
       "325      7.745162        2.651445            37.881209  2.252153\n",
       "327      7.774425        2.621239            37.633894  2.233274\n",
       "328      7.789056        2.606136            37.510236  2.223835\n",
       "\n",
       "[68 rows x 4 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_features_entrance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ed631325",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Humidity (%)</th>\n",
       "      <th>Density (g/m^3)</th>\n",
       "      <th>Enthalpy, h (kJ/kg)</th>\n",
       "      <th>x (g/kg)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>29.08</td>\n",
       "      <td>6.44</td>\n",
       "      <td>38.33</td>\n",
       "      <td>5.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7.00</td>\n",
       "      <td>2.42</td>\n",
       "      <td>38.36</td>\n",
       "      <td>2.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7.64</td>\n",
       "      <td>2.76</td>\n",
       "      <td>38.77</td>\n",
       "      <td>2.32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Humidity (%)  Density (g/m^3)  Enthalpy, h (kJ/kg)  x (g/kg)\n",
       "5          29.08             6.44                38.33      5.46\n",
       "12          7.00             2.42                38.36      2.10\n",
       "15          7.64             2.76                38.77      2.32"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ori_test_features_entrance = ori_test_features_entrance.drop(['Count','Which MAU'], axis=1)\n",
    "ori_test_features_entrance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "04f9d966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "225    82.432389\n",
       "271    90.741540\n",
       "204    89.065664\n",
       "274    90.736442\n",
       "299    89.123186\n",
       "         ...    \n",
       "143    86.009853\n",
       "180    87.637345\n",
       "131    82.056578\n",
       "302    89.293947\n",
       "338    86.883965\n",
       "Name: Temperature (Â°F), Length: 272, dtype: float64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels_entrance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fd346d9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9      79.686283\n",
       "25     87.581740\n",
       "28     87.724749\n",
       "31     87.867758\n",
       "32     87.915428\n",
       "         ...    \n",
       "315    90.033912\n",
       "323    89.343434\n",
       "325    89.015504\n",
       "327    88.687575\n",
       "328    88.523611\n",
       "Name: Temperature (Â°F), Length: 68, dtype: float64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels_entrance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd02152",
   "metadata": {},
   "source": [
    "### Train and test features, and train and test labels for MAU exit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a99eca75",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_exit = train_dataset_exit.copy()\n",
    "test_features_exit = test_dataset_exit.copy()\n",
    "train_labels_exit = train_features_exit.pop('Temperature (Â°F)')\n",
    "test_labels_exit = test_features_exit.pop('Temperature (Â°F)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b45ff786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original\n",
    "ori_test_features_exit = ori_test_exit.copy()\n",
    "ori_test_labels_exit = ori_test_features_exit.pop('Temperature (°F)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0ba7c11c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Humidity (%)</th>\n",
       "      <th>Density (g/m3)</th>\n",
       "      <th>Enthalpy, h (kJ/kg)</th>\n",
       "      <th>x (g/kg)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>38.651416</td>\n",
       "      <td>8.330885</td>\n",
       "      <td>42.033982</td>\n",
       "      <td>7.139027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>38.991298</td>\n",
       "      <td>8.486490</td>\n",
       "      <td>42.588319</td>\n",
       "      <td>7.228584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>38.919027</td>\n",
       "      <td>8.478319</td>\n",
       "      <td>42.572920</td>\n",
       "      <td>7.210885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>39.091829</td>\n",
       "      <td>8.509145</td>\n",
       "      <td>42.643540</td>\n",
       "      <td>7.249823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>42.021180</td>\n",
       "      <td>8.450944</td>\n",
       "      <td>42.483009</td>\n",
       "      <td>7.193186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>38.504690</td>\n",
       "      <td>8.304956</td>\n",
       "      <td>42.012419</td>\n",
       "      <td>7.067463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>38.941504</td>\n",
       "      <td>8.696195</td>\n",
       "      <td>42.417257</td>\n",
       "      <td>7.436372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>38.266814</td>\n",
       "      <td>8.270973</td>\n",
       "      <td>41.950118</td>\n",
       "      <td>7.039145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>41.391091</td>\n",
       "      <td>8.426873</td>\n",
       "      <td>42.436283</td>\n",
       "      <td>7.171947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>39.804100</td>\n",
       "      <td>8.681121</td>\n",
       "      <td>43.047522</td>\n",
       "      <td>7.393481</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>272 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Humidity (%)  Density (g/m3)  Enthalpy, h (kJ/kg)  x (g/kg)\n",
       "225     38.651416        8.330885            42.033982  7.139027\n",
       "271     38.991298        8.486490            42.588319  7.228584\n",
       "204     38.919027        8.478319            42.572920  7.210885\n",
       "274     39.091829        8.509145            42.643540  7.249823\n",
       "299     42.021180        8.450944            42.483009  7.193186\n",
       "..            ...             ...                  ...       ...\n",
       "143     38.504690        8.304956            42.012419  7.067463\n",
       "180     38.941504        8.696195            42.417257  7.436372\n",
       "131     38.266814        8.270973            41.950118  7.039145\n",
       "302     41.391091        8.426873            42.436283  7.171947\n",
       "338     39.804100        8.681121            43.047522  7.393481\n",
       "\n",
       "[272 rows x 4 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features_exit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "57ab8ada",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Humidity (%)</th>\n",
       "      <th>Density (g/m3)</th>\n",
       "      <th>Enthalpy, h (kJ/kg)</th>\n",
       "      <th>x (g/kg)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>38.522389</td>\n",
       "      <td>8.349027</td>\n",
       "      <td>42.239823</td>\n",
       "      <td>7.114779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>38.480295</td>\n",
       "      <td>8.351976</td>\n",
       "      <td>42.219145</td>\n",
       "      <td>7.104779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>38.732330</td>\n",
       "      <td>8.408614</td>\n",
       "      <td>42.352242</td>\n",
       "      <td>7.155752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>38.984366</td>\n",
       "      <td>8.465251</td>\n",
       "      <td>42.485339</td>\n",
       "      <td>7.206726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>39.068378</td>\n",
       "      <td>8.484130</td>\n",
       "      <td>42.529705</td>\n",
       "      <td>7.223717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>38.660708</td>\n",
       "      <td>8.322566</td>\n",
       "      <td>42.233805</td>\n",
       "      <td>7.079912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>38.515605</td>\n",
       "      <td>8.397935</td>\n",
       "      <td>42.410354</td>\n",
       "      <td>7.145693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>38.687404</td>\n",
       "      <td>8.435693</td>\n",
       "      <td>42.495310</td>\n",
       "      <td>7.178732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>38.859204</td>\n",
       "      <td>8.473451</td>\n",
       "      <td>42.580265</td>\n",
       "      <td>7.211770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>38.945103</td>\n",
       "      <td>8.492330</td>\n",
       "      <td>42.622743</td>\n",
       "      <td>7.228289</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Humidity (%)  Density (g/m3)  Enthalpy, h (kJ/kg)  x (g/kg)\n",
       "9       38.522389        8.349027            42.239823  7.114779\n",
       "25      38.480295        8.351976            42.219145  7.104779\n",
       "28      38.732330        8.408614            42.352242  7.155752\n",
       "31      38.984366        8.465251            42.485339  7.206726\n",
       "32      39.068378        8.484130            42.529705  7.223717\n",
       "..            ...             ...                  ...       ...\n",
       "315     38.660708        8.322566            42.233805  7.079912\n",
       "323     38.515605        8.397935            42.410354  7.145693\n",
       "325     38.687404        8.435693            42.495310  7.178732\n",
       "327     38.859204        8.473451            42.580265  7.211770\n",
       "328     38.945103        8.492330            42.622743  7.228289\n",
       "\n",
       "[68 rows x 4 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_features_exit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a8a20e5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Humidity (%)</th>\n",
       "      <th>Density (g/m^3)</th>\n",
       "      <th>Enthalpy, h (kJ/kg)</th>\n",
       "      <th>x (g/kg)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>38.80</td>\n",
       "      <td>8.45</td>\n",
       "      <td>42.50</td>\n",
       "      <td>7.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>38.43</td>\n",
       "      <td>8.36</td>\n",
       "      <td>42.28</td>\n",
       "      <td>7.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>38.07</td>\n",
       "      <td>8.30</td>\n",
       "      <td>42.19</td>\n",
       "      <td>7.06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Humidity (%)   Density (g/m^3)   Enthalpy, h (kJ/kg)   x (g/kg)\n",
       "5          38.80              8.45                 42.50       7.19\n",
       "12         38.43              8.36                 42.28       7.11\n",
       "15         38.07              8.30                 42.19       7.06"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ori_test_features_exit = ori_test_features_exit.drop(['Count','Which MAU'], axis=1)\n",
    "ori_test_features_exit  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0ad33b2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "225    74.742035\n",
       "271    75.130920\n",
       "204    75.096619\n",
       "274    75.141115\n",
       "299    75.082071\n",
       "         ...    \n",
       "143    74.822053\n",
       "180    74.983204\n",
       "131    74.862832\n",
       "302    75.092265\n",
       "338    75.180301\n",
       "Name: Temperature (Â°F), Length: 272, dtype: float64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels_exit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7da236b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9      75.015062\n",
       "25     75.003434\n",
       "28     75.018726\n",
       "31     75.034018\n",
       "32     75.039115\n",
       "         ...    \n",
       "315    75.136442\n",
       "323    75.154814\n",
       "325    75.158212\n",
       "327    75.161611\n",
       "328    75.163310\n",
       "Name: Temperature (Â°F), Length: 68, dtype: float64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels_exit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "998cb563",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5     75.110\n",
       "12    75.074\n",
       "15    75.146\n",
       "Name: Temperature (°F), dtype: float64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ori_test_labels_exit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e07e6e9",
   "metadata": {},
   "source": [
    "## Regression with a deep neural network (DNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db869e0a",
   "metadata": {},
   "source": [
    "Here, you will implement a multiple-input DNN model.\n",
    "\n",
    "The name \"hidden\" here just means not directly connected to the inputs or outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a282793",
   "metadata": {},
   "source": [
    "This model will contain a few layers.\n",
    "\n",
    "* The dense input layer.\n",
    "* Two hidden, non-linear, `Dense` layers with the ReLU (`relu`) activation function nonlinearity.\n",
    "* A linear `Dense` single-output layer.\n",
    "\n",
    "The `compile` method is included in the `build_and_compile_model` function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f8e0518d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_and_compile_model():\n",
    "  model = keras.Sequential([\n",
    "      layers.Dense(4,  kernel_initializer='normal', input_dim = train_features_entrance.shape[1], activation='relu'),\n",
    "      layers.Dense(64,  kernel_initializer='normal', activation='relu'),\n",
    "      layers.Dense(64,  kernel_initializer='normal', activation='relu'),\n",
    "      layers.Dense(1)])\n",
    "\n",
    "  model.compile(loss='mean_absolute_error',\n",
    "                optimizer=tf.keras.optimizers.Adam(0.001))\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a2a043ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment with different configurations\n",
    "#configs = [\n",
    " #   {\"layers\": 2, \"neurons_per_layer\": [32, 16]},\n",
    " #   {\"layers\": 3, \"neurons_per_layer\": [64, 32, 16]},\n",
    " #   {\"layers\": 4, \"neurons_per_layer\": [128, 64, 32, 16]},\n",
    " #   {\"layers\": 2, \"neurons_per_layer\": [64, 64]},\n",
    " #   {\"layers\": 3, \"neurons_per_layer\": [128, 64, 32]}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1449909e",
   "metadata": {},
   "source": [
    "### Regression using a DNN and multiple inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0d03c2cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 4)                 20        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                320       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,565\n",
      "Trainable params: 4,565\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x3265c9bd0>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_model = build_and_compile_model()\n",
    "dnn_model.summary()\n",
    "dnn_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a155532",
   "metadata": {},
   "source": [
    "This table summarizes the architecture of the neural network model. The table is divided into several columns detailing the layers in the model, their types, output shapes, and the number of parameters (weights and biases) each layer has. Here's a breakdown of the table:\n",
    "\n",
    "Layer: Indicates the name and type of each layer in the model. The model consists of a normalization layer followed by three dense (fully connected) layers.\n",
    "\n",
    "Output Shape: The shape of the output for each layer. The notation (None, x) indicates that the batch size is variable (denoted by None), and x is the dimensionality of the output from that layer.\n",
    "\n",
    "The normalization layer takes an input with 9 features ((None, 9)).\n",
    "The first dense layer outputs 64 units ((None, 64)).\n",
    "The second dense layer, identical to the first, also outputs 64 units.\n",
    "The final dense layer outputs a single unit ((None, 1)), corresponding to the model's prediction.\n",
    "\n",
    "Param #: Lists the number of parameters in each layer, which are learned during the training process.\n",
    "\n",
    "The normalization layer has 19 parameters, which are not trainable. These parameters might include statistics like mean and variance for each input feature used for data normalization.\n",
    "The first dense layer has 640 parameters, calculated as (9 input features * 64 output units) + 64 bias terms.\n",
    "The second dense layer has 4160 parameters, derived from (64 input units * 64 output units) + 64 bias terms.\n",
    "The final dense layer has 65 parameters, from (64 input units * 1 output unit) + 1 bias term.\n",
    "\n",
    "Total params: The total number of parameters in the model, summing to 4,884. This includes both trainable and non-trainable parameters.\n",
    "\n",
    "Trainable params: The number of parameters that will be updated during training, totaling 4,865. This excludes the normalization layer's statistics.\n",
    "\n",
    "Non-trainable params: Parameters that do not get updated during the training process, in this case, 19, likely related to the normalization layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3793b510",
   "metadata": {},
   "source": [
    "\n",
    "Train the model with Keras `Model.fit`.\n",
    "\n",
    "The validation_split=0.2 argument in the fit method of the Keras API indicates that 20% of the training data should be set aside for validation. The model will train on 80% of the data and evaluate its performance on the remaining 20% to monitor for issues like overfitting. This validation set is not used to update the model's weights; it's only for evaluation purposes to give an estimate of the model's performance on unseen data.\n",
    "\n",
    "The verbose parameter controls how much information the training process outputs to the console. Setting verbose=0 means that you won’t see any logging output during training, which can be useful if you don't need to track the training process in detail and want to avoid cluttering your console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "66eccda2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-24 19:58:33.248934: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.23 s, sys: 347 ms, total: 1.57 s\n",
      "Wall time: 1.16 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history_entrance = dnn_model.fit(\n",
    "    train_features_entrance,\n",
    "    train_labels_entrance,\n",
    "    validation_split=0.2,\n",
    "    verbose=0, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "73ea7bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.11 s, sys: 308 ms, total: 1.42 s\n",
      "Wall time: 1.05 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history_exit = dnn_model.fit(\n",
    "    train_features_exit,\n",
    "    train_labels_exit,\n",
    "    validation_split=0.2,\n",
    "    verbose=0, epochs=100) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d46c66",
   "metadata": {},
   "source": [
    "### Visualize the model's training progress in DNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d182f5f",
   "metadata": {},
   "source": [
    "Visualize the model's training progress using the stats stored in the `history` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "39113f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(history_entrance):\n",
    "  plt.plot(history_entrance.history['loss'], label='Training loss')\n",
    "  plt.plot(history_entrance.history['val_loss'], label='Validation loss')\n",
    "  plt.ylim([0, 100])\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('Error [Temperature (°F)]')\n",
    "  plt.title('Training progress in DNN model for MAU entrance')\n",
    "  plt.legend()\n",
    "  plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b62084fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss(history_entrance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4657bd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(history_exit):\n",
    "  plt.plot(history_exit.history['loss'], label='Training loss')\n",
    "  plt.plot(history_exit.history['val_loss'], label='Validation loss')\n",
    "  plt.ylim([0, 4])\n",
    "  plt.xlim([0, 100])\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('Error [Temperature (°F)]')\n",
    "  plt.title('Training progress in DNN model for MAU exit')\n",
    "  plt.legend()\n",
    "  plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "89c506f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plot_loss(history_exit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298aa32c",
   "metadata": {},
   "source": [
    "### Collect the results on the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b205b1",
   "metadata": {},
   "source": [
    "#### MAU entrance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f4dbd181",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features_entrance = np.asarray(test_features_entrance).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "fa2521ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dnn_model': 4.4129862785339355}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results_entrance = {}\n",
    "test_results_entrance['dnn_model'] = dnn_model.evaluate(test_features_entrance, test_labels_entrance, verbose=0)\n",
    "test_results_entrance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "25fd8d1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 4)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#original\n",
    "ori_test_features_entrance = np.asarray(ori_test_features_entrance).astype(np.float32)\n",
    "ori_test_features_entrance.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ca733a14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dnn_model': 6.489389896392822}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ori_test_results_entrance = {}\n",
    "ori_test_results_entrance['dnn_model'] = dnn_model.evaluate(ori_test_features_entrance, ori_test_labels_entrance, verbose=0)\n",
    "ori_test_results_entrance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e20fa7",
   "metadata": {},
   "source": [
    "#### MAU exit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c1d5a3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features_exit = np.asarray(test_features_exit).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1d5d13e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dnn_model': 0.3404204547405243}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results_exit = {}\n",
    "test_results_exit['dnn_model'] = dnn_model.evaluate(test_features_exit, test_labels_exit, verbose=0)\n",
    "test_results_exit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "cf9ae93c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 4)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#original\n",
    "ori_test_features_exit = np.asarray(ori_test_features_exit).astype(np.float32)\n",
    "ori_test_features_exit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f4e79ef7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dnn_model': 0.0921173095703125}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ori_test_results_exit = {}\n",
    "ori_test_results_exit['dnn_model'] = dnn_model.evaluate(ori_test_features_exit, ori_test_labels_exit, verbose=0)\n",
    "ori_test_results_exit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09606ee2",
   "metadata": {},
   "source": [
    "## Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "35c1fff3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean absolute error [Temperature]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dnn_model</th>\n",
       "      <td>4.412986</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Mean absolute error [Temperature]\n",
       "dnn_model                           4.412986"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(test_results_entrance, index=['Mean absolute error [Temperature]']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "859a1035",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean absolute error [Temperature]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dnn_model</th>\n",
       "      <td>6.48939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Mean absolute error [Temperature]\n",
       "dnn_model                            6.48939"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# original\n",
    "pd.DataFrame(ori_test_results_entrance, index=['Mean absolute error [Temperature]']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4ad1c10f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean absolute error [Temperature]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dnn_model</th>\n",
       "      <td>0.34042</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Mean absolute error [Temperature]\n",
       "dnn_model                            0.34042"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(test_results_exit, index=['Mean absolute error [Temperature]']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "68a1f9ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean absolute error [Temperature]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dnn_model</th>\n",
       "      <td>0.092117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Mean absolute error [Temperature]\n",
       "dnn_model                           0.092117"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#original\n",
    "pd.DataFrame(ori_test_results_exit, index=['Mean absolute error [Temperature]']).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5853fab4",
   "metadata": {},
   "source": [
    "### Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "39d7f904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 847us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([77.89 , 88.072, 88.274, 88.476, 88.543, 88.947, 89.014, 89.216,\n",
       "       88.888, 88.431, 88.126, 87.699, 87.721, 87.836, 87.858, 86.189,\n",
       "       85.443, 83.206, 77.241, 72.767, 74.516, 75.057, 75.597, 76.137,\n",
       "       77.759, 78.002, 82.558, 82.644, 81.619, 81.449, 81.622, 82.068,\n",
       "       82.737, 84.075, 84.521, 85.706, 85.643, 85.516, 85.39 , 85.074,\n",
       "       85.011, 84.506, 79.173, 79.435, 79.696, 81.523, 82.418, 82.502,\n",
       "       82.552, 82.586, 82.687, 82.613, 82.023, 81.802, 81.655, 81.508,\n",
       "       81.434, 81.26 , 81.395, 81.867, 82.137, 82.272, 82.339, 82.407,\n",
       "       81.435, 80.987, 80.538, 80.314], dtype=float32)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions_entrance = dnn_model.predict(test_features_entrance).flatten()\n",
    "test_predictions_entrance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "98eef494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 7ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([72.067, 82.372, 82.597], dtype=float32)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# original\n",
    "ori_test_predictions_entrance = dnn_model.predict(ori_test_features_entrance).flatten()\n",
    "ori_test_predictions_entrance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "8f24baf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 707us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([74.988, 74.958, 75.083, 75.208, 75.25 , 75.501, 75.543, 75.668,\n",
       "       76.002, 76.414, 76.689, 76.545, 76.361, 75.437, 75.252, 75.195,\n",
       "       75.201, 75.217, 75.261, 75.294, 74.993, 74.926, 74.858, 74.79 ,\n",
       "       74.588, 74.585, 74.621, 74.552, 74.235, 74.182, 74.23 , 74.364,\n",
       "       74.565, 74.966, 75.1  , 75.47 , 75.462, 75.447, 75.432, 75.393,\n",
       "       75.386, 75.324, 74.518, 74.563, 74.609, 74.928, 75.126, 75.216,\n",
       "       75.269, 75.305, 75.412, 75.384, 75.017, 74.88 , 74.788, 74.696,\n",
       "       74.65 , 74.522, 74.576, 74.767, 74.876, 74.931, 74.958, 74.985,\n",
       "       75.259, 75.334, 75.41 , 75.448], dtype=float32)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions_exit = dnn_model.predict(test_features_exit).flatten()\n",
    "test_predictions_exit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "1da56173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 8ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([75.3  , 75.077, 75.062], dtype=float32)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# original\n",
    "ori_test_predictions_exit = dnn_model.predict(ori_test_features_exit).flatten()\n",
    "ori_test_predictions_exit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "27f0962c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9     -1.796452\n",
       "25     0.490708\n",
       "28     0.549459\n",
       "31     0.608225\n",
       "32     0.627800\n",
       "         ...   \n",
       "315   -7.626952\n",
       "323   -7.908848\n",
       "325   -8.028986\n",
       "327   -8.149123\n",
       "328   -8.209203\n",
       "Name: Temperature (Â°F), Length: 68, dtype: float64"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_entrance = test_predictions_entrance - test_labels_entrance\n",
    "error_entrance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "96748d52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    -3.472571\n",
       "12   -8.398349\n",
       "15   -7.597236\n",
       "Name: Temperature (°F), dtype: float64"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# original\n",
    "ori_error_entrance = ori_test_predictions_entrance - ori_test_labels_entrance\n",
    "ori_error_entrance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c6df03d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(error_entrance, bins=25)\n",
    "plt.xlabel('Prediction Error [Temperature]')\n",
    "_ = plt.ylabel('Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "803d7774",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# original\n",
    "plt.hist(ori_error_entrance, bins=25)\n",
    "plt.xlabel('Prediction Error [Temperature]')\n",
    "_ = plt.ylabel('Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "61995131",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9     -0.027361\n",
       "25    -0.045617\n",
       "28     0.064397\n",
       "31     0.174410\n",
       "32     0.211083\n",
       "         ...   \n",
       "315   -0.151121\n",
       "323    0.103693\n",
       "325    0.176039\n",
       "327    0.248378\n",
       "328    0.284543\n",
       "Name: Temperature (Â°F), Length: 68, dtype: float64"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_exit = test_predictions_exit - test_labels_exit\n",
    "error_exit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "6bdd4ac2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5     0.189576\n",
       "12    0.002828\n",
       "15   -0.083950\n",
       "Name: Temperature (°F), dtype: float64"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# original\n",
    "ori_error_exit = ori_test_predictions_exit - ori_test_labels_exit\n",
    "ori_error_exit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "6066fedc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(error_exit, bins=25)\n",
    "plt.xlabel('Prediction Error [Temperature]')\n",
    "_ = plt.ylabel('Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "75732ad9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkEAAAGwCAYAAACuIrGMAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAulElEQVR4nO3deVRV9f7/8deR0QksB8BCwMyBuKVCJXpNbUBtWLZqLe1aDjnc0Fs4ZN24poJ1w/qW0eDQoFL3mplXG26Xr0beNAsrJSwTmkzDCiLNQE1R4fP7wx/n2/GAMRw4wuf5WGuv5f7sz977vT9nKy/3wHEYY4wAAAAs08LbBQAAAHgDIQgAAFiJEAQAAKxECAIAAFYiBAEAACsRggAAgJUIQQAAwEq+3i6gsVVUVOiHH35Q27Zt5XA4vF0OAACoAWOMDh06pM6dO6tFC89cw7EuBP3www8KDw/3dhkAAKAO9u3bp/PPP98j27IuBLVt21bSqUEMCgrycjUAAKAmSktLFR4e7vw57gnWhaDKW2BBQUGEIAAAmhhPPsrCg9EAAMBKhCAAAGAlQhAAALASIQgAAFiJEAQAAKxECAIAAFYiBAEAACsRggAAgJUIQQAAwEqEIAAAYCVCEAAAsJJXQ9C7776rG264QZ07d5bD4dBrr732u+ts3rxZsbGxCgwMVNeuXbV06dKGLxQAADQ7Xg1BR44c0SWXXKKnn366Rv337Nmja6+9VgMHDlRubq7+9re/KSkpSWvXrm3gSgEAQHPj1W+RHz58uIYPH17j/kuXLlWXLl2Unp4uSerVq5e2b9+uRx99VDfffHMDVQkAAJqjJvVM0NatW5WQkODSNnToUG3fvl0nTpyocp2ysjKVlpa6TAAAAF69ElRbRUVFCgkJcWkLCQnRyZMntX//foWFhbmtk5aWptTU1MYqUZH3/ccj29m74DqPbAeNg88dQHNg279lTepKkCQ5HA6XeWNMle2VkpOTVVJS4pz27dvX4DUCAICzX5O6EhQaGqqioiKXtuLiYvn6+qp9+/ZVrhMQEKCAgIDGKA8AADQhTepKUHx8vLKyslza3nrrLcXFxcnPz89LVQEAgKbIqyHo8OHD2rFjh3bs2CHp1CvwO3bsUEFBgaRTt7LGjh3r7J+YmKhvv/1WM2fOVH5+vpYvX65ly5Zp1qxZ3igfAAA0YV69HbZ9+3YNGTLEOT9z5kxJ0rhx45SRkaHCwkJnIJKkqKgoZWZmasaMGVq0aJE6d+6sJ598ktfjAQBArXk1BA0ePNj5YHNVMjIy3NoGDRqkjz/+uAGrAgAANmhSzwQBAAB4CiEIAABYiRAEAACsRAgCAABWIgQBAAArEYIAAICVCEEAAMBKhCAAAGAlQhAAALASIQgAAFiJEAQAAKxECAIAAFYiBAEAACsRggAAgJUIQQAAwEqEIAAAYCVCEAAAsBIhCAAAWIkQBAAArEQIAgAAViIEAQAAKxGCAACAlQhBAADASoQgAABgJUIQAACwEiEIAABYiRAEAACsRAgCAABWIgQBAAArEYIAAICVCEEAAMBKhCAAAGAlQhAAALASIQgAAFiJEAQAAKxECAIAAFYiBAEAACsRggAAgJUIQQAAwEqEIAAAYCVCEAAAsBIhCAAAWIkQBAAArEQIAgAAViIEAQAAKxGCAACAlQhBAADASoQgAABgJUIQAACwEiEIAABYiRAEAACsRAgCAABWIgQBAAArEYIAAICVCEEAAMBKhCAAAGAlQhAAALASIQgAAFiJEAQAAKxECAIAAFbyeghavHixoqKiFBgYqNjYWG3ZsuWM/VeuXKlLLrlErVq1UlhYmG6//XYdOHCgkaoFAADNhVdD0OrVqzV9+nTNnj1bubm5GjhwoIYPH66CgoIq+7/33nsaO3asJk6cqF27dmnNmjXatm2bJk2a1MiVAwCAps6rIWjhwoWaOHGiJk2apF69eik9PV3h4eFasmRJlf0/+OADRUZGKikpSVFRUfrjH/+oO+64Q9u3b692H2VlZSotLXWZAAAAvBaCjh8/rpycHCUkJLi0JyQkKDs7u8p1+vfvr++++06ZmZkyxujHH3/Uv/71L1133XXV7ictLU3BwcHOKTw83KPHAQAAmiavhaD9+/ervLxcISEhLu0hISEqKiqqcp3+/ftr5cqVGjVqlPz9/RUaGqp27drpqaeeqnY/ycnJKikpcU779u3z6HEAAICmyesPRjscDpd5Y4xbW6W8vDwlJSVp7ty5ysnJ0fr167Vnzx4lJiZWu/2AgAAFBQW5TAAAAL7e2nGHDh3k4+PjdtWnuLjY7epQpbS0NA0YMED33HOPJOniiy9W69atNXDgQD344IMKCwtr8LoBAEDz4LUrQf7+/oqNjVVWVpZLe1ZWlvr371/lOr/++qtatHAt2cfHR9KpK0gAAAA15dXbYTNnztTzzz+v5cuXKz8/XzNmzFBBQYHz9lZycrLGjh3r7H/DDTdo3bp1WrJkib755hu9//77SkpK0mWXXabOnTt76zAAAEAT5LXbYZI0atQoHThwQPPnz1dhYaFiYmKUmZmpiIgISVJhYaHL7wwaP368Dh06pKefflp333232rVrpyuvvFIPP/ywtw4BAAA0UV4NQZI0depUTZ06tcplGRkZbm133XWX7rrrrgauCgAANHdefzsMAADAGwhBAADASoQgAABgJUIQAACwEiEIAABYiRAEAACsRAgCAABWIgQBAAArEYIAAICVCEEAAMBKhCAAAGAlQhAAALASIQgAAFiJEAQAAKxECAIAAFYiBAEAACsRggAAgJUIQQAAwEqEIAAAYCVCEAAAsBIhCAAAWIkQBAAArEQIAgAAViIEAQAAKxGCAACAlQhBAADASoQgAABgJUIQAACwEiEIAABYiRAEAACsRAgCAABWIgQBAAArEYIAAICVCEEAAMBKhCAAAGAlQhAAALASIQgAAFiJEAQAAKxECAIAAFYiBAEAACsRggAAgJUIQQAAwEqEIAAAYCVCEAAAsBIhCAAAWIkQBAAArEQIAgAAViIEAQAAKxGCAACAlQhBAADASoQgAABgJUIQAACwEiEIAABYiRAEAACsRAgCAABWIgQBAAArEYIAAICVCEEAAMBKhCAAAGAlr4egxYsXKyoqSoGBgYqNjdWWLVvO2L+srEyzZ89WRESEAgICdMEFF2j58uWNVC0AAGgufL2589WrV2v69OlavHixBgwYoGeeeUbDhw9XXl6eunTpUuU6I0eO1I8//qhly5apW7duKi4u1smTJxu5cgAA0NR5NQQtXLhQEydO1KRJkyRJ6enp2rBhg5YsWaK0tDS3/uvXr9fmzZv1zTff6Nxzz5UkRUZGNmbJAACgmfDa7bDjx48rJydHCQkJLu0JCQnKzs6ucp033nhDcXFxeuSRR3Teeeepe/fumjVrlo4ePVrtfsrKylRaWuoyAQAAeO1K0P79+1VeXq6QkBCX9pCQEBUVFVW5zjfffKP33ntPgYGBevXVV7V//35NnTpVP//8c7XPBaWlpSk1NdXj9QMAgKbN6w9GOxwOl3ljjFtbpYqKCjkcDq1cuVKXXXaZrr32Wi1cuFAZGRnVXg1KTk5WSUmJc9q3b5/HjwEAADQ9XrsS1KFDB/n4+Lhd9SkuLna7OlQpLCxM5513noKDg51tvXr1kjFG3333nS688EK3dQICAhQQEODZ4gEAQJPntStB/v7+io2NVVZWlkt7VlaW+vfvX+U6AwYM0A8//KDDhw8727788ku1aNFC559/foPWCwAAmhev3g6bOXOmnn/+eS1fvlz5+fmaMWOGCgoKlJiYKOnUrayxY8c6+48ePVrt27fX7bffrry8PL377ru65557NGHCBLVs2dJbhwEAAJogr74iP2rUKB04cEDz589XYWGhYmJilJmZqYiICElSYWGhCgoKnP3btGmjrKws3XXXXYqLi1P79u01cuRIPfjgg946BAAA0ER5NQRJ0tSpUzV16tQql2VkZLi19ezZ0+0WGgAAQG15/e0wAAAAb6hTCOratasOHDjg1v7LL7+oa9eu9S4KAACgodUpBO3du1fl5eVu7WVlZfr+++/rXRQAAEBDq9UzQW+88Ybzzxs2bHD5fT3l5eXauHEj3+UFAACahFqFoBtvvFHSqd/yPG7cOJdlfn5+ioyM1GOPPeax4gAAABpKrUJQRUWFJCkqKkrbtm1Thw4dGqQoAACAhlanV+T37Nnj6ToAAAAaVZ1/T9DGjRu1ceNGFRcXO68QVaruG90BAADOFnUKQampqZo/f77i4uIUFhZW7be+AwAAnK3qFIKWLl2qjIwMjRkzxtP1AAAANIo6/Z6g48ePV/tN7wAAAE1BnULQpEmT9NJLL3m6FgAAgEZTp9thx44d07PPPqu3335bF198sfz8/FyWL1y40CPFAQAANJQ6haBPP/1UvXv3liR99tlnLst4SBoAADQFdQpB77zzjqfrAAAAaFR1eiYIAACgqavTlaAhQ4ac8bbXf//73zoXBAAA0BjqFIIqnweqdOLECe3YsUOfffaZ2xerAgAAnI3qFIIef/zxKttTUlJ0+PDhehUEAADQGDz6TNBtt93G94YBAIAmwaMhaOvWrQoMDPTkJgEAABpEnW6H3XTTTS7zxhgVFhZq+/btmjNnjkcKAwAAaEh1CkHBwcEu8y1atFCPHj00f/58JSQkeKQwAACAhlSnELRixQpP1wEAANCo6hSCKuXk5Cg/P18Oh0PR0dHq06ePp+oCAABoUHUKQcXFxbrlllu0adMmtWvXTsYYlZSUaMiQIXr55ZfVsWNHT9cJAADgUXV6O+yuu+5SaWmpdu3apZ9//lkHDx7UZ599ptLSUiUlJXm6RgAAAI+r05Wg9evX6+2331avXr2cbdHR0Vq0aBEPRgMAgCahTleCKioq5Ofn59bu5+enioqKehcFAADQ0OoUgq688kpNmzZNP/zwg7Pt+++/14wZM3TVVVd5rDgAAICGUqcQ9PTTT+vQoUOKjIzUBRdcoG7duikqKkqHDh3SU0895ekaAQAAPK5OzwSFh4fr448/VlZWlj7//HMZYxQdHa2rr77a0/UBAAA0iFpdCfrvf/+r6OholZaWSpKuueYa3XXXXUpKStKll16qiy66SFu2bGmQQgEAADypViEoPT1dkydPVlBQkNuy4OBg3XHHHVq4cKHHigMAAGgotQpBn3zyiYYNG1bt8oSEBOXk5NS7KAAAgIZWqxD0448/VvlqfCVfX1/99NNP9S4KAACgodUqBJ133nnauXNntcs//fRThYWF1bsoAACAhlarEHTttddq7ty5OnbsmNuyo0ePat68ebr++us9VhwAAEBDqdUr8vfff7/WrVun7t27684771SPHj3kcDiUn5+vRYsWqby8XLNnz26oWgEAADymViEoJCRE2dnZmjJlipKTk2WMkSQ5HA4NHTpUixcvVkhISIMUCgAA4Em1/mWJERERyszM1MGDB/X111/LGKMLL7xQ55xzTkPUBwAA0CDq9BujJemcc87RpZde6slaAAAAGk2dvjsMAACgqSMEAQAAKxGCAACAlQhBAADASoQgAABgJUIQAACwEiEIAABYiRAEAACsRAgCAABWIgQBAAArEYIAAICVCEEAAMBKhCAAAGAlQhAAALASIQgAAFiJEAQAAKxECAIAAFbyeghavHixoqKiFBgYqNjYWG3ZsqVG673//vvy9fVV7969G7ZAAADQLHk1BK1evVrTp0/X7NmzlZubq4EDB2r48OEqKCg443olJSUaO3asrrrqqkaqFAAANDdeDUELFy7UxIkTNWnSJPXq1Uvp6ekKDw/XkiVLzrjeHXfcodGjRys+Pr6RKgUAAM2N10LQ8ePHlZOTo4SEBJf2hIQEZWdnV7veihUrtHv3bs2bN69G+ykrK1NpaanLBAAA4LUQtH//fpWXlyskJMSlPSQkREVFRVWu89VXX+m+++7TypUr5evrW6P9pKWlKTg42DmFh4fXu3YAAND0ef3BaIfD4TJvjHFrk6Ty8nKNHj1aqamp6t69e423n5ycrJKSEue0b9++etcMAACavppdTmkAHTp0kI+Pj9tVn+LiYrerQ5J06NAhbd++Xbm5ubrzzjslSRUVFTLGyNfXV2+99ZauvPJKt/UCAgIUEBDQMAcBAACaLK9dCfL391dsbKyysrJc2rOystS/f3+3/kFBQdq5c6d27NjhnBITE9WjRw/t2LFDl19+eWOVDgAAmgGvXQmSpJkzZ2rMmDGKi4tTfHy8nn32WRUUFCgxMVHSqVtZ33//vV588UW1aNFCMTExLut36tRJgYGBbu0AAAC/x6shaNSoUTpw4IDmz5+vwsJCxcTEKDMzUxEREZKkwsLC3/2dQQAAAHXh1RAkSVOnTtXUqVOrXJaRkXHGdVNSUpSSkuL5ogAAQLPn9bfDAAAAvIEQBAAArEQIAgAAViIEAQAAKxGCAACAlQhBAADASoQgAABgJUIQAACwEiEIAABYiRAEAACsRAgCAABWIgQBAAArEYIAAICVCEEAAMBKhCAAAGAlQhAAALASIQgAAFiJEAQAAKxECAIAAFYiBAEAACsRggAAgJUIQQAAwEqEIAAAYCVCEAAAsBIhCAAAWIkQBAAArEQIAgAAViIEAQAAKxGCAACAlQhBAADASoQgAABgJUIQAACwEiEIAABYiRAEAACsRAgCAABWIgQBAAArEYIAAICVCEEAAMBKhCAAAGAlQhAAALASIQgAAFiJEAQAAKxECAIAAFYiBAEAACsRggAAgJUIQQAAwEqEIAAAYCVCEAAAsBIhCAAAWIkQBAAArEQIAgAAViIEAQAAKxGCAACAlQhBAADASoQgAABgJUIQAACwEiEIAABYiRAEAACsRAgCAABWIgQBAAAreT0ELV68WFFRUQoMDFRsbKy2bNlSbd9169bpmmuuUceOHRUUFKT4+Hht2LChEasFAADNhVdD0OrVqzV9+nTNnj1bubm5GjhwoIYPH66CgoIq+7/77ru65pprlJmZqZycHA0ZMkQ33HCDcnNzG7lyAADQ1Pl6c+cLFy7UxIkTNWnSJElSenq6NmzYoCVLligtLc2tf3p6usv8Qw89pNdff13//ve/1adPnyr3UVZWprKyMud8aWmp5w4AAAA0WV67EnT8+HHl5OQoISHBpT0hIUHZ2dk12kZFRYUOHTqkc889t9o+aWlpCg4Odk7h4eH1qhsAADQPXgtB+/fvV3l5uUJCQlzaQ0JCVFRUVKNtPPbYYzpy5IhGjhxZbZ/k5GSVlJQ4p3379tWrbgAA0Dx49XaYJDkcDpd5Y4xbW1VWrVqllJQUvf766+rUqVO1/QICAhQQEFDvOgEAQPPitRDUoUMH+fj4uF31KS4udrs6dLrVq1dr4sSJWrNmja6++uqGLBMAADRTXrsd5u/vr9jYWGVlZbm0Z2VlqX///tWut2rVKo0fP14vvfSSrrvuuoYuEwAANFNevR02c+ZMjRkzRnFxcYqPj9ezzz6rgoICJSYmSjr1PM/333+vF198UdKpADR27Fg98cQT6tevn/MqUsuWLRUcHOy14wAAAE2PV0PQqFGjdODAAc2fP1+FhYWKiYlRZmamIiIiJEmFhYUuvzPomWee0cmTJ/WXv/xFf/nLX5zt48aNU0ZGRmOXDwAAmjCvPxg9depUTZ06tcplpwebTZs2NXxBAADACl7/2gwAAABvIAQBAAArEYIAAICVCEEAAMBKhCAAAGAlQhAAALASIQgAAFiJEAQAAKxECAIAAFYiBAEAACsRggAAgJUIQQAAwEqEIAAAYCVCEAAAsBIhCAAAWIkQBAAArEQIAgAAViIEAQAAKxGCAACAlQhBAADASoQgAABgJUIQAACwEiEIAABYiRAEAACsRAgCAABWIgQBAAArEYIAAICVCEEAAMBKhCAAAGAlQhAAALASIQgAAFiJEAQAAKxECAIAAFYiBAEAACsRggAAgJUIQQAAwEqEIAAAYCVCEAAAsBIhCAAAWIkQBAAArEQIAgAAViIEAQAAKxGCAACAlQhBAADASoQgAABgJUIQAACwEiEIAABYiRAEAACsRAgCAABWIgQBAAArEYIAAICVCEEAAMBKhCAAAGAlQhAAALASIQgAAFiJEAQAAKxECAIAAFYiBAEAACsRggAAgJW8HoIWL16sqKgoBQYGKjY2Vlu2bDlj/82bNys2NlaBgYHq2rWrli5d2kiVAgCA5sSrIWj16tWaPn26Zs+erdzcXA0cOFDDhw9XQUFBlf337Nmja6+9VgMHDlRubq7+9re/KSkpSWvXrm3kygEAQFPn1RC0cOFCTZw4UZMmTVKvXr2Unp6u8PBwLVmypMr+S5cuVZcuXZSenq5evXpp0qRJmjBhgh599NFGrhwAADR1vt7a8fHjx5WTk6P77rvPpT0hIUHZ2dlVrrN161YlJCS4tA0dOlTLli3TiRMn5Ofn57ZOWVmZysrKnPMlJSWSpNLS0voeQpUqyn71yHYaqj40DD53AM3B2fxvWeU2jTEe26bXQtD+/ftVXl6ukJAQl/aQkBAVFRVVuU5RUVGV/U+ePKn9+/crLCzMbZ20tDSlpqa6tYeHh9ej+oYXnO7tCuANfO4AmoOG/Lfs0KFDCg4O9si2vBaCKjkcDpd5Y4xb2+/1r6q9UnJysmbOnOmcr6io0M8//6z27dufcT9wV1paqvDwcO3bt09BQUHeLqfJYhw9h7H0DMbRcxhLz6hqHI0xOnTokDp37uyx/XgtBHXo0EE+Pj5uV32Ki4vdrvZUCg0NrbK/r6+v2rdvX+U6AQEBCggIcGlr165d3QuHgoKC+MvtAYyj5zCWnsE4eg5j6Rmnj6OnrgBV8tqD0f7+/oqNjVVWVpZLe1ZWlvr371/lOvHx8W7933rrLcXFxVX5PBAAAEB1vPp22MyZM/X8889r+fLlys/P14wZM1RQUKDExERJp25ljR071tk/MTFR3377rWbOnKn8/HwtX75cy5Yt06xZs7x1CAAAoIny6jNBo0aN0oEDBzR//nwVFhYqJiZGmZmZioiIkCQVFha6/M6gqKgoZWZmasaMGVq0aJE6d+6sJ598UjfffLO3DsEqAQEBmjdvntvtRdQO4+g5jKVnMI6ew1h6RmONo8N48l0zAACAJsLrX5sBAADgDYQgAABgJUIQAACwEiEIAABYiRAEp4MHD2rMmDEKDg5WcHCwxowZo19++eWM6xhjlJKSos6dO6tly5YaPHiwdu3a5dJn8ODBcjgcLtMtt9zSgEfS+BYvXqyoqCgFBgYqNjZWW7ZsOWP/zZs3KzY2VoGBgeratauWLl3q1mft2rWKjo5WQECAoqOj9eqrrzZU+WcNT49jRkaG27nncDh07NixhjyMs0JtxrKwsFCjR49Wjx491KJFC02fPr3KfpyT9R9HW8/J2ozjunXrdM0116hjx44KCgpSfHy8NmzY4NbPI+ejAf6/YcOGmZiYGJOdnW2ys7NNTEyMuf7668+4zoIFC0zbtm3N2rVrzc6dO82oUaNMWFiYKS0tdfYZNGiQmTx5siksLHROv/zyS0MfTqN5+eWXjZ+fn3nuuedMXl6emTZtmmndurX59ttvq+z/zTffmFatWplp06aZvLw889xzzxk/Pz/zr3/9y9knOzvb+Pj4mIceesjk5+ebhx56yPj6+poPPvigsQ6r0TXEOK5YscIEBQW5nHuFhYWNdUheU9ux3LNnj0lKSjIvvPCC6d27t5k2bZpbH85Jz4yjjedkbcdx2rRp5uGHHzYfffSR+fLLL01ycrLx8/MzH3/8sbOPp85HQhCMMcbk5eUZSS4n0NatW40k8/nnn1e5TkVFhQkNDTULFixwth07dswEBwebpUuXOtsGDRpU5T8GzcVll11mEhMTXdp69uxp7rvvvir733vvvaZnz54ubXfccYfp16+fc37kyJFm2LBhLn2GDh1qbrnlFg9VffZpiHFcsWKFCQ4O9nitZ7vajuVvVff3lXPylPqOo43nZH3GsVJ0dLRJTU11znvqfOR2GCRJW7duVXBwsC6//HJnW79+/RQcHKzs7Owq19mzZ4+KioqUkJDgbAsICNCgQYPc1lm5cqU6dOigiy66SLNmzdKhQ4ca5kAa2fHjx5WTk+MyBpKUkJBQ7bht3brVrf/QoUO1fft2nThx4ox9qttmU9dQ4yhJhw8fVkREhM4//3xdf/31ys3N9fwBnEXqMpY1wTl5Sn3HUbLrnPTEOFZUVOjQoUM699xznW2eOh8JQZAkFRUVqVOnTm7tnTp1cvvS2t+uI8ntC29DQkJc1rn11lu1atUqbdq0SXPmzNHatWt10003ebB679m/f7/Ky8t/dwx+q6ioqMr+J0+e1P79+8/Yp7ptNnUNNY49e/ZURkaG3njjDa1atUqBgYEaMGCAvvrqq4Y5kLNAXcayJjgnT6nvMdt2TnpiHB977DEdOXJEI0eOdLZ56nz06tdmoOGlpKQoNTX1jH22bdsmSXI4HG7LjDFVtv/W6ctPX2fy5MnOP8fExOjCCy9UXFycPv74Y/Xt2/d3j6Ep+L0xqEn/09tru83mwNPj2K9fP/Xr18+5fMCAAerbt6+eeuopPfnkk54q+6zUEOcP52T9j9nWc7Ku47hq1SqlpKTo9ddfd/uPuic+G0JQM3fnnXf+7ptYkZGR+vTTT/Xjjz+6Lfvpp5/c0nal0NBQSacSeVhYmLO9uLi42nUkqW/fvvLz89NXX33V5ENQhw4d5OPj4/a/jzONQWhoaJX9fX191b59+zP2OdO4NmUNNY6na9GihS699NJm+79uqW5jWROck6d4+pib+zlZn3FcvXq1Jk6cqDVr1ujqq692Weap85HbYc1chw4d1LNnzzNOgYGBio+PV0lJiT766CPnuh9++KFKSkrUv3//KrcdFRWl0NBQZWVlOduOHz+uzZs3V7uOJO3atUsnTpxwCU5Nlb+/v2JjY13GQJKysrKqHYP4+Hi3/m+99Zbi4uLk5+d3xj5nGtemrKHG8XTGGO3YsaNZnHvVqctY1gTn5Cn1HcfTNfdzsq7juGrVKo0fP14vvfSSrrvuOrflHjsfa/UYNZq1YcOGmYsvvths3brVbN261fzhD39we0W+R48eZt26dc75BQsWmODgYLNu3Tqzc+dO86c//cnlFfmvv/7apKammm3btpk9e/aY//znP6Znz56mT58+5uTJk416fA2l8vXPZcuWmby8PDN9+nTTunVrs3fvXmOMMffdd58ZM2aMs3/lq90zZswweXl5ZtmyZW6vdr///vvGx8fHLFiwwOTn55sFCxZY8zqyJ8cxJSXFrF+/3uzevdvk5uaa22+/3fj6+poPP/yw0Y+vMdV2LI0xJjc31+Tm5prY2FgzevRok5uba3bt2uVczjnpmXG08Zys7Ti+9NJLxtfX1yxatKjaX63iqfOREASnAwcOmFtvvdW0bdvWtG3b1tx6663m4MGDLn0kmRUrVjjnKyoqzLx580xoaKgJCAgwV1xxhdm5c6dzeUFBgbniiivMueeea/z9/c0FF1xgkpKSzIEDBxrpqBrHokWLTEREhPH39zd9+/Y1mzdvdi4bN26cGTRokEv/TZs2mT59+hh/f38TGRlplixZ4rbNNWvWmB49ehg/Pz/Ts2dPs3bt2oY+DK/z9DhOnz7ddOnSxfj7+5uOHTuahIQEk52d3RiH4nW1HUtJblNERIRLH87J+o+jredkbcZx0KBBVY7juHHjXLbpifPRYcz/f5IQAADAIjwTBAAArEQIAgAAViIEAQAAKxGCAACAlQhBAADASoQgAABgJUIQAACwEiEIAABYiRAEnMVSUlLUu3dv5/z48eN144031mubnthGUzZ48GA5HA45HA7t2LHD2+VYIzIy0jnuv/zyi7fLASQRgoBaGz9+vPMfcz8/P3Xt2lWzZs3SkSNHGnzfTzzxhDIyMmrUd+/evVX+oK/NNuqjcoxOn15++eUG3/fvmTx5sgoLCxUTE6OUlJRqa62c9u7d6+2SPWrTpk2NHka2bdumtWvXNtr+gJrw9XYBQFM0bNgwrVixQidOnNCWLVs0adIkHTlyREuWLHHre+LEiWq/1by2goODz4pt1NSKFSs0bNgwl7Z27dpV2be8vFwOh0MtWrj+3+z48ePy9/ev9b7PtF6rVq0UGhoqSZo1a5YSExOdyy699FL9+c9/1uTJk51tHTt2rPX+vaGuY1UfNT2/O3bsqHPPPbcRKgJqjitBQB0EBAQoNDRU4eHhGj16tG699Va99tprkv7vFtby5cvVtWtXBQQEyBijkpIS/fnPf1anTp0UFBSkK6+8Up988onLdhcsWKCQkBC1bdtWEydO1LFjx1yWn34rq6KiQg8//LC6deumgIAAdenSRX//+98lSVFRUZKkPn36yOFwaPDgwVVuo6ysTElJSerUqZMCAwP1xz/+Udu2bXMur7xqsHHjRsXFxalVq1bq37+/vvjii98dp3bt2ik0NNRlCgwMlCRlZGSoXbt2evPNNxUdHa2AgAB9++23ioyM1IMPPqjx48crODjYGUbWrl2riy66SAEBAYqMjNRjjz3msq/q1vs9bdq0canPx8dHbdu2dc63bNlSU6ZMqfZz++3n3aVLF7Vp00ZTpkxReXm5HnnkEYWGhqpTp07Oz6WSw+HQkiVLNHz4cLVs2VJRUVFas2aNS5/vv/9eo0aN0jnnnKP27dtrxIgRLlelKj/LtLQ0de7cWd27d5ck/fOf/1RcXJzzOEaPHq3i4mJJp64QDhkyRJJ0zjnnyOFwaPz48c4xTE9Pd6mhd+/eSklJcal76dKlGjFihFq3bq0HH3xQkvTvf/9bsbGxCgwMVNeuXZWamqqTJ0/W6DMAvIUQBHhAy5YtdeLECef8119/rVdeeUVr16513o667rrrVFRUpMzMTOXk5Khv37666qqr9PPPP0uSXnnlFc2bN09///vftX37doWFhWnx4sVn3G9ycrIefvhhzZkzR3l5eXrppZcUEhIiSfroo48kSW+//bYKCwu1bt26Krdx7733au3atXrhhRf08ccfq1u3bho6dKizrkqzZ8/WY489pu3bt8vX11cTJkyo01j91q+//qq0tDQ9//zz2rVrlzp16iRJ+p//+R/FxMQoJydHc+bMUU5OjkaOHKlbbrlFO3fuVEpKiubMmeN2W+/09erLGPO7n5sk7d69W//7v/+r9evXa9WqVVq+fLmuu+46fffdd9q8ebMefvhh3X///frggw9ctj9nzhzdfPPN+uSTT3TbbbfpT3/6k/Lz851jM2TIELVp00bvvvuu3nvvPbVp00bDhg3T8ePHndvYuHGj8vPzlZWVpTfffFPSqStCDzzwgD755BO99tpr2rNnjzPohIeHO29LffHFFyosLNQTTzxRq3GZN2+eRowYoZ07d2rChAnasGGDbrvtNiUlJSkvL0/PPPOMMjIy3IIfcNap9ffOA5YbN26cGTFihHP+ww8/NO3btzcjR440xhgzb9484+fnZ4qLi519Nm7caIKCgsyxY8dctnXBBReYZ555xhhjTHx8vElMTHRZfvnll5tLLrmkyn2XlpaagIAA89xzz1VZ5549e4wkk5ubW239hw8fNn5+fmblypXO5cePHzedO3c2jzzyiDHGmHfeecdIMm+//bazz3/+8x8jyRw9erSaUTJGkgkMDDStW7d2mXbv3m2MMWbFihVGktmxY4fLehEREebGG290aRs9erS55pprXNruueceEx0dfcb1qjJo0CAzbdq0apdHRESYxx9/3BhTs89t3rx5plWrVqa0tNS5fOjQoSYyMtKUl5c723r06GHS0tKc85Kq/LynTJlijDFm2bJlpkePHqaiosK5vKyszLRs2dJs2LDBGHPqswwJCTFlZWVnPOaPPvrISDKHDh0yxvzfZ3rw4MFqj73SJZdcYubNm+dS9/Tp0136DBw40Dz00EMubf/4xz9MWFiYS1t1+wW8hWeCgDp488031aZNG508eVInTpzQiBEj9NRTTzmXR0REuDxHkpOTo8OHD6t9+/Yu2zl69Kh2794tScrPz3d5NkWS4uPj9c4771RZQ35+vsrKynTVVVfV+Th2796tEydOaMCAAc42Pz8/XXbZZc4rEpUuvvhi55/DwsIkScXFxerSpUu123/88cd19dVXu7SFh4c7/+zv7++y3UpxcXEu8/n5+RoxYoRL24ABA5Senq7y8nL5+PhUuV591eRzk07dRmrbtq1zPiQkRD4+Pi7PN4WEhDhvSVWKj493m6+8cpiTk6Ovv/7aZbuSdOzYMZd9/+EPf3B7Dig3N1cpKSnasWOHfv75Z1VUVEiSCgoKFB0dXdPDr9bp45yTk6Nt27a5XPkpLy/XsWPH9Ouvv6pVq1b13ifQEAhBQB0MGTJES5YskZ+fnzp37uz2YGjr1q1d5isqKhQWFqZNmza5bau6B4V/T8uWLeu03m8ZYySdes7j9PbT2357jJXLKn+4Vic0NFTdunWrdnnLli3d9iO5j19V9VTWfqb16qumn9vpn3/lm4Ont/3eeFX2q9x3bGysVq5c6dbntwH79GM+cuSIEhISlJCQoH/+85/q2LGjCgoKNHToUJfbaFVp0aKF27j+9jZvdfusqKhQamqqbrrpJre+lc+AAWcjQhBQB61btz7jD/fT9e3bV0VFRfL19VVkZGSVfXr16qUPPvhAY8eOdbad/gzJb1144YVq2bKlNm7cqEmTJrktr7w6UF5eXu02unXrJn9/f7333nsaPXq0pFM/9LZv367p06fX4MgaR3R0tN577z2XtuzsbHXv3t15Fagh1ORzq4+qPu8+ffo497169WrnA9k19fnnn2v//v1asGCB86rb9u3bXfpUd2507NhRhYWFzvnS0lLt2bPnd/fZt29fffHFF7X6OwGcDXgwGmgEV199teLj43XjjTdqw4YN2rt3r7Kzs3X//fc7f0BNmzZNy5cv1/Lly/Xll19q3rx52rVrV7XbDAwM1F//+lfde++9evHFF7V792598MEHWrZsmSSpU6dOatmypdavX68ff/xRJSUlbtto3bq1pkyZonvuuUfr169XXl6eJk+erF9//VUTJ06s93H/8ssvKioqcpnq8vuU7r77bm3cuFEPPPCAvvzyS73wwgt6+umnNWvWrHrXeCY1+dzqY82aNS6f90cffaQ777xTknTrrbeqQ4cOGjFihLZs2aI9e/Zo8+bNmjZtmr777rtqt9mlSxf5+/vrqaee0jfffKM33nhDDzzwgEufiIgIORwOvfnmm/rpp590+PBhSdKVV16pf/zjH9qyZYs+++wzjRs3rkYhc+7cuXrxxReVkpKiXbt2KT8/X6tXr9b9999fj9EBGh4hCGgEDodDmZmZuuKKKzRhwgR1795dt9xyi/bu3et8m2vUqFGaO3eu/vrXvyo2NlbffvutpkyZcsbtzpkzR3fffbfmzp2rXr16adSoUc7nTnx9ffXkk0/qmWeeUefOnd2eqam0YMEC3XzzzRozZoz69u2rr7/+Whs2bNA555xT7+O+/fbbFRYW5jL99tmpmurbt69eeeUVvfzyy4qJidHcuXM1f/585xtPDaUmn1t9pKam6uWXX9bFF1+sF154QStXrnQ+s9OqVSu9++676tKli2666Sb16tVLEyZM0NGjR894Zahjx47KyMjQmjVrFB0drQULFujRRx916XPeeecpNTVV9913n0JCQpzBKzk5WVdccYWuv/56XXvttbrxxht1wQUX/O5xDB06VG+++aaysrJ06aWXql+/flq4cKEiIiLqMTpAw3OYqm6sA0AzNXjwYPXu3dvt9+E0NofDoVdffdWqrzDZtGmThgwZooMHD9b5WTjAk7gSBMA6ixcvVps2bbRz505vl2KNiy66SMOHD/d2GYALHowGYJWVK1fq6NGjknTG1/vhWZmZmc43zWrzoDfQkLgdBgAArMTtMAAAYCVCEAAAsBIhCAAAWIkQBAAArEQIAgAAViIEAQAAKxGCAACAlQhBAADASv8P09gKyHteomoAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# original\n",
    "plt.hist(ori_error_exit, bins=25)\n",
    "plt.xlabel('Prediction Error [Temperature]')\n",
    "_ = plt.ylabel('Count')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fa24a0",
   "metadata": {},
   "source": [
    "#### Average error (AE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8c90bb",
   "metadata": {},
   "source": [
    "AE: Provide a measure of bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d98de95a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average error: -4.173657057012868\n"
     ]
    }
   ],
   "source": [
    "average_error_entrance = np.mean(error_entrance)\n",
    "print(\"Average error:\", average_error_entrance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "a7da3197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average error: -6.4893857014973975\n"
     ]
    }
   ],
   "source": [
    "# original\n",
    "ori_average_error_entrance = np.mean(ori_error_entrance)\n",
    "print(\"Average error:\", ori_average_error_entrance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "f3634dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average error: 0.08173270334501356\n"
     ]
    }
   ],
   "source": [
    "average_error_exit = np.mean(error_exit)\n",
    "print(\"Average error:\", average_error_exit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "b01d58a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average error: 0.03615122477213598\n"
     ]
    }
   ],
   "source": [
    "# original\n",
    "ori_average_error_exit = np.mean(ori_error_exit)\n",
    "print(\"Average error:\", ori_average_error_exit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58aee21",
   "metadata": {},
   "source": [
    "#### Mean squared error (MSE) and mean absolute error (MAE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef604f2d",
   "metadata": {},
   "source": [
    "MSE: Penalize significant errors more heavily \\\n",
    "MAE: Provide a measure of the average magnitude of errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "33b9d2af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 27.807323543159487\n",
      "Mean Absolute Error: 4.412984914955193\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mse = mean_squared_error(test_labels_entrance, test_predictions_entrance)\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "mae = mean_absolute_error(test_labels_entrance, test_predictions_entrance)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Mean Absolute Error:\", mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "52ba6f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 46.76967466451324\n",
      "Mean Absolute Error: 6.4893857014973975\n"
     ]
    }
   ],
   "source": [
    "# original\n",
    "ori_mse = mean_squared_error(ori_test_labels_entrance, ori_test_predictions_entrance)\n",
    "ori_mae = mean_absolute_error(ori_test_labels_entrance, ori_test_predictions_entrance)\n",
    "print(\"Mean Squared Error:\", ori_mse)\n",
    "print(\"Mean Absolute Error:\", ori_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "aa516341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.22737315717287215\n",
      "Mean Absolute Error: 0.3404208850965077\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mse = mean_squared_error(test_labels_exit, test_predictions_exit)\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "mae = mean_absolute_error(test_labels_exit, test_predictions_exit)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Mean Absolute Error:\", mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "084822bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.01433153624631104\n",
      "Mean Absolute Error: 0.09211798095703234\n"
     ]
    }
   ],
   "source": [
    "# original\n",
    "ori_mse = mean_squared_error(ori_test_labels_exit, ori_test_predictions_exit)\n",
    "ori_mae = mean_absolute_error(ori_test_labels_exit, ori_test_predictions_exit)\n",
    "print(\"Mean Squared Error:\", ori_mse)\n",
    "print(\"Mean Absolute Error:\", ori_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "1f61b106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE: 5.02%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def mean_absolute_percentage_error(y_actual, y_pred):\n",
    "    y_actual, y_pred = np.array(y_actual), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_actual - y_pred) / y_actual)) * 100\n",
    "\n",
    "mape = mean_absolute_percentage_error(test_labels_entrance, test_predictions_entrance)\n",
    "print(f'MAPE: {mape:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "48c6c420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE: 7.42%\n"
     ]
    }
   ],
   "source": [
    "# original\n",
    "mape = mean_absolute_percentage_error(ori_test_labels_entrance, ori_test_predictions_entrance)\n",
    "print(f'MAPE: {mape:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "e46bcb80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE: 0.45%\n"
     ]
    }
   ],
   "source": [
    "mape = mean_absolute_percentage_error(test_labels_exit, test_predictions_exit)\n",
    "print(f'MAPE: {mape:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "209b9517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE: 0.12%\n"
     ]
    }
   ],
   "source": [
    "mape = mean_absolute_percentage_error(ori_test_labels_exit, ori_test_predictions_exit)\n",
    "print(f'MAPE: {mape:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30dc233a",
   "metadata": {},
   "source": [
    "# Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "eb5742cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-24 19:58:36,502] A new study created in memory with name: no-name-958c5e74-92dd-4fa0-a0f2-d6c101607358\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6383/147589441.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:58:38,864] Trial 0 finished with value: 1.5924825817346573 and parameters: {'num_layers': 1, 'num_neurons_layer_0': 112, 'learning_rate': 0.0005006727798164402, 'activation': 'relu'}. Best is trial 0 with value: 1.5924825817346573.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6383/147589441.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:58:41,325] Trial 1 finished with value: 69.81199645996094 and parameters: {'num_layers': 2, 'num_neurons_layer_0': 104, 'num_neurons_layer_1': 32, 'learning_rate': 0.000168163433482474, 'activation': 'tanh'}. Best is trial 0 with value: 1.5924825817346573.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6383/147589441.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:58:43,829] Trial 2 finished with value: 0.8460460007190704 and parameters: {'num_layers': 4, 'num_neurons_layer_0': 56, 'num_neurons_layer_1': 28, 'num_neurons_layer_2': 120, 'num_neurons_layer_3': 36, 'learning_rate': 0.0001415650237917892, 'activation': 'relu'}. Best is trial 2 with value: 0.8460460007190704.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6383/147589441.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:58:45,966] Trial 3 finished with value: 42.12613487243652 and parameters: {'num_layers': 1, 'num_neurons_layer_0': 88, 'learning_rate': 0.00048659485244356205, 'activation': 'tanh'}. Best is trial 2 with value: 0.8460460007190704.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6383/147589441.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:58:48,519] Trial 4 finished with value: 0.9309985935688019 and parameters: {'num_layers': 3, 'num_neurons_layer_0': 120, 'num_neurons_layer_1': 112, 'num_neurons_layer_2': 108, 'learning_rate': 0.0022536387421162093, 'activation': 'relu'}. Best is trial 2 with value: 0.8460460007190704.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6383/147589441.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:58:51,334] Trial 5 finished with value: 3.2236512415111065 and parameters: {'num_layers': 4, 'num_neurons_layer_0': 36, 'num_neurons_layer_1': 124, 'num_neurons_layer_2': 72, 'num_neurons_layer_3': 52, 'learning_rate': 0.0018951213525396067, 'activation': 'tanh'}. Best is trial 2 with value: 0.8460460007190704.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6383/147589441.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:58:53,737] Trial 6 finished with value: 2.3445650413632393 and parameters: {'num_layers': 2, 'num_neurons_layer_0': 36, 'num_neurons_layer_1': 16, 'learning_rate': 0.006636839043015897, 'activation': 'tanh'}. Best is trial 2 with value: 0.8460460007190704.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6383/147589441.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:58:56,551] Trial 7 finished with value: 0.9794989228248596 and parameters: {'num_layers': 4, 'num_neurons_layer_0': 100, 'num_neurons_layer_1': 28, 'num_neurons_layer_2': 76, 'num_neurons_layer_3': 68, 'learning_rate': 0.00035374874822791124, 'activation': 'relu'}. Best is trial 2 with value: 0.8460460007190704.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6383/147589441.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:58:58,929] Trial 8 finished with value: 61.12971496582031 and parameters: {'num_layers': 1, 'num_neurons_layer_0': 28, 'learning_rate': 0.0007082957172021455, 'activation': 'tanh'}. Best is trial 2 with value: 0.8460460007190704.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6383/147589441.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:59:02,194] Trial 9 finished with value: 61.31773567199707 and parameters: {'num_layers': 5, 'num_neurons_layer_0': 44, 'num_neurons_layer_1': 96, 'num_neurons_layer_2': 104, 'num_neurons_layer_3': 80, 'num_neurons_layer_4': 72, 'learning_rate': 0.00015414545617714175, 'activation': 'tanh'}. Best is trial 2 with value: 0.8460460007190704.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6383/147589441.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:59:05,412] Trial 10 finished with value: 40.47855257987976 and parameters: {'num_layers': 5, 'num_neurons_layer_0': 64, 'num_neurons_layer_1': 60, 'num_neurons_layer_2': 20, 'num_neurons_layer_3': 20, 'num_neurons_layer_4': 16, 'learning_rate': 0.00011191701629700309, 'activation': 'relu'}. Best is trial 2 with value: 0.8460460007190704.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6383/147589441.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:59:08,326] Trial 11 finished with value: 0.7521409243345261 and parameters: {'num_layers': 3, 'num_neurons_layer_0': 128, 'num_neurons_layer_1': 68, 'num_neurons_layer_2': 128, 'learning_rate': 0.0020956629189811185, 'activation': 'relu'}. Best is trial 11 with value: 0.7521409243345261.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6383/147589441.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:59:11,133] Trial 12 finished with value: 0.8069053888320923 and parameters: {'num_layers': 3, 'num_neurons_layer_0': 72, 'num_neurons_layer_1': 64, 'num_neurons_layer_2': 124, 'learning_rate': 0.0016671988268240154, 'activation': 'relu'}. Best is trial 11 with value: 0.7521409243345261.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6383/147589441.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:59:13,935] Trial 13 finished with value: 0.8161766976118088 and parameters: {'num_layers': 3, 'num_neurons_layer_0': 84, 'num_neurons_layer_1': 68, 'num_neurons_layer_2': 128, 'learning_rate': 0.0018527104429489729, 'activation': 'relu'}. Best is trial 11 with value: 0.7521409243345261.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6383/147589441.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:59:16,823] Trial 14 finished with value: 1.001971498131752 and parameters: {'num_layers': 2, 'num_neurons_layer_0': 128, 'num_neurons_layer_1': 52, 'learning_rate': 0.005159273997480868, 'activation': 'relu'}. Best is trial 11 with value: 0.7521409243345261.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6383/147589441.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:59:19,743] Trial 15 finished with value: 0.8187957108020782 and parameters: {'num_layers': 3, 'num_neurons_layer_0': 76, 'num_neurons_layer_1': 84, 'num_neurons_layer_2': 88, 'learning_rate': 0.0028014536523665286, 'activation': 'relu'}. Best is trial 11 with value: 0.7521409243345261.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6383/147589441.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:59:22,772] Trial 16 finished with value: 0.6536020636558533 and parameters: {'num_layers': 4, 'num_neurons_layer_0': 16, 'num_neurons_layer_1': 84, 'num_neurons_layer_2': 44, 'num_neurons_layer_3': 128, 'learning_rate': 0.001031419253092423, 'activation': 'relu'}. Best is trial 16 with value: 0.6536020636558533.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6383/147589441.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:59:26,054] Trial 17 finished with value: 0.740941196680069 and parameters: {'num_layers': 4, 'num_neurons_layer_0': 24, 'num_neurons_layer_1': 88, 'num_neurons_layer_2': 40, 'num_neurons_layer_3': 128, 'learning_rate': 0.0010375182858494874, 'activation': 'relu'}. Best is trial 16 with value: 0.6536020636558533.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6383/147589441.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:59:29,107] Trial 18 finished with value: 0.996908500790596 and parameters: {'num_layers': 4, 'num_neurons_layer_0': 16, 'num_neurons_layer_1': 92, 'num_neurons_layer_2': 36, 'num_neurons_layer_3': 124, 'learning_rate': 0.0010128862232999382, 'activation': 'relu'}. Best is trial 16 with value: 0.6536020636558533.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6383/147589441.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:59:32,446] Trial 19 finished with value: 0.8709353506565094 and parameters: {'num_layers': 5, 'num_neurons_layer_0': 20, 'num_neurons_layer_1': 108, 'num_neurons_layer_2': 48, 'num_neurons_layer_3': 124, 'num_neurons_layer_4': 124, 'learning_rate': 0.0010695301525790457, 'activation': 'relu'}. Best is trial 16 with value: 0.6536020636558533.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6383/147589441.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:59:35,748] Trial 20 finished with value: 0.792401134967804 and parameters: {'num_layers': 4, 'num_neurons_layer_0': 44, 'num_neurons_layer_1': 48, 'num_neurons_layer_2': 52, 'num_neurons_layer_3': 100, 'learning_rate': 0.0037947860005036215, 'activation': 'relu'}. Best is trial 16 with value: 0.6536020636558533.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6383/147589441.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:59:38,817] Trial 21 finished with value: 0.8577585518360138 and parameters: {'num_layers': 3, 'num_neurons_layer_0': 16, 'num_neurons_layer_1': 80, 'num_neurons_layer_2': 20, 'learning_rate': 0.001277975287848494, 'activation': 'relu'}. Best is trial 16 with value: 0.6536020636558533.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6383/147589441.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:59:41,981] Trial 22 finished with value: 0.9384611546993256 and parameters: {'num_layers': 4, 'num_neurons_layer_0': 52, 'num_neurons_layer_1': 80, 'num_neurons_layer_2': 44, 'num_neurons_layer_3': 100, 'learning_rate': 0.0007241061268293035, 'activation': 'relu'}. Best is trial 16 with value: 0.6536020636558533.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6383/147589441.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:59:45,347] Trial 23 finished with value: 0.6844347715377808 and parameters: {'num_layers': 5, 'num_neurons_layer_0': 28, 'num_neurons_layer_1': 100, 'num_neurons_layer_2': 36, 'num_neurons_layer_3': 128, 'num_neurons_layer_4': 128, 'learning_rate': 0.003161217034606672, 'activation': 'relu'}. Best is trial 16 with value: 0.6536020636558533.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6383/147589441.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:59:48,708] Trial 24 finished with value: 0.8006107807159424 and parameters: {'num_layers': 5, 'num_neurons_layer_0': 36, 'num_neurons_layer_1': 100, 'num_neurons_layer_2': 32, 'num_neurons_layer_3': 124, 'num_neurons_layer_4': 128, 'learning_rate': 0.00026948330732413787, 'activation': 'relu'}. Best is trial 16 with value: 0.6536020636558533.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6383/147589441.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:59:52,181] Trial 25 finished with value: 2.2753272652626038 and parameters: {'num_layers': 5, 'num_neurons_layer_0': 24, 'num_neurons_layer_1': 128, 'num_neurons_layer_2': 60, 'num_neurons_layer_3': 104, 'num_neurons_layer_4': 88, 'learning_rate': 0.003788278629431699, 'activation': 'relu'}. Best is trial 16 with value: 0.6536020636558533.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6383/147589441.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:59:55,467] Trial 26 finished with value: 1.4790867865085602 and parameters: {'num_layers': 4, 'num_neurons_layer_0': 28, 'num_neurons_layer_1': 112, 'num_neurons_layer_2': 32, 'num_neurons_layer_3': 128, 'learning_rate': 0.009258804126343584, 'activation': 'relu'}. Best is trial 16 with value: 0.6536020636558533.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6383/147589441.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 19:59:58,813] Trial 27 finished with value: 1.0277387499809265 and parameters: {'num_layers': 5, 'num_neurons_layer_0': 28, 'num_neurons_layer_1': 88, 'num_neurons_layer_2': 60, 'num_neurons_layer_3': 108, 'num_neurons_layer_4': 84, 'learning_rate': 0.0007001428897295022, 'activation': 'relu'}. Best is trial 16 with value: 0.6536020636558533.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6383/147589441.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:00:02,019] Trial 28 finished with value: 1.7240327894687653 and parameters: {'num_layers': 4, 'num_neurons_layer_0': 48, 'num_neurons_layer_1': 104, 'num_neurons_layer_2': 16, 'num_neurons_layer_3': 116, 'learning_rate': 0.0013007611751748452, 'activation': 'relu'}. Best is trial 16 with value: 0.6536020636558533.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6383/147589441.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:00:05,514] Trial 29 finished with value: 0.8550821542739868 and parameters: {'num_layers': 5, 'num_neurons_layer_0': 60, 'num_neurons_layer_1': 80, 'num_neurons_layer_2': 60, 'num_neurons_layer_3': 84, 'num_neurons_layer_4': 44, 'learning_rate': 0.0004566619088364115, 'activation': 'relu'}. Best is trial 16 with value: 0.6536020636558533.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6383/147589441.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:00:08,736] Trial 30 finished with value: 0.8079227805137634 and parameters: {'num_layers': 4, 'num_neurons_layer_0': 36, 'num_neurons_layer_1': 120, 'num_neurons_layer_2': 36, 'num_neurons_layer_3': 112, 'learning_rate': 0.002932282151825174, 'activation': 'relu'}. Best is trial 16 with value: 0.6536020636558533.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6383/147589441.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:00:11,577] Trial 31 finished with value: 0.7970000654459 and parameters: {'num_layers': 3, 'num_neurons_layer_0': 16, 'num_neurons_layer_1': 72, 'num_neurons_layer_2': 88, 'learning_rate': 0.001351198739928947, 'activation': 'relu'}. Best is trial 16 with value: 0.6536020636558533.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6383/147589441.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:00:14,365] Trial 32 finished with value: 0.7921300828456879 and parameters: {'num_layers': 2, 'num_neurons_layer_0': 108, 'num_neurons_layer_1': 92, 'learning_rate': 0.0008547726578118829, 'activation': 'relu'}. Best is trial 16 with value: 0.6536020636558533.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6383/147589441.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:00:17,331] Trial 33 finished with value: 0.6763487309217453 and parameters: {'num_layers': 3, 'num_neurons_layer_0': 96, 'num_neurons_layer_1': 56, 'num_neurons_layer_2': 44, 'learning_rate': 0.0026130210058488415, 'activation': 'relu'}. Best is trial 16 with value: 0.6536020636558533.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6383/147589441.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:00:20,560] Trial 34 finished with value: 1.7124363109469414 and parameters: {'num_layers': 4, 'num_neurons_layer_0': 96, 'num_neurons_layer_1': 48, 'num_neurons_layer_2': 44, 'num_neurons_layer_3': 88, 'learning_rate': 0.0045499578052782385, 'activation': 'tanh'}. Best is trial 16 with value: 0.6536020636558533.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6383/147589441.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:00:23,584] Trial 35 finished with value: 0.6810104548931122 and parameters: {'num_layers': 3, 'num_neurons_layer_0': 112, 'num_neurons_layer_1': 40, 'num_neurons_layer_2': 28, 'learning_rate': 0.0030805742122938014, 'activation': 'relu'}. Best is trial 16 with value: 0.6536020636558533.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6383/147589441.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:00:26,415] Trial 36 finished with value: 0.6760101318359375 and parameters: {'num_layers': 3, 'num_neurons_layer_0': 116, 'num_neurons_layer_1': 44, 'num_neurons_layer_2': 28, 'learning_rate': 0.0027592343917850547, 'activation': 'relu'}. Best is trial 16 with value: 0.6536020636558533.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6383/147589441.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:00:29,071] Trial 37 finished with value: 0.6615772470831871 and parameters: {'num_layers': 2, 'num_neurons_layer_0': 116, 'num_neurons_layer_1': 40, 'learning_rate': 0.007131739739064789, 'activation': 'tanh'}. Best is trial 16 with value: 0.6536020636558533.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6383/147589441.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:00:31,649] Trial 38 finished with value: 0.4670785516500473 and parameters: {'num_layers': 1, 'num_neurons_layer_0': 120, 'learning_rate': 0.009800022078898239, 'activation': 'tanh'}. Best is trial 38 with value: 0.4670785516500473.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6383/147589441.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:00:34,249] Trial 39 finished with value: 0.443444199860096 and parameters: {'num_layers': 1, 'num_neurons_layer_0': 120, 'learning_rate': 0.009742984014831842, 'activation': 'tanh'}. Best is trial 39 with value: 0.443444199860096.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6383/147589441.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:00:36,841] Trial 40 finished with value: 0.5821045413613319 and parameters: {'num_layers': 1, 'num_neurons_layer_0': 120, 'learning_rate': 0.009916735085376676, 'activation': 'tanh'}. Best is trial 39 with value: 0.443444199860096.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6383/147589441.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:00:39,411] Trial 41 finished with value: 0.48143240064382553 and parameters: {'num_layers': 1, 'num_neurons_layer_0': 120, 'learning_rate': 0.009364675115684446, 'activation': 'tanh'}. Best is trial 39 with value: 0.443444199860096.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6383/147589441.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:00:42,258] Trial 42 finished with value: 0.5239483863115311 and parameters: {'num_layers': 1, 'num_neurons_layer_0': 124, 'learning_rate': 0.00968919450661188, 'activation': 'tanh'}. Best is trial 39 with value: 0.443444199860096.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6383/147589441.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:00:44,858] Trial 43 finished with value: 0.5051498264074326 and parameters: {'num_layers': 1, 'num_neurons_layer_0': 124, 'learning_rate': 0.009819459186117959, 'activation': 'tanh'}. Best is trial 39 with value: 0.443444199860096.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6383/147589441.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:00:47,554] Trial 44 finished with value: 0.47546857222914696 and parameters: {'num_layers': 1, 'num_neurons_layer_0': 124, 'learning_rate': 0.007171344560286514, 'activation': 'tanh'}. Best is trial 39 with value: 0.443444199860096.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6383/147589441.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:00:50,180] Trial 45 finished with value: 0.5100218206644058 and parameters: {'num_layers': 1, 'num_neurons_layer_0': 108, 'learning_rate': 0.006906849445679008, 'activation': 'tanh'}. Best is trial 39 with value: 0.443444199860096.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6383/147589441.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:00:52,862] Trial 46 finished with value: 0.39729592204093933 and parameters: {'num_layers': 1, 'num_neurons_layer_0': 124, 'learning_rate': 0.005514531407669683, 'activation': 'tanh'}. Best is trial 46 with value: 0.39729592204093933.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6383/147589441.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:00:55,415] Trial 47 finished with value: 0.36320966109633446 and parameters: {'num_layers': 1, 'num_neurons_layer_0': 104, 'learning_rate': 0.005410490232028349, 'activation': 'tanh'}. Best is trial 47 with value: 0.36320966109633446.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6383/147589441.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:00:58,055] Trial 48 finished with value: 0.4667072109878063 and parameters: {'num_layers': 1, 'num_neurons_layer_0': 104, 'learning_rate': 0.005462198160643826, 'activation': 'tanh'}. Best is trial 47 with value: 0.36320966109633446.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6383/147589441.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:01:00,890] Trial 49 finished with value: 8.758821725845337 and parameters: {'num_layers': 2, 'num_neurons_layer_0': 104, 'num_neurons_layer_1': 16, 'learning_rate': 0.005596975864563591, 'activation': 'tanh'}. Best is trial 47 with value: 0.36320966109633446.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6383/147589441.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:01:03,475] Trial 50 finished with value: 0.41806307062506676 and parameters: {'num_layers': 1, 'num_neurons_layer_0': 100, 'learning_rate': 0.005799467970319974, 'activation': 'tanh'}. Best is trial 47 with value: 0.36320966109633446.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6383/147589441.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:01:06,165] Trial 51 finished with value: 0.41679009050130844 and parameters: {'num_layers': 1, 'num_neurons_layer_0': 96, 'learning_rate': 0.005768691754798629, 'activation': 'tanh'}. Best is trial 47 with value: 0.36320966109633446.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6383/147589441.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:01:08,815] Trial 52 finished with value: 0.4545419029891491 and parameters: {'num_layers': 1, 'num_neurons_layer_0': 88, 'learning_rate': 0.005612287843906213, 'activation': 'tanh'}. Best is trial 47 with value: 0.36320966109633446.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6383/147589441.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:01:11,411] Trial 53 finished with value: 0.39988818019628525 and parameters: {'num_layers': 1, 'num_neurons_layer_0': 88, 'learning_rate': 0.004282630378559565, 'activation': 'tanh'}. Best is trial 47 with value: 0.36320966109633446.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6383/147589441.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:01:13,894] Trial 54 finished with value: 0.42908458039164543 and parameters: {'num_layers': 1, 'num_neurons_layer_0': 80, 'learning_rate': 0.004190824045477732, 'activation': 'tanh'}. Best is trial 47 with value: 0.36320966109633446.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6383/147589441.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:01:16,760] Trial 55 finished with value: 14.510530948638916 and parameters: {'num_layers': 2, 'num_neurons_layer_0': 80, 'num_neurons_layer_1': 20, 'learning_rate': 0.004127656298124181, 'activation': 'tanh'}. Best is trial 47 with value: 0.36320966109633446.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6383/147589441.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:01:19,349] Trial 56 finished with value: 0.45289361476898193 and parameters: {'num_layers': 1, 'num_neurons_layer_0': 92, 'learning_rate': 0.0035703335012768557, 'activation': 'tanh'}. Best is trial 47 with value: 0.36320966109633446.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6383/147589441.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:01:21,848] Trial 57 finished with value: 0.43401629105210304 and parameters: {'num_layers': 1, 'num_neurons_layer_0': 72, 'learning_rate': 0.004869658753993747, 'activation': 'tanh'}. Best is trial 47 with value: 0.36320966109633446.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6383/147589441.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:01:24,563] Trial 58 finished with value: 1.7060320116579533 and parameters: {'num_layers': 2, 'num_neurons_layer_0': 84, 'num_neurons_layer_1': 24, 'learning_rate': 0.00775170154653812, 'activation': 'tanh'}. Best is trial 47 with value: 0.36320966109633446.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6383/147589441.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:01:27,234] Trial 59 finished with value: 0.42352938652038574 and parameters: {'num_layers': 1, 'num_neurons_layer_0': 96, 'learning_rate': 0.006064816249196885, 'activation': 'tanh'}. Best is trial 47 with value: 0.36320966109633446.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6383/147589441.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:01:30,115] Trial 60 finished with value: 0.4876057803630829 and parameters: {'num_layers': 2, 'num_neurons_layer_0': 100, 'num_neurons_layer_1': 120, 'learning_rate': 0.0061266206749132765, 'activation': 'tanh'}. Best is trial 47 with value: 0.36320966109633446.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6383/147589441.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:01:32,726] Trial 61 finished with value: 0.3688250556588173 and parameters: {'num_layers': 1, 'num_neurons_layer_0': 92, 'learning_rate': 0.004503697154041131, 'activation': 'tanh'}. Best is trial 47 with value: 0.36320966109633446.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6383/147589441.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:01:35,363] Trial 62 finished with value: 0.5676713362336159 and parameters: {'num_layers': 1, 'num_neurons_layer_0': 92, 'learning_rate': 0.008045481816266036, 'activation': 'tanh'}. Best is trial 47 with value: 0.36320966109633446.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6383/147589441.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:01:38,002] Trial 63 finished with value: 0.4731113724410534 and parameters: {'num_layers': 1, 'num_neurons_layer_0': 100, 'learning_rate': 0.002322863955249082, 'activation': 'tanh'}. Best is trial 47 with value: 0.36320966109633446.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6383/147589441.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:01:40,658] Trial 64 finished with value: 0.3947700634598732 and parameters: {'num_layers': 1, 'num_neurons_layer_0': 88, 'learning_rate': 0.004837230925306066, 'activation': 'tanh'}. Best is trial 47 with value: 0.36320966109633446.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6383/147589441.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:01:43,258] Trial 65 finished with value: 0.4248566962778568 and parameters: {'num_layers': 1, 'num_neurons_layer_0': 88, 'learning_rate': 0.004782597148421807, 'activation': 'tanh'}. Best is trial 47 with value: 0.36320966109633446.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6383/147589441.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:01:45,854] Trial 66 finished with value: 0.440652035176754 and parameters: {'num_layers': 1, 'num_neurons_layer_0': 68, 'learning_rate': 0.00342716573480483, 'activation': 'tanh'}. Best is trial 47 with value: 0.36320966109633446.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6383/147589441.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:01:48,592] Trial 67 finished with value: 1.7080082520842552 and parameters: {'num_layers': 2, 'num_neurons_layer_0': 92, 'num_neurons_layer_1': 36, 'learning_rate': 0.004400391632372293, 'activation': 'tanh'}. Best is trial 47 with value: 0.36320966109633446.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6383/147589441.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:01:51,388] Trial 68 finished with value: 0.5850579813122749 and parameters: {'num_layers': 1, 'num_neurons_layer_0': 84, 'learning_rate': 0.006323091727548264, 'activation': 'tanh'}. Best is trial 47 with value: 0.36320966109633446.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6383/147589441.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:01:53,975] Trial 69 finished with value: 0.42371916025877 and parameters: {'num_layers': 1, 'num_neurons_layer_0': 104, 'learning_rate': 0.00813700431989055, 'activation': 'tanh'}. Best is trial 47 with value: 0.36320966109633446.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6383/147589441.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:01:56,714] Trial 70 finished with value: 1.7052264586091042 and parameters: {'num_layers': 2, 'num_neurons_layer_0': 100, 'num_neurons_layer_1': 32, 'learning_rate': 0.00501471026213269, 'activation': 'tanh'}. Best is trial 47 with value: 0.36320966109633446.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6383/147589441.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:01:59,435] Trial 71 finished with value: 0.5107102245092392 and parameters: {'num_layers': 1, 'num_neurons_layer_0': 96, 'learning_rate': 0.006039058491252839, 'activation': 'tanh'}. Best is trial 47 with value: 0.36320966109633446.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6383/147589441.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:02:02,219] Trial 72 finished with value: 0.4454530030488968 and parameters: {'num_layers': 1, 'num_neurons_layer_0': 88, 'learning_rate': 0.003868009624524175, 'activation': 'tanh'}. Best is trial 47 with value: 0.36320966109633446.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6383/147589441.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:02:04,949] Trial 73 finished with value: 52.986345291137695 and parameters: {'num_layers': 1, 'num_neurons_layer_0': 108, 'learning_rate': 0.00024590312863585176, 'activation': 'tanh'}. Best is trial 47 with value: 0.36320966109633446.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6383/147589441.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:02:07,860] Trial 74 finished with value: 0.43654216080904007 and parameters: {'num_layers': 1, 'num_neurons_layer_0': 96, 'learning_rate': 0.006443879716237609, 'activation': 'tanh'}. Best is trial 47 with value: 0.36320966109633446.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6383/147589441.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:02:10,721] Trial 75 finished with value: 0.5051556564867496 and parameters: {'num_layers': 1, 'num_neurons_layer_0': 80, 'learning_rate': 0.003308787613527393, 'activation': 'tanh'}. Best is trial 47 with value: 0.36320966109633446.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6383/147589441.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:02:13,413] Trial 76 finished with value: 0.4035085663199425 and parameters: {'num_layers': 1, 'num_neurons_layer_0': 92, 'learning_rate': 0.005095004258496058, 'activation': 'tanh'}. Best is trial 47 with value: 0.36320966109633446.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6383/147589441.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:02:16,153] Trial 77 finished with value: 0.43585608527064323 and parameters: {'num_layers': 1, 'num_neurons_layer_0': 112, 'learning_rate': 0.002386725087904445, 'activation': 'tanh'}. Best is trial 47 with value: 0.36320966109633446.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6383/147589441.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:02:18,881] Trial 78 finished with value: 1.7076052203774452 and parameters: {'num_layers': 1, 'num_neurons_layer_0': 76, 'learning_rate': 0.0018102137098540447, 'activation': 'tanh'}. Best is trial 47 with value: 0.36320966109633446.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6383/147589441.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:02:21,709] Trial 79 finished with value: 0.5390064530074596 and parameters: {'num_layers': 2, 'num_neurons_layer_0': 84, 'num_neurons_layer_1': 60, 'learning_rate': 0.005141709999964499, 'activation': 'tanh'}. Best is trial 47 with value: 0.36320966109633446.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6383/147589441.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:02:24,554] Trial 80 finished with value: 0.5562276095151901 and parameters: {'num_layers': 1, 'num_neurons_layer_0': 92, 'learning_rate': 0.008260676520664983, 'activation': 'tanh'}. Best is trial 47 with value: 0.36320966109633446.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6383/147589441.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:02:27,195] Trial 81 finished with value: 0.41132548078894615 and parameters: {'num_layers': 1, 'num_neurons_layer_0': 100, 'learning_rate': 0.004605032892449045, 'activation': 'tanh'}. Best is trial 47 with value: 0.36320966109633446.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6383/147589441.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:02:29,835] Trial 82 finished with value: 0.4695252850651741 and parameters: {'num_layers': 1, 'num_neurons_layer_0': 104, 'learning_rate': 0.004535021065072342, 'activation': 'tanh'}. Best is trial 47 with value: 0.36320966109633446.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6383/147589441.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:02:32,629] Trial 83 finished with value: 0.3778449445962906 and parameters: {'num_layers': 1, 'num_neurons_layer_0': 112, 'learning_rate': 0.003878082009471544, 'activation': 'tanh'}. Best is trial 47 with value: 0.36320966109633446.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6383/147589441.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:02:35,344] Trial 84 finished with value: 0.41078297048807144 and parameters: {'num_layers': 1, 'num_neurons_layer_0': 116, 'learning_rate': 0.0038059001208692856, 'activation': 'tanh'}. Best is trial 47 with value: 0.36320966109633446.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6383/147589441.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:02:38,074] Trial 85 finished with value: 0.4028336927294731 and parameters: {'num_layers': 1, 'num_neurons_layer_0': 112, 'learning_rate': 0.003925433961664148, 'activation': 'tanh'}. Best is trial 47 with value: 0.36320966109633446.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6383/147589441.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:02:40,940] Trial 86 finished with value: 0.45855268090963364 and parameters: {'num_layers': 1, 'num_neurons_layer_0': 112, 'learning_rate': 0.0038929117154223054, 'activation': 'tanh'}. Best is trial 47 with value: 0.36320966109633446.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6383/147589441.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:02:43,751] Trial 87 finished with value: 0.5029719322919846 and parameters: {'num_layers': 1, 'num_neurons_layer_0': 116, 'learning_rate': 0.0025505843751632176, 'activation': 'tanh'}. Best is trial 47 with value: 0.36320966109633446.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6383/147589441.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:02:46,480] Trial 88 finished with value: 0.41204529628157616 and parameters: {'num_layers': 1, 'num_neurons_layer_0': 128, 'learning_rate': 0.0037782251041331037, 'activation': 'tanh'}. Best is trial 47 with value: 0.36320966109633446.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6383/147589441.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:02:49,436] Trial 89 finished with value: 0.4619959779083729 and parameters: {'num_layers': 2, 'num_neurons_layer_0': 116, 'num_neurons_layer_1': 112, 'learning_rate': 0.002100349490987471, 'activation': 'tanh'}. Best is trial 47 with value: 0.36320966109633446.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6383/147589441.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:02:52,224] Trial 90 finished with value: 0.4795007072389126 and parameters: {'num_layers': 1, 'num_neurons_layer_0': 112, 'learning_rate': 0.0029944784763948906, 'activation': 'tanh'}. Best is trial 47 with value: 0.36320966109633446.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6383/147589441.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:02:54,933] Trial 91 finished with value: 0.3893604502081871 and parameters: {'num_layers': 1, 'num_neurons_layer_0': 108, 'learning_rate': 0.004448082120866896, 'activation': 'tanh'}. Best is trial 47 with value: 0.36320966109633446.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6383/147589441.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:02:57,753] Trial 92 finished with value: 0.39249231666326523 and parameters: {'num_layers': 1, 'num_neurons_layer_0': 108, 'learning_rate': 0.003566819864017088, 'activation': 'tanh'}. Best is trial 47 with value: 0.36320966109633446.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6383/147589441.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:03:00,718] Trial 93 finished with value: 0.4182836227118969 and parameters: {'num_layers': 1, 'num_neurons_layer_0': 108, 'learning_rate': 0.0032366984581566134, 'activation': 'tanh'}. Best is trial 47 with value: 0.36320966109633446.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6383/147589441.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:03:03,449] Trial 94 finished with value: 0.4466424286365509 and parameters: {'num_layers': 1, 'num_neurons_layer_0': 108, 'learning_rate': 0.004256978636937901, 'activation': 'tanh'}. Best is trial 47 with value: 0.36320966109633446.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6383/147589441.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:03:06,147] Trial 95 finished with value: 0.3964071199297905 and parameters: {'num_layers': 1, 'num_neurons_layer_0': 104, 'learning_rate': 0.005115815338206275, 'activation': 'tanh'}. Best is trial 47 with value: 0.36320966109633446.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6383/147589441.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:03:08,761] Trial 96 finished with value: 0.5558348819613457 and parameters: {'num_layers': 1, 'num_neurons_layer_0': 104, 'learning_rate': 0.007272061838834579, 'activation': 'tanh'}. Best is trial 47 with value: 0.36320966109633446.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6383/147589441.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:03:11,376] Trial 97 finished with value: 0.39078114181756973 and parameters: {'num_layers': 1, 'num_neurons_layer_0': 124, 'learning_rate': 0.005318388428165515, 'activation': 'tanh'}. Best is trial 47 with value: 0.36320966109633446.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6383/147589441.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:03:13,911] Trial 98 finished with value: 0.4397144690155983 and parameters: {'num_layers': 1, 'num_neurons_layer_0': 124, 'learning_rate': 0.005372951990175113, 'activation': 'tanh'}. Best is trial 47 with value: 0.36320966109633446.\n",
      "/var/folders/2z/b1lzf17n4z90pz80khfc42fw0000gp/T/ipykernel_6383/147589441.py:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2024-10-24 20:03:16,563] Trial 99 finished with value: 0.397786982357502 and parameters: {'num_layers': 1, 'num_neurons_layer_0': 124, 'learning_rate': 0.0034578560877660436, 'activation': 'tanh'}. Best is trial 47 with value: 0.36320966109633446.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:  {'num_layers': 1, 'num_neurons_layer_0': 104, 'learning_rate': 0.005410490232028349, 'activation': 'tanh'}\n",
      "Best trial loss:  0.36320966109633446\n",
      "Epoch 1/50\n",
      "9/9 [==============================] - 0s 787us/step - loss: 82.4290\n",
      "Epoch 2/50\n",
      "9/9 [==============================] - 0s 687us/step - loss: 74.7908\n",
      "Epoch 3/50\n",
      "9/9 [==============================] - 0s 589us/step - loss: 68.8738\n",
      "Epoch 4/50\n",
      "9/9 [==============================] - 0s 495us/step - loss: 63.8015\n",
      "Epoch 5/50\n",
      "9/9 [==============================] - 0s 557us/step - loss: 58.7466\n",
      "Epoch 6/50\n",
      "9/9 [==============================] - 0s 620us/step - loss: 53.5475\n",
      "Epoch 7/50\n",
      "9/9 [==============================] - 0s 629us/step - loss: 48.3059\n",
      "Epoch 8/50\n",
      "9/9 [==============================] - 0s 606us/step - loss: 43.0615\n",
      "Epoch 9/50\n",
      "9/9 [==============================] - 0s 524us/step - loss: 37.8262\n",
      "Epoch 10/50\n",
      "9/9 [==============================] - 0s 531us/step - loss: 32.6025\n",
      "Epoch 11/50\n",
      "9/9 [==============================] - 0s 509us/step - loss: 27.3897\n",
      "Epoch 12/50\n",
      "9/9 [==============================] - 0s 578us/step - loss: 22.1864\n",
      "Epoch 13/50\n",
      "9/9 [==============================] - 0s 509us/step - loss: 16.9913\n",
      "Epoch 14/50\n",
      "9/9 [==============================] - 0s 443us/step - loss: 11.8088\n",
      "Epoch 15/50\n",
      "9/9 [==============================] - 0s 485us/step - loss: 7.2114\n",
      "Epoch 16/50\n",
      "9/9 [==============================] - 0s 470us/step - loss: 4.3449\n",
      "Epoch 17/50\n",
      "9/9 [==============================] - 0s 470us/step - loss: 3.1001\n",
      "Epoch 18/50\n",
      "9/9 [==============================] - 0s 520us/step - loss: 3.2717\n",
      "Epoch 19/50\n",
      "9/9 [==============================] - 0s 540us/step - loss: 3.1268\n",
      "Epoch 20/50\n",
      "9/9 [==============================] - 0s 546us/step - loss: 3.0467\n",
      "Epoch 21/50\n",
      "9/9 [==============================] - 0s 547us/step - loss: 3.0356\n",
      "Epoch 22/50\n",
      "9/9 [==============================] - 0s 484us/step - loss: 3.0278\n",
      "Epoch 23/50\n",
      "9/9 [==============================] - 0s 506us/step - loss: 3.0228\n",
      "Epoch 24/50\n",
      "9/9 [==============================] - 0s 537us/step - loss: 3.0288\n",
      "Epoch 25/50\n",
      "9/9 [==============================] - 0s 497us/step - loss: 3.0171\n",
      "Epoch 26/50\n",
      "9/9 [==============================] - 0s 513us/step - loss: 3.0142\n",
      "Epoch 27/50\n",
      "9/9 [==============================] - 0s 532us/step - loss: 3.0122\n",
      "Epoch 28/50\n",
      "9/9 [==============================] - 0s 474us/step - loss: 3.0208\n",
      "Epoch 29/50\n",
      "9/9 [==============================] - 0s 519us/step - loss: 3.0227\n",
      "Epoch 30/50\n",
      "9/9 [==============================] - 0s 502us/step - loss: 3.0261\n",
      "Epoch 31/50\n",
      "9/9 [==============================] - 0s 513us/step - loss: 3.0140\n",
      "Epoch 32/50\n",
      "9/9 [==============================] - 0s 548us/step - loss: 3.0166\n",
      "Epoch 33/50\n",
      "9/9 [==============================] - 0s 494us/step - loss: 3.0144\n",
      "Epoch 34/50\n",
      "9/9 [==============================] - 0s 474us/step - loss: 3.0112\n",
      "Epoch 35/50\n",
      "9/9 [==============================] - 0s 477us/step - loss: 2.9702\n",
      "Epoch 36/50\n",
      "9/9 [==============================] - 0s 507us/step - loss: 2.6806\n",
      "Epoch 37/50\n",
      "9/9 [==============================] - 0s 547us/step - loss: 2.6428\n",
      "Epoch 38/50\n",
      "9/9 [==============================] - 0s 554us/step - loss: 2.6035\n",
      "Epoch 39/50\n",
      "9/9 [==============================] - 0s 511us/step - loss: 2.3278\n",
      "Epoch 40/50\n",
      "9/9 [==============================] - 0s 490us/step - loss: 1.6777\n",
      "Epoch 41/50\n",
      "9/9 [==============================] - 0s 490us/step - loss: 1.4972\n",
      "Epoch 42/50\n",
      "9/9 [==============================] - 0s 542us/step - loss: 1.2969\n",
      "Epoch 43/50\n",
      "9/9 [==============================] - 0s 560us/step - loss: 1.0573\n",
      "Epoch 44/50\n",
      "9/9 [==============================] - 0s 527us/step - loss: 0.9608\n",
      "Epoch 45/50\n",
      "9/9 [==============================] - 0s 522us/step - loss: 0.8511\n",
      "Epoch 46/50\n",
      "9/9 [==============================] - 0s 487us/step - loss: 0.8804\n",
      "Epoch 47/50\n",
      "9/9 [==============================] - 0s 475us/step - loss: 0.8190\n",
      "Epoch 48/50\n",
      "9/9 [==============================] - 0s 542us/step - loss: 0.8583\n",
      "Epoch 49/50\n",
      "9/9 [==============================] - 0s 558us/step - loss: 0.8295\n",
      "Epoch 50/50\n",
      "9/9 [==============================] - 0s 556us/step - loss: 0.8752\n",
      "Epoch 1/50\n",
      "9/9 [==============================] - 0s 638us/step - loss: 71.1487\n",
      "Epoch 2/50\n",
      "9/9 [==============================] - 0s 604us/step - loss: 64.6496\n",
      "Epoch 3/50\n",
      "9/9 [==============================] - 0s 556us/step - loss: 59.1001\n",
      "Epoch 4/50\n",
      "9/9 [==============================] - 0s 547us/step - loss: 54.1261\n",
      "Epoch 5/50\n",
      "9/9 [==============================] - 0s 604us/step - loss: 49.2190\n",
      "Epoch 6/50\n",
      "9/9 [==============================] - 0s 591us/step - loss: 44.1397\n",
      "Epoch 7/50\n",
      "9/9 [==============================] - 0s 589us/step - loss: 38.9933\n",
      "Epoch 8/50\n",
      "9/9 [==============================] - 0s 504us/step - loss: 33.8278\n",
      "Epoch 9/50\n",
      "9/9 [==============================] - 0s 501us/step - loss: 28.6596\n",
      "Epoch 10/50\n",
      "9/9 [==============================] - 0s 632us/step - loss: 23.4942\n",
      "Epoch 11/50\n",
      "9/9 [==============================] - 0s 574us/step - loss: 18.3331\n",
      "Epoch 12/50\n",
      "9/9 [==============================] - 0s 549us/step - loss: 13.1761\n",
      "Epoch 13/50\n",
      "9/9 [==============================] - 0s 488us/step - loss: 8.0229\n",
      "Epoch 14/50\n",
      "9/9 [==============================] - 0s 469us/step - loss: 2.8730\n",
      "Epoch 15/50\n",
      "9/9 [==============================] - 0s 503us/step - loss: 1.1372\n",
      "Epoch 16/50\n",
      "9/9 [==============================] - 0s 568us/step - loss: 0.6757\n",
      "Epoch 17/50\n",
      "9/9 [==============================] - 0s 517us/step - loss: 0.4345\n",
      "Epoch 18/50\n",
      "9/9 [==============================] - 0s 528us/step - loss: 0.2569\n",
      "Epoch 19/50\n",
      "9/9 [==============================] - 0s 511us/step - loss: 0.1554\n",
      "Epoch 20/50\n",
      "9/9 [==============================] - 0s 473us/step - loss: 0.1365\n",
      "Epoch 21/50\n",
      "9/9 [==============================] - 0s 523us/step - loss: 0.1177\n",
      "Epoch 22/50\n",
      "9/9 [==============================] - 0s 569us/step - loss: 0.1022\n",
      "Epoch 23/50\n",
      "9/9 [==============================] - 0s 515us/step - loss: 0.1031\n",
      "Epoch 24/50\n",
      "9/9 [==============================] - 0s 500us/step - loss: 0.1045\n",
      "Epoch 25/50\n",
      "9/9 [==============================] - 0s 495us/step - loss: 0.1028\n",
      "Epoch 26/50\n",
      "9/9 [==============================] - 0s 455us/step - loss: 0.1078\n",
      "Epoch 27/50\n",
      "9/9 [==============================] - 0s 503us/step - loss: 0.1105\n",
      "Epoch 28/50\n",
      "9/9 [==============================] - 0s 541us/step - loss: 0.1085\n",
      "Epoch 29/50\n",
      "9/9 [==============================] - 0s 463us/step - loss: 0.1079\n",
      "Epoch 30/50\n",
      "9/9 [==============================] - 0s 510us/step - loss: 0.1045\n",
      "Epoch 31/50\n",
      "9/9 [==============================] - 0s 556us/step - loss: 0.1085\n",
      "Epoch 32/50\n",
      "9/9 [==============================] - 0s 481us/step - loss: 0.1155\n",
      "Epoch 33/50\n",
      "9/9 [==============================] - 0s 526us/step - loss: 0.1138\n",
      "Epoch 34/50\n",
      "9/9 [==============================] - 0s 480us/step - loss: 0.1112\n",
      "Epoch 35/50\n",
      "9/9 [==============================] - 0s 522us/step - loss: 0.1109\n",
      "Epoch 36/50\n",
      "9/9 [==============================] - 0s 560us/step - loss: 0.1090\n",
      "Epoch 37/50\n",
      "9/9 [==============================] - 0s 551us/step - loss: 0.1137\n",
      "Epoch 38/50\n",
      "9/9 [==============================] - 0s 486us/step - loss: 0.1115\n",
      "Epoch 39/50\n",
      "9/9 [==============================] - 0s 503us/step - loss: 0.1165\n",
      "Epoch 40/50\n",
      "9/9 [==============================] - 0s 532us/step - loss: 0.1057\n",
      "Epoch 41/50\n",
      "9/9 [==============================] - 0s 526us/step - loss: 0.1007\n",
      "Epoch 42/50\n",
      "9/9 [==============================] - 0s 531us/step - loss: 0.1004\n",
      "Epoch 43/50\n",
      "9/9 [==============================] - 0s 578us/step - loss: 0.1000\n",
      "Epoch 44/50\n",
      "9/9 [==============================] - 0s 466us/step - loss: 0.1018\n",
      "Epoch 45/50\n",
      "9/9 [==============================] - 0s 484us/step - loss: 0.1040\n",
      "Epoch 46/50\n",
      "9/9 [==============================] - 0s 495us/step - loss: 0.1082\n",
      "Epoch 47/50\n",
      "9/9 [==============================] - 0s 546us/step - loss: 0.1046\n",
      "Epoch 48/50\n",
      "9/9 [==============================] - 0s 572us/step - loss: 0.1009\n",
      "Epoch 49/50\n",
      "9/9 [==============================] - 0s 516us/step - loss: 0.1026\n",
      "Epoch 50/50\n",
      "9/9 [==============================] - 0s 421us/step - loss: 0.1033\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x32e7f5390>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:  {'num_layers': 1, 'num_neurons_layer_0': 84, 'learning_rate': 0.005292881562622825, 'activation': 'tanh'}\n",
      "Best trial loss:  0.36439890041947365\n",
      "Epoch 1/50\n",
      "9/9 [==============================] - 0s 994us/step - loss: 82.8630\n",
      "Epoch 2/50\n",
      "9/9 [==============================] - 0s 750us/step - loss: 76.9507\n",
      "Epoch 3/50\n",
      "9/9 [==============================] - 0s 750us/step - loss: 72.1721\n",
      "Epoch 4/50\n",
      "9/9 [==============================] - 0s 750us/step - loss: 68.2158\n",
      "Epoch 5/50\n",
      "9/9 [==============================] - 0s 750us/step - loss: 64.1739\n",
      "Epoch 6/50\n",
      "9/9 [==============================] - 0s 750us/step - loss: 60.0504\n",
      "Epoch 7/50\n",
      "9/9 [==============================] - 0s 750us/step - loss: 55.9062\n",
      "Epoch 8/50\n",
      "9/9 [==============================] - 0s 750us/step - loss: 51.7634\n",
      "Epoch 9/50\n",
      "9/9 [==============================] - 0s 750us/step - loss: 47.6283\n",
      "Epoch 10/50\n",
      "9/9 [==============================] - 0s 750us/step - loss: 43.5019\n",
      "Epoch 11/50\n",
      "9/9 [==============================] - 0s 750us/step - loss: 39.3833\n",
      "Epoch 12/50\n",
      "9/9 [==============================] - 0s 750us/step - loss: 35.2715\n",
      "Epoch 13/50\n",
      "9/9 [==============================] - 0s 750us/step - loss: 31.1654\n",
      "Epoch 14/50\n",
      "9/9 [==============================] - 0s 741us/step - loss: 27.0642\n",
      "Epoch 15/50\n",
      "9/9 [==============================] - 0s 750us/step - loss: 22.9672\n",
      "Epoch 16/50\n",
      "9/9 [==============================] - 0s 750us/step - loss: 18.8737\n",
      "Epoch 17/50\n",
      "9/9 [==============================] - 0s 748us/step - loss: 14.7834\n",
      "Epoch 18/50\n",
      "9/9 [==============================] - 0s 625us/step - loss: 10.7207\n",
      "Epoch 19/50\n",
      "9/9 [==============================] - 0s 753us/step - loss: 7.1276\n",
      "Epoch 20/50\n",
      "9/9 [==============================] - 0s 751us/step - loss: 4.8036\n",
      "Epoch 21/50\n",
      "9/9 [==============================] - 0s 751us/step - loss: 3.5120\n",
      "Epoch 22/50\n",
      "9/9 [==============================] - 0s 750us/step - loss: 3.0825\n",
      "Epoch 23/50\n",
      "9/9 [==============================] - 0s 750us/step - loss: 3.1228\n",
      "Epoch 24/50\n",
      "9/9 [==============================] - 0s 750us/step - loss: 3.0458\n",
      "Epoch 25/50\n",
      "9/9 [==============================] - 0s 750us/step - loss: 3.0220\n",
      "Epoch 26/50\n",
      "9/9 [==============================] - 0s 750us/step - loss: 3.0122\n",
      "Epoch 27/50\n",
      "9/9 [==============================] - 0s 625us/step - loss: 3.0142\n",
      "Epoch 28/50\n",
      "9/9 [==============================] - 0s 741us/step - loss: 3.0142\n",
      "Epoch 29/50\n",
      "9/9 [==============================] - 0s 750us/step - loss: 3.0112\n",
      "Epoch 30/50\n",
      "9/9 [==============================] - 0s 750us/step - loss: 3.0123\n",
      "Epoch 31/50\n",
      "9/9 [==============================] - 0s 625us/step - loss: 3.0172\n",
      "Epoch 32/50\n",
      "9/9 [==============================] - 0s 750us/step - loss: 3.0083\n",
      "Epoch 33/50\n",
      "9/9 [==============================] - 0s 750us/step - loss: 2.6428\n",
      "Epoch 34/50\n",
      "9/9 [==============================] - 0s 741us/step - loss: 2.5192\n",
      "Epoch 35/50\n",
      "9/9 [==============================] - 0s 750us/step - loss: 2.5482\n",
      "Epoch 36/50\n",
      "9/9 [==============================] - 0s 625us/step - loss: 2.1293\n",
      "Epoch 37/50\n",
      "9/9 [==============================] - 0s 750us/step - loss: 1.9841\n",
      "Epoch 38/50\n",
      "9/9 [==============================] - 0s 750us/step - loss: 1.9400\n",
      "Epoch 39/50\n",
      "9/9 [==============================] - 0s 751us/step - loss: 1.9259\n",
      "Epoch 40/50\n",
      "9/9 [==============================] - 0s 752us/step - loss: 1.8484\n",
      "Epoch 41/50\n",
      "9/9 [==============================] - 0s 750us/step - loss: 1.8481\n",
      "Epoch 42/50\n",
      "9/9 [==============================] - 0s 875us/step - loss: 1.5286\n",
      "Epoch 43/50\n",
      "9/9 [==============================] - 0s 875us/step - loss: 1.3917\n",
      "Epoch 44/50\n",
      "9/9 [==============================] - 0s 875us/step - loss: 1.3320\n",
      "Epoch 45/50\n",
      "9/9 [==============================] - 0s 750us/step - loss: 1.3145\n",
      "Epoch 46/50\n",
      "9/9 [==============================] - 0s 750us/step - loss: 1.1324\n",
      "Epoch 47/50\n",
      "9/9 [==============================] - 0s 750us/step - loss: 1.0900\n",
      "Epoch 48/50\n",
      "9/9 [==============================] - 0s 750us/step - loss: 1.0998\n",
      "Epoch 49/50\n",
      "9/9 [==============================] - 0s 706us/step - loss: 1.1077\n",
      "Epoch 50/50\n",
      "9/9 [==============================] - 0s 717us/step - loss: 1.1560\n",
      "Epoch 1/50\n",
      "9/9 [==============================] - 0s 854us/step - loss: 69.4700\n",
      "Epoch 2/50\n",
      "9/9 [==============================] - 0s 727us/step - loss: 64.2348\n",
      "Epoch 3/50\n",
      "9/9 [==============================] - 0s 690us/step - loss: 59.5347\n",
      "Epoch 4/50\n",
      "9/9 [==============================] - 0s 807us/step - loss: 55.5645\n",
      "Epoch 5/50\n",
      "9/9 [==============================] - 0s 813us/step - loss: 51.6067\n",
      "Epoch 6/50\n",
      "9/9 [==============================] - 0s 728us/step - loss: 47.5567\n",
      "Epoch 7/50\n",
      "9/9 [==============================] - 0s 840us/step - loss: 43.4762\n",
      "Epoch 8/50\n",
      "9/9 [==============================] - 0s 750us/step - loss: 39.3883\n",
      "Epoch 9/50\n",
      "9/9 [==============================] - 0s 875us/step - loss: 35.3007\n",
      "Epoch 10/50\n",
      "9/9 [==============================] - 0s 751us/step - loss: 31.2159\n",
      "Epoch 11/50\n",
      "9/9 [==============================] - 0s 761us/step - loss: 27.1342\n",
      "Epoch 12/50\n",
      "9/9 [==============================] - 0s 750us/step - loss: 23.0554\n",
      "Epoch 13/50\n",
      "9/9 [==============================] - 0s 750us/step - loss: 18.9792\n",
      "Epoch 14/50\n",
      "9/9 [==============================] - 0s 625us/step - loss: 14.9053\n",
      "Epoch 15/50\n",
      "9/9 [==============================] - 0s 751us/step - loss: 10.8333\n",
      "Epoch 16/50\n",
      "9/9 [==============================] - 0s 750us/step - loss: 6.7629\n",
      "Epoch 17/50\n",
      "9/9 [==============================] - 0s 750us/step - loss: 2.6940\n",
      "Epoch 18/50\n",
      "9/9 [==============================] - 0s 750us/step - loss: 0.7873\n",
      "Epoch 19/50\n",
      "9/9 [==============================] - 0s 750us/step - loss: 0.5962\n",
      "Epoch 20/50\n",
      "9/9 [==============================] - 0s 625us/step - loss: 0.3523\n",
      "Epoch 21/50\n",
      "9/9 [==============================] - 0s 625us/step - loss: 0.1811\n",
      "Epoch 22/50\n",
      "9/9 [==============================] - 0s 751us/step - loss: 0.1309\n",
      "Epoch 23/50\n",
      "9/9 [==============================] - 0s 625us/step - loss: 0.1111\n",
      "Epoch 24/50\n",
      "9/9 [==============================] - 0s 625us/step - loss: 0.1019\n",
      "Epoch 25/50\n",
      "9/9 [==============================] - 0s 625us/step - loss: 0.1000\n",
      "Epoch 26/50\n",
      "9/9 [==============================] - 0s 750us/step - loss: 0.1017\n",
      "Epoch 27/50\n",
      "9/9 [==============================] - 0s 750us/step - loss: 0.1030\n",
      "Epoch 28/50\n",
      "9/9 [==============================] - 0s 751us/step - loss: 0.1056\n",
      "Epoch 29/50\n",
      "9/9 [==============================] - 0s 875us/step - loss: 0.1160\n",
      "Epoch 30/50\n",
      "9/9 [==============================] - 0s 750us/step - loss: 0.1143\n",
      "Epoch 31/50\n",
      "9/9 [==============================] - 0s 875us/step - loss: 0.1085\n",
      "Epoch 32/50\n",
      "9/9 [==============================] - 0s 751us/step - loss: 0.1003\n",
      "Epoch 33/50\n",
      "9/9 [==============================] - 0s 750us/step - loss: 0.1005\n",
      "Epoch 34/50\n",
      "9/9 [==============================] - 0s 750us/step - loss: 0.1059\n",
      "Epoch 35/50\n",
      "9/9 [==============================] - 0s 750us/step - loss: 0.1251\n",
      "Epoch 36/50\n",
      "9/9 [==============================] - 0s 751us/step - loss: 0.1078\n",
      "Epoch 37/50\n",
      "9/9 [==============================] - 0s 751us/step - loss: 0.1129\n",
      "Epoch 38/50\n",
      "9/9 [==============================] - 0s 750us/step - loss: 0.1049\n",
      "Epoch 39/50\n",
      "9/9 [==============================] - 0s 750us/step - loss: 0.1142\n",
      "Epoch 40/50\n",
      "9/9 [==============================] - 0s 625us/step - loss: 0.1081\n",
      "Epoch 41/50\n",
      "9/9 [==============================] - 0s 750us/step - loss: 0.1064\n",
      "Epoch 42/50\n",
      "9/9 [==============================] - 0s 625us/step - loss: 0.1138\n",
      "Epoch 43/50\n",
      "9/9 [==============================] - 0s 750us/step - loss: 0.1153\n",
      "Epoch 44/50\n",
      "9/9 [==============================] - 0s 627us/step - loss: 0.1250\n",
      "Epoch 45/50\n",
      "9/9 [==============================] - 0s 750us/step - loss: 0.1070\n",
      "Epoch 46/50\n",
      "9/9 [==============================] - 0s 750us/step - loss: 0.1020\n",
      "Epoch 47/50\n",
      "9/9 [==============================] - 0s 750us/step - loss: 0.1067\n",
      "Epoch 48/50\n",
      "9/9 [==============================] - 0s 751us/step - loss: 0.1154\n",
      "Epoch 49/50\n",
      "9/9 [==============================] - 0s 625us/step - loss: 0.1242\n",
      "Epoch 50/50\n",
      "9/9 [==============================] - 0s 625us/step - loss: 0.1104\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1be9a198d00>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import optuna\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "trial_losses = []\n",
    "\n",
    "# Function to create a model with the given hyperparameters\n",
    "# Function to create a model with a specific number of neurons in each layer\n",
    "def create_model(input_shape, neurons_per_layer, activation, learning_rate):\n",
    "    model = tf.keras.Sequential()\n",
    "    \n",
    "    # Add the first layer with input shape\n",
    "    model.add(layers.Dense(neurons_per_layer[0], activation=activation, input_shape=(input_shape,)))\n",
    "    \n",
    "    # Add subsequent layers with specified number of neurons\n",
    "    for neurons in neurons_per_layer[1:]:\n",
    "        model.add(layers.Dense(neurons, activation=activation))\n",
    "    \n",
    "    model.add(layers.Dense(1))  # Output layer\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate),\n",
    "                  loss='mean_absolute_error')\n",
    "    return model\n",
    "\n",
    "# Objective function to optimize both entrance and exit models\n",
    "def objective(trial):\n",
    "    # Suggest number of layers\n",
    "    num_layers = trial.suggest_int('num_layers', 1, 5)\n",
    "    \n",
    "    # Suggest a different number of neurons for each layer\n",
    "    neurons_per_layer = []\n",
    "    for i in range(num_layers):\n",
    "        neurons = trial.suggest_int(f'num_neurons_layer_{i}', 16, 128, step=4)  # Each layer can have 16 to 128 neurons\n",
    "        neurons_per_layer.append(neurons)\n",
    "    \n",
    "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
    "    activation = trial.suggest_categorical('activation', ['relu', 'tanh'])\n",
    "\n",
    "    # Create models for both entrance and exit\n",
    "    model_entrance = create_model(train_features_entrance.shape[1], neurons_per_layer, activation, learning_rate)\n",
    "    model_exit = create_model(train_features_exit.shape[1], neurons_per_layer, activation, learning_rate)\n",
    "\n",
    "    # Split data into training and validation for both entrance and exit\n",
    "    x_train_entrance, x_val_entrance, y_train_entrance, y_val_entrance = train_test_split(train_features_entrance, train_labels_entrance, test_size=0.2, random_state=42)\n",
    "    x_train_exit, x_val_exit, y_train_exit, y_val_exit = train_test_split(train_features_exit, train_labels_exit, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Train both models\n",
    "    model_entrance.fit(x_train_entrance, y_train_entrance, validation_data=(x_val_entrance, y_val_entrance), \n",
    "                       epochs=100, batch_size=32, verbose=0)\n",
    "    model_exit.fit(x_train_exit, y_train_exit, validation_data=(x_val_exit, y_val_exit), \n",
    "                   epochs=100, batch_size=32, verbose=0)\n",
    "\n",
    "    # Evaluate both models on validation data\n",
    "    val_loss_entrance = model_entrance.evaluate(x_val_entrance, y_val_entrance, verbose=0)\n",
    "    val_loss_exit = model_exit.evaluate(x_val_exit, y_val_exit, verbose=0)\n",
    "\n",
    "    # Combine the two objectives by returning a weighted sum\n",
    "    combined_loss = 0.5 * val_loss_entrance + 0.5 * val_loss_exit\n",
    "    trial_losses.append(combined_loss)  # Append the loss to the list\n",
    "    \n",
    "    return combined_loss\n",
    "\n",
    "# Create a study and optimize both models simultaneously\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "# Plot the losses\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(trial_losses, label='Loss per Trial', marker='o', color='blue')\n",
    "plt.title('Optimization Progress: Loss per Trial')\n",
    "plt.xlabel('Trial')\n",
    "plt.ylabel('Objective Value (Loss)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Print best hyperparameters\n",
    "print(\"Best hyperparameters: \", study.best_params)\n",
    "print(\"Best trial loss: \", study.best_value)\n",
    "\n",
    "# Build the final optimized models\n",
    "def build_best_model(best_params, input_shape):\n",
    "    num_layers = best_params['num_layers']\n",
    "    \n",
    "    # Reconstruct neurons per layer using the best parameters\n",
    "    neurons_per_layer = [best_params[f'num_neurons_layer_{i}'] for i in range(num_layers)]\n",
    "    activation = best_params['activation']\n",
    "    learning_rate = best_params['learning_rate']\n",
    "\n",
    "    model = create_model(input_shape, neurons_per_layer, activation, learning_rate)\n",
    "    return model\n",
    "\n",
    "# Create the final models using the best hyperparameters\n",
    "final_model_entrance = build_best_model(study.best_params, train_features_entrance.shape[1])\n",
    "final_model_exit = build_best_model(study.best_params, train_features_exit.shape[1])\n",
    "\n",
    "\n",
    "# Train the final models on the full datasets\n",
    "final_model_entrance.fit(train_features_entrance, train_labels_entrance, epochs=50, batch_size=32, verbose=1)\n",
    "final_model_exit.fit(train_features_exit, train_labels_exit, epochs=50, batch_size=32, verbose=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "3fea0f5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 773us/step - loss: 0.6612\n",
      "Test set loss for entrance: 0.6612163782119751\n",
      "3/3 [==============================] - 0s 870us/step - loss: 0.0869\n",
      "Test set loss for exit: 0.0869249477982521\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4418\n",
      "v2. Test set loss for entrance: 0.44183602929115295\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0251\n",
      "v2. Test set loss for exit: 0.025054931640625\n",
      "Test features Entrance: [[27.114  6.637 41.253  5.672]\n",
      " [20.427  6.524 45.683  5.674]\n",
      " [20.362  6.536 45.788  5.686]\n",
      " [20.297  6.547 45.893  5.697]\n",
      " [20.275  6.551 45.928  5.701]\n",
      " [20.145  6.573 46.137  5.723]\n",
      " [20.123  6.577 46.172  5.727]\n",
      " [20.058  6.589 46.277  5.739]\n",
      " [20.115  6.559 46.094  5.709]\n",
      " [20.2    6.52  45.839  5.67 ]\n",
      " [20.257  6.493 45.669  5.643]\n",
      " [20.435  6.468 45.451  5.618]\n",
      " [20.462  6.474 45.47   5.624]\n",
      " [20.594  6.502 45.564  5.652]\n",
      " [20.62   6.508 45.583  5.658]\n",
      " [21.527  6.503 44.819  5.639]\n",
      " [21.926  6.499 44.476  5.629]\n",
      " [23.123  6.489 43.448  5.601]\n",
      " [26.313  6.463 40.707  5.525]\n",
      " [28.706  6.443 38.651  5.469]\n",
      " [26.201  6.171 39.083  5.255]\n",
      " [25.566  6.111 39.249  5.209]\n",
      " [24.931  6.052 39.415  5.164]\n",
      " [24.296  5.992 39.581  5.119]\n",
      " [22.39   5.814 40.08   4.983]\n",
      " [21.942  5.734 40.099  4.917]\n",
      " [13.073  4.084 40.306  3.554]\n",
      " [12.696  4.023 40.263  3.493]\n",
      " [13.749  4.261 40.008  3.64 ]\n",
      " [13.925  4.301 39.966  3.665]\n",
      " [14.175  4.394 40.146  3.737]\n",
      " [14.059  4.396 40.367  3.75 ]\n",
      " [13.885  4.401 40.698  3.77 ]\n",
      " [13.536  4.409 41.361  3.809]\n",
      " [13.42   4.412 41.582  3.822]\n",
      " [13.104  4.417 42.167  3.857]\n",
      " [13.115  4.415 42.134  3.855]\n",
      " [13.137  4.41  42.068  3.85 ]\n",
      " [13.159  4.405 42.001  3.845]\n",
      " [13.213  4.393 41.836  3.833]\n",
      " [13.224  4.391 41.803  3.831]\n",
      " [13.311  4.372 41.539  3.812]\n",
      " [18.344  4.744 39.424  3.129]\n",
      " [17.418  4.555 39.337  3.045]\n",
      " [16.492  4.365 39.25   2.961]\n",
      " [10.01   3.037 38.642  2.373]\n",
      " [ 7.074  2.447 38.412  2.127]\n",
      " [ 7.208  2.497 38.506  2.177]\n",
      " [ 7.289  2.527 38.563  2.207]\n",
      " [ 7.343  2.546 38.601  2.226]\n",
      " [ 7.504  2.606 38.714  2.286]\n",
      " [ 7.599  2.636 38.707  2.309]\n",
      " [ 7.751  2.666 38.435  2.305]\n",
      " [ 7.807  2.677 38.333  2.304]\n",
      " [ 7.845  2.685 38.265  2.303]\n",
      " [ 7.883  2.693 38.197  2.302]\n",
      " [ 7.902  2.696 38.163  2.302]\n",
      " [ 7.949  2.713 38.087  2.301]\n",
      " [ 7.917  2.718 38.156  2.303]\n",
      " [ 7.808  2.734 38.397  2.31 ]\n",
      " [ 7.746  2.744 38.535  2.314]\n",
      " [ 7.715  2.749 38.604  2.315]\n",
      " [ 7.699  2.751 38.639  2.316]\n",
      " [ 7.684  2.753 38.673  2.317]\n",
      " [ 7.716  2.682 38.129  2.271]\n",
      " [ 7.745  2.651 37.881  2.252]\n",
      " [ 7.774  2.621 37.634  2.233]\n",
      " [ 7.789  2.606 37.51   2.224]]\n",
      "\n",
      "v2. Test features Entrance: [[29.08  6.44 38.33  5.46]\n",
      " [ 7.    2.42 38.36  2.1 ]\n",
      " [ 7.64  2.76 38.77  2.32]]\n",
      "\n",
      "Test result Entrance: {'dnn_model': 0.6612163782119751}\n",
      "\n",
      "v2. Test result Entrance: {'dnn_model': 0.44183602929115295}\n",
      "\n",
      "Test features Exit: [[38.522  8.349 42.24   7.115]\n",
      " [38.48   8.352 42.219  7.105]\n",
      " [38.732  8.409 42.352  7.156]\n",
      " [38.984  8.465 42.485  7.207]\n",
      " [39.068  8.484 42.53   7.224]\n",
      " [39.572  8.597 42.796  7.326]\n",
      " [39.656  8.616 42.84   7.343]\n",
      " [39.908  8.673 42.973  7.394]\n",
      " [39.752  8.636 42.887  6.269]\n",
      " [39.509  8.58  42.754  4.802]\n",
      " [39.346  8.542 42.666  3.824]\n",
      " [39.022  8.471 42.499  3.73 ]\n",
      " [39.004  8.468 42.492  4.199]\n",
      " [38.915  8.454 42.459  6.545]\n",
      " [38.897  8.451 42.452  7.014]\n",
      " [38.88   8.45  42.455  7.19 ]\n",
      " [38.876  8.45  42.458  7.19 ]\n",
      " [38.863  8.45  42.465  7.19 ]\n",
      " [38.829  8.45  42.484  7.19 ]\n",
      " [38.804  8.45  42.498  7.19 ]\n",
      " [38.539  8.369 42.256  7.122]\n",
      " [38.482  8.351 42.202  7.106]\n",
      " [38.424  8.333 42.149  7.091]\n",
      " [38.366  8.315 42.095  7.076]\n",
      " [38.194  8.261 41.933  7.031]\n",
      " [38.207  8.262 41.935  7.032]\n",
      " [38.584  8.316 42.033  7.077]\n",
      " [38.602  8.385 42.049  7.145]\n",
      " [38.568  8.674 42.089  7.434]\n",
      " [38.563  8.722 42.095  7.482]\n",
      " [38.643  8.798 42.183  7.553]\n",
      " [38.718  8.773 42.242  7.524]\n",
      " [38.83   8.734 42.329  7.48 ]\n",
      " [39.053  8.658 42.505  7.392]\n",
      " [39.128  8.632 42.564  7.363]\n",
      " [39.298  8.552 42.715  7.273]\n",
      " [39.267  8.546 42.703  7.268]\n",
      " [39.204  8.534 42.679  7.258]\n",
      " [39.14   8.521 42.656  7.247]\n",
      " [38.982  8.491 42.597  7.221]\n",
      " [38.951  8.484 42.585  7.216]\n",
      " [38.698  8.435 42.49   7.175]\n",
      " [38.551  8.308 41.979  7.116]\n",
      " [38.542  8.312 42.004  7.115]\n",
      " [38.532  8.316 42.028  7.115]\n",
      " [38.462  8.346 42.2    7.112]\n",
      " [38.522  8.381 42.331  7.129]\n",
      " [38.69   8.419 42.423  7.165]\n",
      " [38.79   8.441 42.478  7.186]\n",
      " [38.857  8.456 42.515  7.2  ]\n",
      " [39.058  8.502 42.625  7.243]\n",
      " [39.389  8.516 42.659  7.256]\n",
      " [40.665  8.497 42.602  7.237]\n",
      " [41.144  8.49  42.581  7.23 ]\n",
      " [41.463  8.486 42.567  7.226]\n",
      " [41.782  8.481 42.553  7.221]\n",
      " [41.942  8.479 42.546  7.219]\n",
      " [42.231  8.459 42.499  7.2  ]\n",
      " [41.811  8.443 42.467  7.186]\n",
      " [40.341  8.387 42.358  7.137]\n",
      " [39.501  8.355 42.296  7.108]\n",
      " [39.081  8.339 42.265  7.094]\n",
      " [38.871  8.331 42.249  7.087]\n",
      " [38.661  8.323 42.234  7.08 ]\n",
      " [38.516  8.398 42.41   7.146]\n",
      " [38.687  8.436 42.495  7.179]\n",
      " [38.859  8.473 42.58   7.212]\n",
      " [38.945  8.492 42.623  7.228]]\n",
      "\n",
      "v2. Test features Exit: [[38.8   8.45 42.5   7.19]\n",
      " [38.43  8.36 42.28  7.11]\n",
      " [38.07  8.3  42.19  7.06]]\n",
      "Test result Exit: {'dnn_model': 0.0869249477982521}\n",
      "\n",
      "v2. Test result Exit: {'dnn_model': 0.025054931640625}\n",
      "\n",
      "3/3 [==============================] - 0s 665us/step\n",
      "Test Predictions Entrance: [77.821 87.234 87.3   87.362 87.382 87.493 87.511 87.561 87.492 87.384\n",
      " 87.305 87.138 87.13  87.09  87.082 86.093 85.519 83.484 78.231 75.649\n",
      " 77.43  78.071 78.767 79.505 81.859 82.348 88.073 88.119 87.955 87.922\n",
      " 87.901 87.948 88.009 88.105 88.131 88.191 88.189 88.184 88.179 88.166\n",
      " 88.163 88.14  84.483 85.314 86.073 88.603 89.98  89.94  89.915 89.896\n",
      " 89.838 89.796 89.703 89.666 89.64  89.614 89.601 89.568 89.59  89.667\n",
      " 89.708 89.728 89.738 89.748 89.686 89.65  89.611 89.592]\n",
      "\n",
      "3/3 [==============================] - 0s 745us/step\n",
      "Test Predictions Exit: [75.113 75.113 75.113 75.113 75.113 75.113 75.113 75.113 75.113 75.113\n",
      " 75.113 75.113 75.113 75.113 75.113 75.113 75.113 75.113 75.113 75.113\n",
      " 75.113 75.113 75.113 75.113 75.113 75.113 75.113 75.113 75.113 75.113\n",
      " 75.113 75.113 75.113 75.113 75.113 75.113 75.113 75.113 75.113 75.113\n",
      " 75.113 75.113 75.113 75.113 75.113 75.113 75.113 75.113 75.113 75.113\n",
      " 75.113 75.113 75.113 75.113 75.113 75.113 75.113 75.113 75.113 75.113\n",
      " 75.113 75.113 75.113 75.113 75.113 75.113 75.113 75.113]\n",
      "\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "v2. Test Predictions Entrance: [75.403 90.001 89.775]\n",
      "\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "v2. Test Predictions Exit: [75.113 75.113 75.113]\n",
      "\n",
      "Error entrance: 9     -1.865482\n",
      "25    -0.347808\n",
      "28    -0.425212\n",
      "31    -0.506140\n",
      "32    -0.533882\n",
      "         ...   \n",
      "315   -0.285819\n",
      "323    0.342792\n",
      "325    0.634032\n",
      "327    0.923921\n",
      "328    1.068377\n",
      "Name: Temperature (Â°F), Length: 68, dtype: float64\n",
      "\n",
      "Error exit: 9     -1.865482\n",
      "25    -0.347808\n",
      "28    -0.425212\n",
      "31    -0.506140\n",
      "32    -0.533882\n",
      "         ...   \n",
      "315   -0.285819\n",
      "323    0.342792\n",
      "325    0.634032\n",
      "327    0.923921\n",
      "328    1.068377\n",
      "Name: Temperature (Â°F), Length: 68, dtype: float64\n",
      "\n",
      "v2. Error entrance: 5    -0.137214\n",
      "12   -0.769329\n",
      "15   -0.418937\n",
      "Name: Temperature (°F), dtype: float64\n",
      "\n",
      "v2. Error exit: 5    -0.137214\n",
      "12   -0.769329\n",
      "15   -0.418937\n",
      "Name: Temperature (°F), dtype: float64\n",
      "\n",
      "Average error for entrance: -0.09480098150160873\n",
      "\n",
      "Average error for exit: 0.07776631576459077\n",
      "\n",
      "v2. Average error for entrance: -0.4418265991210954\n",
      "\n",
      "v2. Average error for exit: -0.4418265991210954\n",
      "\n",
      "Mean Squared Error for entrance: 0.662096968144272\n",
      "Mean Squared Error for exit: 0.01579783421937427\n",
      "\n",
      "v2. Mean Squared Error for entrance: 0.2620675682762518\n",
      "v2. Mean Squared Error for exit: 0.000874625283451199\n",
      "\n",
      "Mean Absolute Error for entrance: 0.6612122803107762\n",
      "Mean Absolute Error for exit: 0.08692253310317062\n",
      "\n",
      "v2. Mean Absolute Error for entrance: 0.4418265991210954\n",
      "v2. Mean Absolute Error for exit: 0.025060689290365683\n",
      "\n",
      "MAPE for entrance: 0.76%\n",
      "MAPE for exit: 0.12%\n",
      "v2. MAPE for entrance: 0.50%\n",
      "v2. MAPE for exit: 0.03%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Optionally, evaluate on a test set (if you have one)\n",
    "test_loss_entrance = final_model_entrance.evaluate(test_features_entrance, test_labels_entrance, verbose=1)\n",
    "print(f\"Test set loss for entrance: {test_loss_entrance}\")\n",
    "test_loss_exit = final_model_exit.evaluate(test_features_exit, test_labels_exit, verbose=1)\n",
    "print(f\"Test set loss for exit: {test_loss_exit}\")\n",
    "\n",
    "ori_test_loss_entrance = final_model_entrance.evaluate(ori_test_features_entrance, ori_test_labels_entrance, verbose=1)\n",
    "print(f\"v2. Test set loss for entrance: {ori_test_loss_entrance}\")\n",
    "ori_test_loss_exit = final_model_exit.evaluate(ori_test_features_exit, ori_test_labels_exit, verbose=1)\n",
    "print(f\"v2. Test set loss for exit: {ori_test_loss_exit}\")\n",
    "\n",
    "#----------------------\n",
    "test_features_entrance = np.asarray(test_features_entrance).astype(np.float32)\n",
    "print(\"Test features Entrance:\", test_features_entrance)\n",
    "print()\n",
    "\n",
    "ori_test_features_entrance = np.asarray(ori_test_features_entrance).astype(np.float32)\n",
    "print(\"v2. Test features Entrance:\", ori_test_features_entrance)\n",
    "print()\n",
    "\n",
    "#----------------------\n",
    "test_results_entrance = {}\n",
    "test_results_entrance['dnn_model'] = final_model_entrance.evaluate(test_features_entrance, test_labels_entrance, verbose=0)\n",
    "print(\"Test result Entrance:\", test_results_entrance)\n",
    "print()\n",
    "\n",
    "ori_test_results_entrance = {}\n",
    "ori_test_results_entrance['dnn_model'] = final_model_entrance.evaluate(ori_test_features_entrance, ori_test_labels_entrance, verbose=0)\n",
    "print(\"v2. Test result Entrance:\", ori_test_results_entrance)\n",
    "print()\n",
    "\n",
    "#----------------------\n",
    "test_features_exit = np.asarray(test_features_exit).astype(np.float32)\n",
    "print(\"Test features Exit:\", test_features_exit)\n",
    "print()\n",
    "\n",
    "ori_test_features_exit = np.asarray(ori_test_features_exit).astype(np.float32)\n",
    "print(\"v2. Test features Exit:\", ori_test_features_exit)\n",
    "\n",
    "#----------------------\n",
    "test_results_exit = {}\n",
    "test_results_exit['dnn_model'] = final_model_exit.evaluate(test_features_exit, test_labels_exit, verbose=0)\n",
    "print(\"Test result Exit:\", test_results_exit)\n",
    "print()\n",
    "\n",
    "ori_test_results_exit = {}\n",
    "ori_test_results_exit['dnn_model'] = final_model_exit.evaluate(ori_test_features_exit, ori_test_labels_exit, verbose=0)\n",
    "print(\"v2. Test result Exit:\", ori_test_results_exit)\n",
    "print()\n",
    "\n",
    "#----------------------\n",
    "pd.DataFrame(test_results_entrance, index=['Mean absolute error [Temperature]']).T\n",
    "\n",
    "pd.DataFrame(test_results_exit, index=['Mean absolute error [Temperature]']).T\n",
    "\n",
    "pd.DataFrame(ori_test_results_entrance, index=['Mean absolute error [Temperature]']).T\n",
    "\n",
    "pd.DataFrame(ori_test_results_exit, index=['Mean absolute error [Temperature]']).T\n",
    "\n",
    "#----------------------\n",
    "test_predictions_entrance = final_model_entrance.predict(test_features_entrance).flatten()\n",
    "print(\"Test Predictions Entrance:\", test_predictions_entrance)\n",
    "print()\n",
    "\n",
    "test_predictions_exit = final_model_exit.predict(test_features_exit).flatten()\n",
    "print(\"Test Predictions Exit:\", test_predictions_exit)\n",
    "print()\n",
    "\n",
    "ori_test_predictions_entrance = final_model_entrance.predict(ori_test_features_entrance).flatten()\n",
    "print(\"v2. Test Predictions Entrance:\", ori_test_predictions_entrance)\n",
    "print()\n",
    "\n",
    "ori_test_predictions_exit = final_model_exit.predict(ori_test_features_exit).flatten()\n",
    "print(\"v2. Test Predictions Exit:\", ori_test_predictions_exit)\n",
    "print()\n",
    "\n",
    "#----------------------\n",
    "error_entrance = test_predictions_entrance - test_labels_entrance\n",
    "print(\"Error entrance:\", error_entrance)\n",
    "print()\n",
    "\n",
    "error_exit = test_predictions_entrance - test_labels_entrance\n",
    "print(\"Error exit:\", error_exit)\n",
    "print()\n",
    "\n",
    "ori_error_entrance = ori_test_predictions_entrance - ori_test_labels_entrance\n",
    "print(\"v2. Error entrance:\", ori_error_entrance)\n",
    "print()\n",
    "\n",
    "ori_error_exit = ori_test_predictions_entrance - ori_test_labels_entrance\n",
    "print(\"v2. Error exit:\", ori_error_exit)\n",
    "print()\n",
    "\n",
    "#----------------------\n",
    "plt.hist(error_entrance, bins=25, color='lightblue')\n",
    "plt.xlabel('Prediction Error [Temperature]')\n",
    "_ = plt.ylabel('Count')\n",
    "\n",
    "error_exit = test_predictions_exit - test_labels_exit\n",
    "error_exit\n",
    "\n",
    "plt.hist(error_exit, bins=25, color='lightblue')\n",
    "plt.xlabel('Prediction Error [Temperature]')\n",
    "_ = plt.ylabel('Count')\n",
    "\n",
    "# average error\n",
    "average_error_entrance = np.mean(error_entrance)\n",
    "print(\"Average error for entrance:\", average_error_entrance)\n",
    "print()\n",
    "\n",
    "average_error_exit = np.mean(error_exit)\n",
    "print(\"Average error for exit:\", average_error_exit)\n",
    "print()\n",
    "\n",
    "ori_average_error_entrance = np.mean(ori_error_entrance)\n",
    "print(\"v2. Average error for entrance:\", ori_average_error_entrance)\n",
    "print()\n",
    "\n",
    "ori_average_error_exit = np.mean(ori_error_exit)\n",
    "print(\"v2. Average error for exit:\", ori_average_error_exit)\n",
    "print()\n",
    "\n",
    "# mean squared error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse_entrance = mean_squared_error(test_labels_entrance, test_predictions_entrance)\n",
    "mse_exit = mean_squared_error(test_labels_exit, test_predictions_exit)\n",
    "print(\"Mean Squared Error for entrance:\", mse_entrance)\n",
    "print(\"Mean Squared Error for exit:\", mse_exit)\n",
    "print()\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "ori_mse_entrance = mean_squared_error(ori_test_labels_entrance, ori_test_predictions_entrance)\n",
    "ori_mse_exit = mean_squared_error(ori_test_labels_exit, ori_test_predictions_exit)\n",
    "print(\"v2. Mean Squared Error for entrance:\", ori_mse_entrance)\n",
    "print(\"v2. Mean Squared Error for exit:\", ori_mse_exit)\n",
    "print()\n",
    "\n",
    "# mean absolute error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "mae_entrance = mean_absolute_error(test_labels_entrance, test_predictions_entrance)\n",
    "mae_exit = mean_absolute_error(test_labels_exit, test_predictions_exit)\n",
    "print(\"Mean Absolute Error for entrance:\", mae_entrance)\n",
    "print(\"Mean Absolute Error for exit:\", mae_exit)\n",
    "print()\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "ori_mae_entrance = mean_absolute_error(ori_test_labels_entrance, ori_test_predictions_entrance)\n",
    "ori_mae_exit = mean_absolute_error(ori_test_labels_exit, ori_test_predictions_exit)\n",
    "print(\"v2. Mean Absolute Error for entrance:\", ori_mae_entrance)\n",
    "print(\"v2. Mean Absolute Error for exit:\", ori_mae_exit)\n",
    "print()\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def mean_absolute_percentage_error(y_actual, y_pred):\n",
    "    y_actual, y_pred = np.array(y_actual), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_actual - y_pred) / y_actual)) * 100\n",
    "\n",
    "mape = mean_absolute_percentage_error(test_labels_entrance, test_predictions_entrance)\n",
    "print(f'MAPE for entrance: {mape:.2f}%')\n",
    "\n",
    "mape = mean_absolute_percentage_error(test_labels_exit, test_predictions_exit)\n",
    "print(f'MAPE for exit: {mape:.2f}%')\n",
    "\n",
    "ori_mape = mean_absolute_percentage_error(ori_test_labels_entrance, ori_test_predictions_entrance)\n",
    "print(f'v2. MAPE for entrance: {ori_mape:.2f}%')\n",
    "\n",
    "ori_mape = mean_absolute_percentage_error(ori_test_labels_exit, ori_test_predictions_exit)\n",
    "print(f'v2. MAPE for exit: {ori_mape:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "26b7ba0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial Losses (Objective Values) as a Column:\n",
      "1|1.5924825817346573\n",
      "2|69.81199645996094\n",
      "3|0.8460460007190704\n",
      "4|42.12613487243652\n",
      "5|0.9309985935688019\n",
      "6|3.2236512415111065\n",
      "7|2.3445650413632393\n",
      "8|0.9794989228248596\n",
      "9|61.12971496582031\n",
      "10|61.31773567199707\n",
      "11|40.47855257987976\n",
      "12|0.7521409243345261\n",
      "13|0.8069053888320923\n",
      "14|0.8161766976118088\n",
      "15|1.001971498131752\n",
      "16|0.8187957108020782\n",
      "17|0.6536020636558533\n",
      "18|0.740941196680069\n",
      "19|0.996908500790596\n",
      "20|0.8709353506565094\n",
      "21|0.792401134967804\n",
      "22|0.8577585518360138\n",
      "23|0.9384611546993256\n",
      "24|0.6844347715377808\n",
      "25|0.8006107807159424\n",
      "26|2.2753272652626038\n",
      "27|1.4790867865085602\n",
      "28|1.0277387499809265\n",
      "29|1.7240327894687653\n",
      "30|0.8550821542739868\n",
      "31|0.8079227805137634\n",
      "32|0.7970000654459\n",
      "33|0.7921300828456879\n",
      "34|0.6763487309217453\n",
      "35|1.7124363109469414\n",
      "36|0.6810104548931122\n",
      "37|0.6760101318359375\n",
      "38|0.6615772470831871\n",
      "39|0.4670785516500473\n",
      "40|0.443444199860096\n",
      "41|0.5821045413613319\n",
      "42|0.48143240064382553\n",
      "43|0.5239483863115311\n",
      "44|0.5051498264074326\n",
      "45|0.47546857222914696\n",
      "46|0.5100218206644058\n",
      "47|0.39729592204093933\n",
      "48|0.36320966109633446\n",
      "49|0.4667072109878063\n",
      "50|8.758821725845337\n",
      "51|0.41806307062506676\n",
      "52|0.41679009050130844\n",
      "53|0.4545419029891491\n",
      "54|0.39988818019628525\n",
      "55|0.42908458039164543\n",
      "56|14.510530948638916\n",
      "57|0.45289361476898193\n",
      "58|0.43401629105210304\n",
      "59|1.7060320116579533\n",
      "60|0.42352938652038574\n",
      "61|0.4876057803630829\n",
      "62|0.3688250556588173\n",
      "63|0.5676713362336159\n",
      "64|0.4731113724410534\n",
      "65|0.3947700634598732\n",
      "66|0.4248566962778568\n",
      "67|0.440652035176754\n",
      "68|1.7080082520842552\n",
      "69|0.5850579813122749\n",
      "70|0.42371916025877\n",
      "71|1.7052264586091042\n",
      "72|0.5107102245092392\n",
      "73|0.4454530030488968\n",
      "74|52.986345291137695\n",
      "75|0.43654216080904007\n",
      "76|0.5051556564867496\n",
      "77|0.4035085663199425\n",
      "78|0.43585608527064323\n",
      "79|1.7076052203774452\n",
      "80|0.5390064530074596\n",
      "81|0.5562276095151901\n",
      "82|0.41132548078894615\n",
      "83|0.4695252850651741\n",
      "84|0.3778449445962906\n",
      "85|0.41078297048807144\n",
      "86|0.4028336927294731\n",
      "87|0.45855268090963364\n",
      "88|0.5029719322919846\n",
      "89|0.41204529628157616\n",
      "90|0.4619959779083729\n",
      "91|0.4795007072389126\n",
      "92|0.3893604502081871\n",
      "93|0.39249231666326523\n",
      "94|0.4182836227118969\n",
      "95|0.4466424286365509\n",
      "96|0.3964071199297905\n",
      "97|0.5558348819613457\n",
      "98|0.39078114181756973\n",
      "99|0.4397144690155983\n",
      "100|0.397786982357502\n"
     ]
    }
   ],
   "source": [
    "print(\"Trial Losses (Objective Values) as a Column:\")\n",
    "for i, loss in enumerate(trial_losses):\n",
    "    print(f\"{i + 1}|{loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88692e6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
